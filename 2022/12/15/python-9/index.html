<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hot5656.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.2.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/search.json","localsearch":{"enable":"enable","trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="說明5 components Spiders Spiders (spider Middleware-extracting data) scrapy.spider crawlspider   Pipelines Middleware(Downloader Middeware) Engine Scheduler">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Scrapy 說明(爬蟲框架)">
<meta property="og:url" content="https://hot5656.github.io/2022/12/15/python-9/index.html">
<meta property="og:site_name" content="Robert 雜記">
<meta property="og:description" content="說明5 components Spiders Spiders (spider Middleware-extracting data) scrapy.spider crawlspider   Pipelines Middleware(Downloader Middeware) Engine Scheduler">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic13.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic14.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic15.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic16.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic17.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic18.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic19.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic20.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic21.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic22.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic11.png">
<meta property="og:image" content="https://hot5656.github.io/2022/12/15/python-9/pic12.png">
<meta property="article:published_time" content="2022-12-15T03:22:47.000Z">
<meta property="article:modified_time" content="2024-04-23T09:23:34.070Z">
<meta property="article:author" content="Robert Kao">
<meta property="article:tag" content="python">
<meta property="article:tag" content="crawling">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hot5656.github.io/2022/12/15/python-9/pic13.png">


<link rel="canonical" href="https://hot5656.github.io/2022/12/15/python-9/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>
<title>Python Scrapy 說明(爬蟲框架) | Robert 雜記</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Robert 雜記</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔列表</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AA%AA%E6%98%8E"><span class="nav-number">1.</span> <span class="nav-text">說明</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-components"><span class="nav-number">1.1.</span> <span class="nav-text">5 components</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spider-type"><span class="nav-number">1.2.</span> <span class="nav-text">Spider type</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Robots-txt-websites"><span class="nav-number">1.3.</span> <span class="nav-text">Robots.txt (websites)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#the-why%E2%80%99s-and-when%E2%80%99s-of-web-scraping"><span class="nav-number">1.4.</span> <span class="nav-text">the why’s and when’s of web scraping</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrapy-sider-templates"><span class="nav-number">1.5.</span> <span class="nav-text">scrapy sider templates</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#command"><span class="nav-number">2.</span> <span class="nav-text">command</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#install-scrapy"><span class="nav-number">2.1.</span> <span class="nav-text">install scrapy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#install-pymongo-amp-dnspython-for-MongoDB"><span class="nav-number">2.2.</span> <span class="nav-text">install pymongo &amp; dnspython(for MongoDB)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#install-scrapy-by-conda"><span class="nav-number">2.3.</span> <span class="nav-text">install scrapy by conda</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#insatll-scrapy"><span class="nav-number">2.3.1.</span> <span class="nav-text">insatll scrapy</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#once-scrapy-parse-ok-but-doesn%E2%80%99t-know-Why"><span class="nav-number">2.3.2.</span> <span class="nav-text">once scrapy parse ok - but doesn’t know Why?</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#create-project"><span class="nav-number">2.4.</span> <span class="nav-text">create project</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#create-spider"><span class="nav-number">2.5.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#create-spider-crawl-template"><span class="nav-number">2.6.</span> <span class="nav-text">create spider(crawl template)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run"><span class="nav-number">2.7.</span> <span class="nav-text">run</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#data-generate-by-dataset-json-csv-xml"><span class="nav-number">2.8.</span> <span class="nav-text">data generate by dataset(json, csv, xml)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#manual-control"><span class="nav-number">3.</span> <span class="nav-text">manual control</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#version-amp-help"><span class="nav-number">3.1.</span> <span class="nav-text">version &amp; help</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#shell-get-url"><span class="nav-number">3.2.</span> <span class="nav-text">shell get url</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fetch-and-view"><span class="nav-number">3.3.</span> <span class="nav-text">fetch and view</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Packages"><span class="nav-number">4.</span> <span class="nav-text">Packages</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Selector"><span class="nav-number">4.1.</span> <span class="nav-text">Selector</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#settings-py"><span class="nav-number">5.</span> <span class="nav-text">settings.py</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#set-JSON-utf-8-format"><span class="nav-number">5.1.</span> <span class="nav-text">set JSON utf-8 format</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#set-close-scrapy-for-item-count"><span class="nav-number">5.2.</span> <span class="nav-text">set close scrapy for item count</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#set-User-Agent-2-way"><span class="nav-number">5.3.</span> <span class="nav-text">set User-Agent(2 way)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#save-Scrapy-crawl-Command-output"><span class="nav-number">5.4.</span> <span class="nav-text">save Scrapy crawl Command output</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#coding"><span class="nav-number">6.</span> <span class="nav-text">coding</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#starting-spider-py"><span class="nav-number">6.1.</span> <span class="nav-text">starting spider .py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bsolute-url"><span class="nav-number">6.2.</span> <span class="nav-text">bsolute url</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#relative-url"><span class="nav-number">6.3.</span> <span class="nav-text">relative url</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#add-meta-for-callback-parameter"><span class="nav-number">6.4.</span> <span class="nav-text">add meta for callback parameter</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#dealing-with-pagination"><span class="nav-number">6.5.</span> <span class="nav-text">dealing with pagination</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#add-headers"><span class="nav-number">6.6.</span> <span class="nav-text">add headers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#add-headers-crawl-template"><span class="nav-number">6.7.</span> <span class="nav-text">add headers(crawl template)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fake-useragent"><span class="nav-number">6.8.</span> <span class="nav-text">fake_useragent</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-1"><span class="nav-number">6.8.1.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#middlewares-py"><span class="nav-number">6.8.2.</span> <span class="nav-text">middlewares.py</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#output-2-json-files-by-coding"><span class="nav-number">6.9.</span> <span class="nav-text">output 2 json files(by coding)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#pipelines-py"><span class="nav-number">6.9.1.</span> <span class="nav-text">pipelines.py</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pipelines"><span class="nav-number">7.</span> <span class="nav-text">Pipelines</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#enabel-pipelines"><span class="nav-number">7.1.</span> <span class="nav-text">enabel pipelines</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-2"><span class="nav-number">7.1.1.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#pipelines-py-1"><span class="nav-number">7.1.2.</span> <span class="nav-text">pipelines.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-1"><span class="nav-number">7.1.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Store-data-in-MongoDB"><span class="nav-number">7.2.</span> <span class="nav-text">Store data in MongoDB</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#pipelines-py-2"><span class="nav-number">7.2.1.</span> <span class="nav-text">pipelines.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-3"><span class="nav-number">7.2.2.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-2"><span class="nav-number">7.2.3.</span> <span class="nav-text">run</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MongoDB"><span class="nav-number">7.2.4.</span> <span class="nav-text">MongoDB</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Store-data-in-SQLite3"><span class="nav-number">7.3.</span> <span class="nav-text">Store data in SQLite3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#pipelines-py-3"><span class="nav-number">7.3.1.</span> <span class="nav-text">pipelines.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-4"><span class="nav-number">7.3.2.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-3"><span class="nav-number">7.3.3.</span> <span class="nav-text">run</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SQLite3"><span class="nav-number">7.3.4.</span> <span class="nav-text">SQLite3</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Middleware"><span class="nav-number">8.</span> <span class="nav-text">Middleware</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#install-fake-useragent"><span class="nav-number">8.1.</span> <span class="nav-text">install fake-useragent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#UserAgent"><span class="nav-number">8.2.</span> <span class="nav-text">UserAgent</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-5"><span class="nav-number">8.2.1.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#middlewares-py-1"><span class="nav-number">8.2.2.</span> <span class="nav-text">middlewares.py</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scrapy-API"><span class="nav-number">9.</span> <span class="nav-text">Scrapy API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Quotes-to-Scrape"><span class="nav-number">9.1.</span> <span class="nav-text">Quotes to Scrape</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#check-API-from-chrom"><span class="nav-number">9.1.1.</span> <span class="nav-text">check API from chrom</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#create-project-and-spider"><span class="nav-number">9.1.2.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#quotes-py"><span class="nav-number">9.1.3.</span> <span class="nav-text">quotes.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-4"><span class="nav-number">9.1.4.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OPEN-LIBRARY"><span class="nav-number">9.2.</span> <span class="nav-text">OPEN LIBRARY</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#check-API-from-chrome"><span class="nav-number">9.2.1.</span> <span class="nav-text">check API from chrome</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#create-spider-1"><span class="nav-number">9.2.2.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ebooks-py"><span class="nav-number">9.2.3.</span> <span class="nav-text">ebooks.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-5"><span class="nav-number">9.2.4.</span> <span class="nav-text">run</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Login-to-websites"><span class="nav-number">10.</span> <span class="nav-text">Login to websites</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Quote-to-Scrape"><span class="nav-number">10.1.</span> <span class="nav-text">Quote to Scrape</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#check-from-chrome"><span class="nav-number">10.1.1.</span> <span class="nav-text">check from chrome</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#create-project-and-spider-1"><span class="nav-number">10.1.2.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#quotes-login-py"><span class="nav-number">10.1.3.</span> <span class="nav-text">quotes_login.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-6"><span class="nav-number">10.1.4.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Open-Library"><span class="nav-number">10.2.</span> <span class="nav-text">Open Library</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-spider-2"><span class="nav-number">10.2.1.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#open-library-py"><span class="nav-number">10.2.2.</span> <span class="nav-text">open_library.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#openlibrary-login-py"><span class="nav-number">10.2.3.</span> <span class="nav-text">openlibrary_login.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-7"><span class="nav-number">10.2.4.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Aarchive-Org"><span class="nav-number">10.3.</span> <span class="nav-text">Aarchive Org</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-spider-3"><span class="nav-number">10.3.1.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#openlibrary-login2-py"><span class="nav-number">10.3.2.</span> <span class="nav-text">openlibrary_login2.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-8"><span class="nav-number">10.3.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Quote-to-Scrape-Script"><span class="nav-number">10.4.</span> <span class="nav-text">Quote to Scrape - Script</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-spider-4"><span class="nav-number">10.4.1.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#quotes-login2-py"><span class="nav-number">10.4.2.</span> <span class="nav-text">quotes_login2.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-9"><span class="nav-number">10.4.3.</span> <span class="nav-text">run</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ByPass-Cloudflare"><span class="nav-number">11.</span> <span class="nav-text">ByPass Cloudflare</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CoinMarketCap-block-by-status-code-429-too-many-request"><span class="nav-number">11.1.</span> <span class="nav-text">CoinMarketCap - block by status code 429(too many request)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-project-and-spider-2"><span class="nav-number">11.1.1.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#coins-py"><span class="nav-number">11.1.2.</span> <span class="nav-text">coins.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-10"><span class="nav-number">11.1.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fix-block-by-status-code-429-%E4%BE%9D%E8%AA%B2%E7%A8%8B%E4%BF%AE%E6%94%B9%E4%BD%86%E6%B2%92%E6%9C%89%E7%94%A8"><span class="nav-number">11.2.</span> <span class="nav-text">fix block by status code 429(依課程修改但沒有用)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#install"><span class="nav-number">11.2.1.</span> <span class="nav-text">install</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-6"><span class="nav-number">11.2.2.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CloudFlare-Middleware-modify"><span class="nav-number">11.2.3.</span> <span class="nav-text">CloudFlare Middleware modify</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-11"><span class="nav-number">11.2.4.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fix-block-by-status-code-429-call-splash-%E9%82%84%E6%98%AF%E6%9C%83%E5%9B%9E429"><span class="nav-number">11.3.</span> <span class="nav-text">fix block by status code 429 - call splash(還是會回429)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-projector-and-spider"><span class="nav-number">11.3.1.</span> <span class="nav-text">create projector and spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#basic-setting"><span class="nav-number">11.3.2.</span> <span class="nav-text">basic setting</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#coins2-py"><span class="nav-number">11.3.3.</span> <span class="nav-text">coins2.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-12"><span class="nav-number">11.3.4.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CoinMarketCap-bs4-cloudscraper"><span class="nav-number">11.4.</span> <span class="nav-text">CoinMarketCap - bs4 + cloudscraper</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#install-beautifulsoup4"><span class="nav-number">11.4.1.</span> <span class="nav-text">install beautifulsoup4</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#bypass-coinmarket-py"><span class="nav-number">11.4.2.</span> <span class="nav-text">bypass_coinmarket.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-13"><span class="nav-number">11.4.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fiverr-bs4-cloudscraper"><span class="nav-number">11.5.</span> <span class="nav-text">fiverr - bs4 + cloudscraper</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#bypass-fiverr-py"><span class="nav-number">11.5.1.</span> <span class="nav-text">bypass_fiverr.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-14"><span class="nav-number">11.5.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fiverr-block-403"><span class="nav-number">11.6.</span> <span class="nav-text">fiverr - block 403</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-project-and-spider-3"><span class="nav-number">11.6.1.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-15"><span class="nav-number">11.6.2.</span> <span class="nav-text">run</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#install-beautifulsoup4-and-cloudscraper"><span class="nav-number">11.6.3.</span> <span class="nav-text">install beautifulsoup4 and cloudscraper</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Downloading-Files-Using-Scrapy"><span class="nav-number">12.</span> <span class="nav-text">Downloading Files Using Scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#mp3-59"><span class="nav-number">12.1.</span> <span class="nav-text">mp3-59</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-project-and-spider-4"><span class="nav-number">12.1.1.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#mp3-downloader-py"><span class="nav-number">12.1.2.</span> <span class="nav-text">mp3_downloader.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-7"><span class="nav-number">12.1.3.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#items-py"><span class="nav-number">12.1.4.</span> <span class="nav-text">items.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-16"><span class="nav-number">12.1.5.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mp3-59-fix-file-name"><span class="nav-number">12.2.</span> <span class="nav-text">mp3-59 - fix file name</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py-8"><span class="nav-number">12.2.1.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#pipelines-py-4"><span class="nav-number">12.2.2.</span> <span class="nav-text">pipelines.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-17"><span class="nav-number">12.2.3.</span> <span class="nav-text">run</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#download-image-by-python"><span class="nav-number">13.</span> <span class="nav-text">download image by python</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Debug"><span class="nav-number">14.</span> <span class="nav-text">Debug</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Parse-Command"><span class="nav-number">14.1.</span> <span class="nav-text">Parse Command</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Scrapy-Shell"><span class="nav-number">14.2.</span> <span class="nav-text">Scrapy Shell</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Open-in-browser"><span class="nav-number">14.3.</span> <span class="nav-text">Open in browser</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Logging"><span class="nav-number">14.4.</span> <span class="nav-text">Logging</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-python-debug-need-set-to-corect-python-enviroment"><span class="nav-number">14.5.</span> <span class="nav-text">run python debug(need set to corect python enviroment)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#runner-py"><span class="nav-number">14.5.1.</span> <span class="nav-text">runner.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#F5-run-debug"><span class="nav-number">14.5.2.</span> <span class="nav-text">F5 run debug</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Test-Scrapy"><span class="nav-number">14.6.</span> <span class="nav-text">Test Scrapy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XPath-expression"><span class="nav-number">15.</span> <span class="nav-text">XPath expression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Xpath-guide"><span class="nav-number">15.1.</span> <span class="nav-text">Xpath guide</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#function"><span class="nav-number">15.1.1.</span> <span class="nav-text">function</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-html-for-XPath-expression"><span class="nav-number">15.2.</span> <span class="nav-text">test html for XPath expression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#XPath-expression-1"><span class="nav-number">15.3.</span> <span class="nav-text">XPath expression</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CSS-selectors"><span class="nav-number">16.</span> <span class="nav-text">CSS selectors</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#test-html-for-CSS-selectors"><span class="nav-number">16.1.</span> <span class="nav-text">test html for CSS selectors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CSS-selectors-1"><span class="nav-number">16.2.</span> <span class="nav-text">CSS selectors</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#run-by-python"><span class="nav-number">17.</span> <span class="nav-text">run by python</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python-run-process"><span class="nav-number">17.1.</span> <span class="nav-text">python run process</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#run-scrapy-subprocess-py"><span class="nav-number">17.1.1.</span> <span class="nav-text">run_scrapy_subprocess.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-18"><span class="nav-number">17.1.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrapy-run-crawler-Process"><span class="nav-number">17.2.</span> <span class="nav-text">scrapy run crawler Process</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#run-scrapy-crawlerprocess-py"><span class="nav-number">17.2.1.</span> <span class="nav-text">run_scrapy_crawlerprocess.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-19"><span class="nav-number">17.2.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-by-Twisted-reactor"><span class="nav-number">17.3.</span> <span class="nav-text">run by Twisted reactor</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#run-scrapy-crawlerrunner-py"><span class="nav-number">17.3.1.</span> <span class="nav-text">run_scrapy_crawlerrunner.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-20"><span class="nav-number">17.3.2.</span> <span class="nav-text">run</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tool"><span class="nav-number">18.</span> <span class="nav-text">Tool</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Evaluate-and-validate-XPath-x2F-CSS-selectors-in-Chrome-Developer-Tools"><span class="nav-number">18.1.</span> <span class="nav-text">Evaluate and validate XPath&#x2F;CSS selectors in Chrome Developer Tools</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#VscCode-automatically-formatted-the-JSON-file"><span class="nav-number">18.2.</span> <span class="nav-text">VscCode automatically formatted the JSON file</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#vs-code-plugin"><span class="nav-number">18.3.</span> <span class="nav-text">vs code plugin</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#excel-%E9%96%8B-utf-8-csv-file"><span class="nav-number">18.4.</span> <span class="nav-text">excel 開  utf-8 .csv file</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Chrome-plugin"><span class="nav-number">18.5.</span> <span class="nav-text">Chrome plugin</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Wait"><span class="nav-number">19.</span> <span class="nav-text">Wait</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ref"><span class="nav-number">20.</span> <span class="nav-text">Ref</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Robert Kao"
      src="/images/head.png">
  <p class="site-author-name" itemprop="name">Robert Kao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">170</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">66</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
        <div class="back-to-top animated" role="button">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://hot5656.github.io/2022/12/15/python-9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="Robert Kao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Robert 雜記">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python Scrapy 說明(爬蟲框架)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-12-15 11:22:47" itemprop="dateCreated datePublished" datetime="2022-12-15T11:22:47+08:00">2022-12-15</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新於</span>
        <time title="修改時間：2024-04-23 17:23:34" itemprop="dateModified" datetime="2024-04-23T17:23:34+08:00">2024-04-23</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Coding/" itemprop="url" rel="index"><span itemprop="name">Coding</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2022/12/15/python-9/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/12/15/python-9/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>99k</span>
    </span>
    <span class="post-meta-item" title="所需閱讀時間">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">所需閱讀時間 &asymp;</span>
      <span>1:30</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="說明"><a href="#說明" class="headerlink" title="說明"></a>說明</h3><h4 id="5-components"><a href="#5-components" class="headerlink" title="5 components"></a>5 components</h4><ul>
<li>Spiders</li>
<li>Spiders (spider Middleware-extracting data)<ul>
<li>scrapy.spider</li>
<li>crawlspider</li>
</ul>
</li>
<li>Pipelines</li>
<li>Middleware(Downloader Middeware)</li>
<li>Engine</li>
<li>Scheduler</li>
</ul>
<span id="more"></span>

<h4 id="Spider-type"><a href="#Spider-type" class="headerlink" title="Spider type"></a>Spider type</h4><ul>
<li>XMLFeedSpider</li>
<li>CSVFeedSpider</li>
<li>SitemapSpider</li>
</ul>
<h4 id="Robots-txt-websites"><a href="#Robots-txt-websites" class="headerlink" title="Robots.txt (websites)"></a>Robots.txt (websites)</h4><ul>
<li>User-Agent</li>
<li>Allow</li>
<li>Disallow</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># example website : https:&#x2F;&#x2F;www.facebook.com&#x2F;robots.txt</span><br><span class="line"># Notice: Collection of data on Facebook through automated means is</span><br><span class="line"># prohibited unless you have express written permission from Facebook</span><br><span class="line"># and may only be conducted for the limited purpose contained in said</span><br><span class="line"># permission.</span><br><span class="line"># See: http:&#x2F;&#x2F;www.facebook.com&#x2F;apps&#x2F;site_scraping_tos_terms.php</span><br><span class="line"></span><br><span class="line">User-agent: Applebot</span><br><span class="line">Disallow: &#x2F;ajax&#x2F;</span><br><span class="line">Disallow: &#x2F;album.php</span><br><span class="line">Disallow: &#x2F;checkpoint&#x2F;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">User-agent: Googlebot</span><br><span class="line">Disallow: &#x2F;ajax&#x2F;</span><br><span class="line">Disallow: &#x2F;album.php</span><br><span class="line">Disallow: &#x2F;checkpoint&#x2F;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">User-agent: Applebot</span><br><span class="line">Allow: &#x2F;ajax&#x2F;bootloader-endpoint&#x2F;</span><br><span class="line">Allow: &#x2F;ajax&#x2F;pagelet&#x2F;generic.php&#x2F;PagePostsSectionPagelet</span><br><span class="line">Allow: &#x2F;careers&#x2F;</span><br><span class="line">Allow: &#x2F;safetycheck&#x2F;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">User-agent: Googlebot</span><br><span class="line">Allow: &#x2F;*&#x2F;videos&#x2F;</span><br><span class="line">Allow: &#x2F;ajax&#x2F;bootloader-endpoint&#x2F;</span><br><span class="line">Allow: &#x2F;ajax&#x2F;pagelet&#x2F;generic.php&#x2F;PagePostsSectionPagelet</span><br><span class="line">Allow: &#x2F;careers&#x2F;</span><br><span class="line">Allow: &#x2F;safetycheck&#x2F;</span><br><span class="line">Allow: &#x2F;watch</span><br><span class="line">......</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="the-why’s-and-when’s-of-web-scraping"><a href="#the-why’s-and-when’s-of-web-scraping" class="headerlink" title="the why’s and when’s of web scraping"></a>the why’s and when’s of web scraping</h4><ul>
<li><p>Why web scraping?</p>
<ul>
<li>Data analysis<br>  Data analysis relies 100% on a large amount of data(datasets).<br>  The more data you have the more accurate your data analysis will be.</li>
<li>Machine learning<br>  Machine learning requires a huge amount of data.<br>  The more data you have the more your system can learn.</li>
</ul>
<p>	</p>
</li>
<li><p>Why web scrapy</p>
<ul>
<li>Lead generation</li>
<li>Real estate listings</li>
<li>Price Monitoring</li>
<li>Stock marking tracking</li>
<li>Drop shipping</li>
</ul>
</li>
<li><p>When to&#x2F;not use web scraping</p>
<ul>
<li>Terms of service &amp; the Robots.txt?</li>
<li>Does the website have a public API?</li>
<li>Does the API have any limitations?</li>
<li>Does the API provide all the data you want?</li>
<li>Is the API free&#x2F;paid?</li>
</ul>
</li>
</ul>
<h4 id="scrapy-sider-templates"><a href="#scrapy-sider-templates" class="headerlink" title="scrapy sider templates"></a>scrapy sider templates</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy genspider -l</span><br><span class="line">Available templates:</span><br><span class="line">  basic</span><br><span class="line">  crawl</span><br><span class="line">  csvfeed</span><br><span class="line">  xmlfeed</span><br></pre></td></tr></table></figure>

<h3 id="command"><a href="#command" class="headerlink" title="command"></a>command</h3><h4 id="install-scrapy"><a href="#install-scrapy" class="headerlink" title="install scrapy"></a>install scrapy</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python 3.11 有問題, python 3.10 ok</span></span><br><span class="line"><span class="comment"># install myenv10_scrapy</span></span><br><span class="line">rem <span class="built_in">cd</span> \app\python_env\</span><br><span class="line"><span class="comment"># install scrapy version 1.7.1</span></span><br><span class="line">rem pip install scrapy scrapy==1.7.1                                      </span><br><span class="line">rem py -3.10 -m virtualenv myenv10_scrapy</span><br><span class="line"><span class="comment"># install </span></span><br><span class="line">pip install scrapy </span><br><span class="line">pip install pylint </span><br><span class="line">pip install autopep8</span><br><span class="line">pip install ipython</span><br></pre></td></tr></table></figure>

<h4 id="install-pymongo-amp-dnspython-for-MongoDB"><a href="#install-pymongo-amp-dnspython-for-MongoDB" class="headerlink" title="install pymongo &amp; dnspython(for MongoDB)"></a>install pymongo &amp; dnspython(for MongoDB)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pymongo dnspython</span><br></pre></td></tr></table></figure>

<h4 id="install-scrapy-by-conda"><a href="#install-scrapy-by-conda" class="headerlink" title="install scrapy by conda"></a>install scrapy by conda</h4><h5 id="insatll-scrapy"><a href="#insatll-scrapy" class="headerlink" title="insatll scrapy"></a>insatll scrapy</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Anaconda download</span></span><br><span class="line"><span class="comment"># install virtual machine</span></span><br><span class="line"><span class="comment"># install scrapy</span></span><br><span class="line">(virtual_3_7_spider) C:\Users\robertkao&gt;conda install -c conda-forge scrapy==1.6 pylint autopep8 -y</span><br><span class="line"><span class="comment"># check version</span></span><br><span class="line">(virtual_3_7_spider) C:\Users\robertkao&gt;scrapy</span><br><span class="line"><span class="comment"># test scrapy shell</span></span><br><span class="line">scrapy shell</span><br><span class="line"><span class="comment"># found error : ImportError: cannot import name &#x27;HTTPClientFactory&#x27; from &#x27;twisted.web.client&#x27; (unknown location)</span></span><br><span class="line"><span class="comment"># change twisted version from 22.4.0 to 21.7.0 solved the problem</span></span><br><span class="line">conda uninstall twisted</span><br><span class="line">conda install twisted==21.7.0 -y</span><br><span class="line"><span class="comment"># test scrapy shell ok</span></span><br><span class="line">scrapy shell</span><br></pre></td></tr></table></figure>

<h5 id="once-scrapy-parse-ok-but-doesn’t-know-Why"><a href="#once-scrapy-parse-ok-but-doesn’t-know-Why" class="headerlink" title="once scrapy parse ok - but doesn’t know Why?"></a>once scrapy parse ok - but doesn’t know Why?</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">PS D:\work\run\python_crawler\102-conda\worldometers&gt; scrapy parse --spider=countries -c parse_country --meta=<span class="string">&#x27;&#123;\&quot;country_name\&quot; : \&quot;China\&quot;&#125;&#x27;</span> https://www.worldometers.info/world-population/china-population/</span><br><span class="line">2022-12-16 16:16:28 [scrapy.utils.log] INFO: Scrapy 2.6.2 started (bot: worldometers)</span><br><span class="line">2022-12-16 16:16:28 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.2.0, Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1s  1 Nov 2022), cryptography 37.0.1, Platform Windows-10-10.0.19044-SP0</span><br><span class="line">2022-12-16 16:16:28 [scrapy.crawler] INFO: Overridden settings:</span><br><span class="line">&#123;<span class="string">&#x27;BOT_NAME&#x27;</span>: <span class="string">&#x27;worldometers&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;NEWSPIDER_MODULE&#x27;</span>: <span class="string">&#x27;worldometers.spiders&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ROBOTSTXT_OBEY&#x27;</span>: True,</span><br><span class="line"> <span class="string">&#x27;SPIDER_MODULES&#x27;</span>: [<span class="string">&#x27;worldometers.spiders&#x27;</span>]&#125;</span><br><span class="line">2022-12-16 16:16:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor</span><br><span class="line">2022-12-16 16:16:28 [scrapy.extensions.telnet] INFO: Telnet Password: 446a57845c238b66</span><br><span class="line">2022-12-16 16:16:28 [scrapy.middleware] INFO: Enabled extensions:</span><br><span class="line">[<span class="string">&#x27;scrapy.extensions.corestats.CoreStats&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.extensions.telnet.TelnetConsole&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.extensions.logstats.LogStats&#x27;</span>]</span><br><span class="line">2022-12-16 16:16:28 [scrapy.middleware] INFO: Enabled downloader middlewares:</span><br><span class="line">[<span class="string">&#x27;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.retry.RetryMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.downloadermiddlewares.stats.DownloaderStats&#x27;</span>]</span><br><span class="line">2022-12-16 16:16:28 [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">[<span class="string">&#x27;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.spidermiddlewares.referer.RefererMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scrapy.spidermiddlewares.depth.DepthMiddleware&#x27;</span>]</span><br><span class="line">2022-12-16 16:16:28 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[]</span><br><span class="line">2022-12-16 16:16:28 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2022-12-16 16:16:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</span><br><span class="line">2022-12-16 16:16:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024</span><br><span class="line">2022-12-16 16:16:29 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET https://www.worldometers.info/robots.txt&gt; (referer: None)</span><br><span class="line">2022-12-16 16:16:29 [protego] DEBUG: Rule at line 2 without any user agent to enforce it on.</span><br><span class="line">2022-12-16 16:16:29 [protego] DEBUG: Rule at line 10 without any user agent to enforce it on.</span><br><span class="line">2022-12-16 16:16:29 [protego] DEBUG: Rule at line 12 without any user agent to enforce it on.</span><br><span class="line">2022-12-16 16:16:29 [protego] DEBUG: Rule at line 14 without any user agent to enforce it on.</span><br><span class="line">2022-12-16 16:16:29 [protego] DEBUG: Rule at line 16 without any user agent to enforce it on.</span><br><span class="line">2022-12-16 16:16:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.worldometers.info/world-population/china-population/&gt; (referer: None)</span><br><span class="line">2022-12-16 16:16:29 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">2022-12-16 16:16:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 494,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 2,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 2,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 13588,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 2,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/404&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 1.187387,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;finished&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 16, 8, 16, 29, 771491),</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_bytes&#x27;</span>: 67695,</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_count&#x27;</span>: 2,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 8,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 2,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/404&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 16, 8, 16, 28, 584104)&#125;</span><br><span class="line">2022-12-16 16:16:29 [scrapy.core.engine] INFO: Spider closed (finished)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;</span><br><span class="line"><span class="comment"># Scraped Items  ------------------------------------------------------------</span></span><br><span class="line">[&#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,439,323,776&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2020&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,433,783,686&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2019&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,427,647,786&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2018&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,421,021,791&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2017&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,414,049,351&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2016&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,406,847,870&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2015&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,368,810,615&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2010&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,330,776,380&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2005&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,290,550,765&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2000&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,240,920,535&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1995&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,176,883,674&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1990&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,075,589,361&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1985&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;1,000,089,235&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1980&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;926,240,885&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1975&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;827,601,394&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1970&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;724,218,968&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1965&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;660,408,056&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1960&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>, <span class="string">&#x27;population&#x27;</span>: <span class="string">&#x27;612,241,554&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1955&#x27;</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Requests  -----------------------------------------------------------------</span></span><br><span class="line">[]</span><br><span class="line"></span><br><span class="line">PS D:\work\run\python_crawler\102-conda\worldometers&gt; </span><br></pre></td></tr></table></figure>

<h4 id="create-project"><a href="#create-project" class="headerlink" title="create project"></a>create project</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject glassesshop</span><br><span class="line">New Scrapy project <span class="string">&#x27;glassesshop&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\glassesshop</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> glassesshop</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure>

<h4 id="create-spider"><a href="#create-spider" class="headerlink" title="create spider"></a>create spider</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> glassesshop</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\glassesshop&gt;scrapy genspider products https://www.glassesshop.com/bestsellers</span><br><span class="line">Created spider <span class="string">&#x27;products&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  glassesshop.spiders.products</span><br></pre></td></tr></table></figure>

<h4 id="create-spider-crawl-template"><a href="#create-spider-crawl-template" class="headerlink" title="create spider(crawl template)"></a>create spider(crawl template)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> imdb</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy genspider -t crawl best_movies imdb.com</span><br><span class="line">Created spider <span class="string">&#x27;best_movies&#x27;</span> using template <span class="string">&#x27;crawl&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  imdb.spiders.best_movies</span><br></pre></td></tr></table></figure>

<h4 id="run"><a href="#run" class="headerlink" title="run"></a>run</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line"></span><br><span class="line"><span class="comment"># no show log</span></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_downloader&gt;scrapy crawl mp3_downloader --nolog</span><br><span class="line"></span><br><span class="line"><span class="comment"># show warning</span></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_downloader&gt;scrapy crawl mp3_downloader -L WARN</span><br></pre></td></tr></table></figure>

<h4 id="data-generate-by-dataset-json-csv-xml"><a href="#data-generate-by-dataset-json-csv-xml" class="headerlink" title="data generate by dataset(json, csv, xml)"></a>data generate by dataset(json, csv, xml)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate json file</span></span><br><span class="line">scrapy crawl countries -o population_dataset.json</span><br><span class="line"><span class="comment"># generate csv file</span></span><br><span class="line">scrapy crawl countries -o population_dataset.csv</span><br><span class="line"><span class="comment"># generate xml file</span></span><br><span class="line">scrapy crawl countries -o population_dataset.xml</span><br></pre></td></tr></table></figure>

<h3 id="manual-control"><a href="#manual-control" class="headerlink" title="manual control"></a>manual control</h3><h4 id="version-amp-help"><a href="#version-amp-help" class="headerlink" title="version &amp; help"></a>version &amp; help</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler&gt;scrapy</span><br><span class="line">......</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x0000025B9E971C00&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x0000025B9E973340&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update <span class="built_in">local</span> objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update <span class="built_in">local</span> objects</span><br><span class="line">[s]   shelp()           Shell <span class="built_in">help</span> (<span class="built_in">print</span> this <span class="built_in">help</span>)</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> a browser</span><br><span class="line">2022-12-15 13:47:24 [asyncio] DEBUG: Using proactor: IocpProactor</span><br><span class="line">In [1]: fetch(<span class="string">&quot;https://www.worldometers.info/world-population/population-by-cou</span></span><br><span class="line"><span class="string">   ...: ntry&quot;</span>)</span><br><span class="line">2022-12-15 13:47:32 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2022-12-15 13:47:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to &lt;GET https://www.worldometers.info/world-population/population-by-country/&gt; from &lt;GET https://www.worldometers.info/world-population/population-by-country&gt;</span><br><span class="line">2022-12-15 13:47:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.worldometers.info/world-population/population-by-country/&gt; (referer: None)</span><br><span class="line"></span><br><span class="line">In [2]: title = response.xpath(<span class="string">&quot;//h1/text()&quot;</span>)</span><br><span class="line"></span><br><span class="line">In [3]: title</span><br><span class="line">Out[3]: [&lt;Selector xpath=<span class="string">&#x27;//h1/text()&#x27;</span> data=<span class="string">&#x27;Countries in the world by population ...&#x27;</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [4]: title.get()</span><br><span class="line">Out[4]: <span class="string">&#x27;Countries in the world by population (2022)&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="shell-get-url"><a href="#shell-get-url" class="headerlink" title="shell get url"></a>shell get url</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;</span><br><span class="line">scrapy shell <span class="string">&quot;https://www.worldometers.info/world-population/population-by-country/&quot;</span></span><br><span class="line">2022-12-09 12:24:35 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">[s]   shelp()           Shell <span class="built_in">help</span> (<span class="built_in">print</span> this <span class="built_in">help</span>)</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> a browser</span><br><span class="line">2022-12-09 12:24:37 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line">In [1]:</span><br><span class="line"></span><br><span class="line">In [1]: countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line"></span><br><span class="line">In [2]: countries</span><br><span class="line">Out[2]:</span><br><span class="line">[&lt;Selector xpath=<span class="string">&#x27;//td/a&#x27;</span> data=<span class="string">&#x27;&lt;a href=&quot;/world-population/china-popu...&#x27;</span>&gt;,</span><br><span class="line"> &lt;Selector xpath=<span class="string">&#x27;//td/a&#x27;</span> data=<span class="string">&#x27;&lt;a href=&quot;/world-population/india-popu...&#x27;</span>&gt;,</span><br><span class="line"> ......</span><br><span class="line"> &lt;Selector xpath=<span class="string">&#x27;//td/a&#x27;</span> data=<span class="string">&#x27;&lt;a href=&quot;/world-population/tokelau-po...&#x27;</span>&gt;,</span><br><span class="line"> &lt;Selector xpath=<span class="string">&#x27;//td/a&#x27;</span> data=<span class="string">&#x27;&lt;a href=&quot;/world-population/holy-see-p...&#x27;</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [3]:</span><br></pre></td></tr></table></figure>

<h4 id="fetch-and-view"><a href="#fetch-and-view" class="headerlink" title="fetch and view"></a>fetch and view</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler&gt;scrapy shell</span><br><span class="line">......</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x000002AD58F421A0&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x000002AD58F43AF0&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update <span class="built_in">local</span> objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update <span class="built_in">local</span> objects</span><br><span class="line">[s]   shelp()           Shell <span class="built_in">help</span> (<span class="built_in">print</span> this <span class="built_in">help</span>)</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> a browser</span><br><span class="line">2022-12-15 14:02:50 [asyncio] DEBUG: Using proactor: IocpProactor</span><br><span class="line">In [1]: fetch(<span class="string">&quot;https://www.worldometers.info/world-population/population-by-cou</span></span><br><span class="line"><span class="string">   ...: ntry&quot;</span>)</span><br><span class="line">2022-12-15 14:02:57 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2022-12-15 14:02:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to &lt;GET https://www.worldometers.info/world-population/population-by-country/&gt; from &lt;GET https://www.worldometers.info/world-population/population-by-country&gt;</span><br><span class="line">2022-12-15 14:02:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.worldometers.info/world-population/population-by-country/&gt; (referer: None)</span><br><span class="line"></span><br><span class="line">In [2]: title = response.xpath(<span class="string">&quot;//h1/text()&quot;</span>)</span><br><span class="line"></span><br><span class="line">In [3]: title</span><br><span class="line">Out[3]: [&lt;Selector xpath=<span class="string">&#x27;//h1/text()&#x27;</span> data=<span class="string">&#x27;Countries in the world by population ...&#x27;</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [4]: title.get()</span><br><span class="line">Out[4]: <span class="string">&#x27;Countries in the world by population (2022)&#x27;</span></span><br><span class="line"></span><br><span class="line">In [5]: view(response)</span><br><span class="line">Out[5]: True</span><br></pre></td></tr></table></figure>


<h3 id="Packages"><a href="#Packages" class="headerlink" title="Packages"></a>Packages</h3><h4 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.selector <span class="keyword">import</span> Selector</span><br><span class="line"></span><br><span class="line"><span class="comment"># process from GET(json format)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    resp_dict = json.loads(response.body)</span><br><span class="line">    html = resp_dict.get(<span class="string">&#x27;d&#x27;</span>).get(<span class="string">&#x27;Result&#x27;</span>).get(<span class="string">&#x27;html&#x27;</span>)</span><br><span class="line">    sel = Selector(text=html)</span><br><span class="line">    listings = sel.xpath(<span class="string">&quot;//div[@class=&#x27;shell&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print html or write to file</span></span><br><span class="line">    <span class="built_in">print</span>(html)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=====================&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;index.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(html)</span><br></pre></td></tr></table></figure>

<h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a>settings.py</h3><h4 id="set-JSON-utf-8-format"><a href="#set-JSON-utf-8-format" class="headerlink" title="set JSON utf-8 format"></a>set JSON utf-8 format</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set JSON utf-8 format</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">&#x27;utf-8&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="set-close-scrapy-for-item-count"><a href="#set-close-scrapy-for-item-count" class="headerlink" title="set close scrapy for item count"></a>set close scrapy for item count</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLOSESPIDER_ITEMCOUNT = <span class="number">100</span></span><br></pre></td></tr></table></figure>


<h4 id="set-User-Agent-2-way"><a href="#set-User-Agent-2-way" class="headerlink" title="set User-Agent(2 way)"></a>set User-Agent(2 way)</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line"><span class="comment">#USER_AGENT = &#x27;tinydeal (+http://www.yourdomain.com)&#x27;</span></span><br><span class="line"><span class="comment"># change user agent</span></span><br><span class="line">USER_AGENT = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Override the default request headers:</span></span><br><span class="line"><span class="comment">#DEFAULT_REQUEST_HEADERS = &#123;</span></span><br><span class="line"><span class="comment">#   &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;Accept-Language&#x27;: &#x27;en&#x27;,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"><span class="comment"># change default heads</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">  <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="save-Scrapy-crawl-Command-output"><a href="#save-Scrapy-crawl-Command-output" class="headerlink" title="save Scrapy crawl Command output"></a>save Scrapy crawl Command output</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LOG_STDOUT &#x3D; True</span><br><span class="line">LOG_FILE &#x3D; &#39;scrapy_output.txt&#39;</span><br></pre></td></tr></table></figure>

<h3 id="coding"><a href="#coding" class="headerlink" title="coding"></a>coding</h3><h4 id="starting-spider-py"><a href="#starting-spider-py" class="headerlink" title="starting spider .py"></a>starting spider .py</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul[@class=&quot;productlisting-ul&quot;]/div/li&#x27;</span>):</span><br><span class="line">          <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span> : product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/text()&#x27;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;url&#x27;</span> : response.urljoin(product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/@href&#x27;</span>).get()),</span><br><span class="line">            <span class="string">&#x27;discounted_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[1]/text()&#x27;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;original_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[2]/text()&#x27;</span>).get()</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure>

<h4 id="bsolute-url"><a href="#bsolute-url" class="headerlink" title="bsolute url"></a>bsolute url</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># absolute url</span></span><br><span class="line"><span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">absolute_url = response.urljoin(link)</span><br><span class="line"><span class="keyword">yield</span> scrapy.Request(url=absolute_url)</span><br></pre></td></tr></table></figure>

<h4 id="relative-url"><a href="#relative-url" class="headerlink" title="relative url"></a>relative url</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># relative url</span></span><br><span class="line"><span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country)</span><br></pre></td></tr></table></figure>

<h4 id="add-meta-for-callback-parameter"><a href="#add-meta-for-callback-parameter" class="headerlink" title="add meta for callback parameter"></a>add meta for callback parameter</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">      name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">      link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="comment"># add meta for callback parameter</span></span><br><span class="line">      <span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country, meta=&#123;<span class="string">&#x27;country_name&#x27;</span>: name&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    name = response.request.meta[<span class="string">&#x27;country_name&#x27;</span>]</span><br><span class="line">    rows = response.xpath(<span class="string">&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">      year = row.xpath(<span class="string">&quot;./td[1]/text()&quot;</span>).get()</span><br><span class="line">      population = row.xpath(<span class="string">&quot;./td[2]/strong/text()&quot;</span>).get()</span><br><span class="line">      <span class="keyword">yield</span> &#123;</span><br><span class="line">        <span class="string">&#x27;country_name&#x27;</span> : name,</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span> : year,</span><br><span class="line">        <span class="string">&#x27;population&#x27;</span>: population</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<h4 id="dealing-with-pagination"><a href="#dealing-with-pagination" class="headerlink" title="dealing with pagination"></a>dealing with pagination</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul[@class=&quot;productlisting-ul&quot;]/div/li&#x27;</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span> : product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;url&#x27;</span> : response.urljoin(product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/@href&#x27;</span>).get()),</span><br><span class="line">                <span class="string">&#x27;discounted_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[1]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;original_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[2]/text()&#x27;</span>).get()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.xpath(<span class="string">&#x27;//a[@class=&quot;nextPage&quot;]/@href&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>

<h4 id="add-headers"><a href="#add-headers" class="headerlink" title="add headers"></a>add headers</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># change user agent</span></span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>, callback=self.parse, headers=&#123;</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul[@class=&quot;productlisting-ul&quot;]/div/li&#x27;</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span>: product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;url&#x27;</span>: response.urljoin(product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/@href&#x27;</span>).get()),</span><br><span class="line">                <span class="string">&#x27;discounted_price&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[1]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;original_price&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[2]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="comment"># show response.request User-Agent</span></span><br><span class="line">                <span class="string">&#x27;User-Agent&#x27;</span>: response.request.headers[<span class="string">&#x27;User-Agent&#x27;</span>]</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.xpath(<span class="string">&#x27;//a[@class=&quot;nextPage&quot;]/@href&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            <span class="comment"># change user agent</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=next_page, callback=self.parse, headers=&#123;</span><br><span class="line">                <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure>

<h4 id="add-headers-crawl-template"><a href="#add-headers-crawl-template" class="headerlink" title="add headers(crawl template)"></a>add headers(crawl template)</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># best_movies.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BestMoviesSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;best_movies&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;imdb.com&#x27;</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># change user agent</span></span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;]</span></span><br><span class="line">    user_agent = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=<span class="string">&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;</span>, headers=&#123;</span><br><span class="line">        	<span class="string">&#x27;User-Agent&#x27;</span>: self.user_agent</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;//h3[@class=&#x27;lister-item-header&#x27;]/a&quot;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>, process_request=<span class="string">&#x27;set_user_agent&#x27;</span>),</span><br><span class="line">		<span class="comment"># add next page rule</span></span><br><span class="line">		Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;(//a[@class=&#x27;lister-page-next next-page&#x27;])[2]&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment"># for scrappier 2.0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_user_agent</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = self.user_agent</span><br><span class="line">        <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;sc-80d4314-1 fbQftq&#x27;]/h1/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;year&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;sc-8c396aa2-2 itZqyK&#x27;]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;&#x27;</span>.join(response.xpath(<span class="string">&quot;//ul[@class=&#x27;ipc-inline-list ipc-inline-list--show-dividers sc-8c396aa2-0 kqWovI baseAlt&#x27;]/li[3]/text()&quot;</span>).getall()),</span><br><span class="line">            <span class="string">&#x27;genre&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;ipc-chip-list__scroller&#x27;]/a/span/text()&quot;</span>).getall(),</span><br><span class="line">            <span class="string">&#x27;rating&#x27;</span>: response.xpath(<span class="string">&quot;//div[@data-testid=&#x27;hero-rating-bar__aggregate-rating__score&#x27;]/span[1]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;movie_url&#x27;</span>: response.url,</span><br><span class="line">            <span class="string">&#x27;user-agent&#x27;</span>: response.request.headers[<span class="string">&#x27;User-Agent&#x27;</span>]</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="fake-useragent"><a href="#fake-useragent" class="headerlink" title="fake_useragent"></a>fake_useragent</h4><h5 id="settings-py-1"><a href="#settings-py-1" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#DOWNLOADER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;ithome2.middlewares.Ithome2DownloaderMiddleware&#x27;: 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">&#x27;ithome2.middlewares.Item2AgentMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="middlewares-py"><a href="#middlewares-py" class="headerlink" title="middlewares.py"></a>middlewares.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add user agent</span></span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Item2AgentMiddleware</span>(<span class="params">UserAgentMiddleware</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, user_agent=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        self.user_agent = user_agent</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = ua.random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self, request, response, spider</span>):</span></span><br><span class="line">        <span class="comment"># log test</span></span><br><span class="line">        spider.logger.info(<span class="string">f&#x27;Item2AgentMiddleware-process_response User-Agent of [<span class="subst">&#123;request.url&#125;</span>] is [<span class="subst">&#123;request.headers[<span class="string">&quot;User-Agent&quot;</span>]&#125;</span>]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>

<h4 id="output-2-json-files-by-coding"><a href="#output-2-json-files-by-coding" class="headerlink" title="output 2 json files(by coding)"></a>output 2 json files(by coding)</h4><h5 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py"></a>pipelines.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> ithome2.items <span class="keyword">as</span> items</span><br><span class="line"><span class="keyword">import</span> ithome2.env <span class="keyword">as</span> env</span><br><span class="line"><span class="comment"># save item to json</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ithome2Pipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(item).__name__ == <span class="string">&#x27;IthomeArticleItem&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> item[<span class="string">&#x27;view_count&#x27;</span>] &lt; <span class="number">100</span>:</span><br><span class="line">                <span class="keyword">raise</span> DropItem(<span class="string">f&#x27;[<span class="subst">&#123;item[<span class="string">&quot;title&quot;</span>]&#125;</span>] 瀏覽數小於 100&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPipeline</span>:</span></span><br><span class="line">    collection_article = <span class="string">&#x27;articles&#x27;</span></span><br><span class="line">    collection_response = <span class="string">&#x27;response&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        dbname = <span class="string">&#x27;ithome2&#x27;</span></span><br><span class="line">        user = env.MONGO_USER</span><br><span class="line">        password = env.MONGO_PASSWORD</span><br><span class="line">        host = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">        port =  <span class="number">27017</span></span><br><span class="line">        MONGO_URI = <span class="string">f&#x27;mongodb://<span class="subst">&#123;user&#125;</span>:<span class="subst">&#123;password&#125;</span>@<span class="subst">&#123;host&#125;</span>:<span class="subst">&#123;port&#125;</span>/&#x27;</span></span><br><span class="line">        self.client = MongoClient(MONGO_URI)</span><br><span class="line">        self.db = self.client[dbname]</span><br><span class="line">        <span class="comment"># save item to json</span></span><br><span class="line">        self.file1 = <span class="built_in">open</span>(<span class="string">&#x27;art.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        self.file2 = <span class="built_in">open</span>(<span class="string">&#x27;resp.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        self.file1.write(<span class="string">&#x27;[\n&#x27;</span>)</span><br><span class="line">        self.file2.write(<span class="string">&#x27;[\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.client.close()</span><br><span class="line">        <span class="comment"># save item to json</span></span><br><span class="line">        self.file1.write(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">        self.file2.write(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">        self.file1.close()</span><br><span class="line">        self.file2.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment"># if type(item).__name__ == &#x27;IthomeArticleItem&#x27;:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(item) <span class="keyword">is</span> items.IthomeArticleItem:</span><br><span class="line">            <span class="comment"># 查詢資料庫中是否有相同網址的資料存在</span></span><br><span class="line">            doc = self.db[self.collection_article].find_one(&#123;<span class="string">&#x27;url&#x27;</span>: item[<span class="string">&#x27;url&#x27;</span>]&#125;)</span><br><span class="line">            item[<span class="string">&#x27;update_time&#x27;</span>] = datetime.now()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> doc:</span><br><span class="line">                <span class="comment"># 沒有就新增</span></span><br><span class="line">                item[<span class="string">&#x27;_id&#x27;</span>] = <span class="built_in">str</span>(self.db[self.collection_article].insert_one(<span class="built_in">dict</span>(item)).inserted_id)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 已存在則更新</span></span><br><span class="line">                self.db[self.collection_article].update_one(</span><br><span class="line">                    &#123;<span class="string">&#x27;_id&#x27;</span>: doc[<span class="string">&#x27;_id&#x27;</span>]&#125;,</span><br><span class="line">                    &#123;<span class="string">&#x27;$set&#x27;</span>: <span class="built_in">dict</span>(item)&#125;</span><br><span class="line">                )</span><br><span class="line">                item[<span class="string">&#x27;_id&#x27;</span>] = <span class="built_in">str</span>(doc[<span class="string">&#x27;_id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># save item to json</span></span><br><span class="line">            values = <span class="built_in">dict</span>(item)</span><br><span class="line">            values[<span class="string">&#x27;update_time&#x27;</span>] = values[<span class="string">&#x27;update_time&#x27;</span>].strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">            line = json.dumps(values, ensure_ascii=<span class="literal">False</span>) + <span class="string">&quot;,\n&quot;</span></span><br><span class="line">            self.file1.write(line)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if type(item).__name__ == &#x27;IthomeReplyItem&#x27;:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(item) <span class="keyword">is</span> items.IthomeReplyItem:</span><br><span class="line">            <span class="comment"># save item to json</span></span><br><span class="line">            values = <span class="built_in">dict</span>(item)</span><br><span class="line">            <span class="keyword">del</span> values[<span class="string">&#x27;_id&#x27;</span>]</span><br><span class="line">            values[<span class="string">&#x27;publish_time&#x27;</span>] = values[<span class="string">&#x27;publish_time&#x27;</span>].strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">            values[<span class="string">&#x27;article_id&#x27;</span>] = <span class="built_in">str</span>(values[<span class="string">&#x27;article_id&#x27;</span>])</span><br><span class="line">            line = json.dumps(values, ensure_ascii=<span class="literal">False</span>) + <span class="string">&quot;,\n&quot;</span></span><br><span class="line">            self.file2.write(line)</span><br><span class="line"></span><br><span class="line">            document = self.db[self.collection_response].find_one(item[<span class="string">&#x27;_id&#x27;</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> document:</span><br><span class="line">                insert_result = self.db[self.collection_response].insert_one(<span class="built_in">dict</span>(item))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">del</span> item[<span class="string">&#x27;_id&#x27;</span>]</span><br><span class="line">                self.db[self.collection_response].update_one(</span><br><span class="line">                    &#123;<span class="string">&#x27;_id&#x27;</span>: document[<span class="string">&#x27;_id&#x27;</span>]&#125;,</span><br><span class="line">                    &#123;<span class="string">&#x27;$set&#x27;</span>: <span class="built_in">dict</span>(item)&#125;,</span><br><span class="line">                    upsert=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h3 id="Pipelines"><a href="#Pipelines" class="headerlink" title="Pipelines"></a>Pipelines</h3><h4 id="enabel-pipelines"><a href="#enabel-pipelines" class="headerlink" title="enabel pipelines"></a>enabel pipelines</h4><ul>
<li>add log at open_spider and close_spider</li>
<li>get setting value</li>
</ul>
<h5 id="settings-py-2"><a href="#settings-py-2" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="comment"># enable pipleline</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;imdb.pipelines.ImdbPipeline&#x27;</span>: <span class="number">300</span></span><br><span class="line">   <span class="comment"># if add filter, need have higher pripority</span></span><br><span class="line">   <span class="comment"># &#x27;imdb.pipelines.FillterDuplicate&#x27;: 100,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MONGO_URL = <span class="string">&quot;Hello World&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="pipelines-py-1"><a href="#pipelines-py-1" class="headerlink" title="pipelines.py"></a>pipelines.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="comment"># add loggin to open_spider and close_spider</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImdbPipeline</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add get setting value</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        logging.warning(crawler.settings.get(<span class="string">&quot;MONGO_URL&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> cls()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add loggin to open_spider and close_spider</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        logging.warning(<span class="string">&quot;SPIDER OPEND FROM PIPLINE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add loggin to open_spider and close_spider</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        logging.warning(<span class="string">&quot;SPIDER CLOSE FROM PIPLINE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h5 id="run-1"><a href="#run-1" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br><span class="line">......</span><br><span class="line"><span class="comment"># get setting value</span></span><br><span class="line">2022-12-27 13:54:48 [root] WARNING: Hello World</span><br><span class="line">2022-12-27 13:54:48 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[<span class="string">&#x27;imdb.pipelines.ImdbPipeline&#x27;</span>]</span><br><span class="line">2022-12-27 13:54:48 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line"><span class="comment"># open spider</span></span><br><span class="line">2022-12-27 13:54:48 [root] WARNING: SPIDER OPEND FROM PIPLINE</span><br><span class="line">......</span><br><span class="line">2022-12-27 13:55:29 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line"><span class="comment"># close spider</span></span><br><span class="line">2022-12-27 13:55:29 [root] WARNING: SPIDER CLOSE FROM PIPLINE</span><br><span class="line">2022-12-27 13:55:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="Store-data-in-MongoDB"><a href="#Store-data-in-MongoDB" class="headerlink" title="Store data in MongoDB"></a>Store data in MongoDB</h4><h5 id="pipelines-py-2"><a href="#pipelines-py-2" class="headerlink" title="pipelines.py"></a>pipelines.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="comment"># for MongoDB</span></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"></span><br><span class="line"><span class="comment"># for MongoDB - changhe name</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongodbPipeline</span>:</span></span><br><span class="line">    collection_name = <span class="string">&quot;best_movies&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="comment"># for MongoDB</span></span><br><span class="line">        self.client = pymongo.MongoClient(<span class="string">&quot;mongodb+srv://robert:testtest@cluster0.vpuxrtz.mongodb.net/?retryWrites=true&amp;w=majority&quot;</span>)</span><br><span class="line">        self.db = self.client[<span class="string">&quot;IMDB&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="comment"># for MongoDB</span></span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment"># for MongoDB</span></span><br><span class="line">        self.db[self.collection_name].insert_one(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h5 id="settings-py-3"><a href="#settings-py-3" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="comment"># enable pipleline - for MongoDB</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;imdb.pipelines.MongodbPipeline&#x27;</span>: <span class="number">300</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-2"><a href="#run-2" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br></pre></td></tr></table></figure>

<h5 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h5><div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic13.png" class="" title="pic13">
</div>


<h4 id="Store-data-in-SQLite3"><a href="#Store-data-in-SQLite3" class="headerlink" title="Store data in SQLite3"></a>Store data in SQLite3</h4><h5 id="pipelines-py-3"><a href="#pipelines-py-3" class="headerlink" title="pipelines.py"></a>pipelines.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="comment"># for MongoDB</span></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="comment"># for SQlite</span></span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="comment"># for mongodb client link</span></span><br><span class="line"><span class="keyword">import</span> mongodb_altas</span><br><span class="line"><span class="comment"># delete imdb if exist</span></span><br><span class="line"><span class="comment"># import os</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for MongoDB - changhe name</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongodbPipeline</span>:</span></span><br><span class="line">    collection_name = <span class="string">&quot;best_movies&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="comment"># for MongoDB</span></span><br><span class="line">        <span class="comment"># for mongodb client link</span></span><br><span class="line">        self.client = pymongo.MongoClient(mongodb_altas.mogodb_link)</span><br><span class="line">        self.db = self.client[<span class="string">&quot;IMDB&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="comment"># for MongoDB</span></span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment"># for MongoDB</span></span><br><span class="line">        self.db[self.collection_name].insert_one(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="comment"># for SQlite</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLitePipeline</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="comment"># delete imdb if exist</span></span><br><span class="line">        <span class="comment"># if os.path.exists(&quot;imdb.db&quot;):</span></span><br><span class="line">        <span class="comment">#     os.remove(&quot;imdb.db&quot;)</span></span><br><span class="line"></span><br><span class="line">        self.connection = sqlite3.connect(<span class="string">&quot;imdb.db&quot;</span>)</span><br><span class="line">        self.c = self.connection.cursor()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.c.execute(<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                CREATE TABLE best_movies(</span></span><br><span class="line"><span class="string">                    title TEXT,</span></span><br><span class="line"><span class="string">                    year TEXT,</span></span><br><span class="line"><span class="string">                    duration TEXT,</span></span><br><span class="line"><span class="string">                    genre TEXT,</span></span><br><span class="line"><span class="string">                    rating TEXT,</span></span><br><span class="line"><span class="string">                    movie_url TEXT</span></span><br><span class="line"><span class="string">                )</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span>)</span><br><span class="line">            self.connection.commit()</span><br><span class="line">        <span class="keyword">except</span> sqlite3.OperationalError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.connection.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        self.c.execute(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                INSERT INTO best_movies (title,year,duration,genre,rating,movie_url) values(?,?,?,?,?,?)</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span>,(</span><br><span class="line">                item.get(<span class="string">&#x27;title&#x27;</span>),</span><br><span class="line">                item.get(<span class="string">&#x27;year&#x27;</span>),</span><br><span class="line">                item.get(<span class="string">&#x27;duration&#x27;</span>),</span><br><span class="line">                <span class="string">&#x27;,&#x27;</span>.join(item.get(<span class="string">&#x27;genre&#x27;</span>)),</span><br><span class="line">                item.get(<span class="string">&#x27;rating&#x27;</span>),</span><br><span class="line">                item.get(<span class="string">&#x27;movie_url&#x27;</span>)</span><br><span class="line">            ))</span><br><span class="line">        self.connection.commit()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h5 id="settings-py-4"><a href="#settings-py-4" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="comment"># enable pipleline - for MongoDB</span></span><br><span class="line"><span class="comment"># ITEM_PIPELINES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;imdb.pipelines.MongodbPipeline&#x27;: 300</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"><span class="comment"># enable pipleline - for SQlite</span></span><br><span class="line"><span class="comment"># for SQlite</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;imdb.pipelines.SQLitePipeline&#x27;</span>: <span class="number">300</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-3"><a href="#run-3" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br></pre></td></tr></table></figure>

<h5 id="SQLite3"><a href="#SQLite3" class="headerlink" title="SQLite3"></a>SQLite3</h5><div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic14.png" class="" title="pic14">
</div>


<h3 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h3><h4 id="install-fake-useragent"><a href="#install-fake-useragent" class="headerlink" title="install fake-useragent"></a>install fake-useragent</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install fake-useragent</span><br></pre></td></tr></table></figure>

<h4 id="UserAgent"><a href="#UserAgent" class="headerlink" title="UserAgent"></a>UserAgent</h4><h5 id="settings-py-5"><a href="#settings-py-5" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#DOWNLOADER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;ithome2.middlewares.Ithome2DownloaderMiddleware&#x27;: 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">&#x27;ithome2.middlewares.Item2AgentMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="middlewares-py-1"><a href="#middlewares-py-1" class="headerlink" title="middlewares.py"></a>middlewares.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> is_item, ItemAdapter</span><br><span class="line"></span><br><span class="line"><span class="comment"># add user agent</span></span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Item2AgentMiddleware</span>(<span class="params">UserAgentMiddleware</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, user_agent=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        self.user_agent = user_agent</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = ua.random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self, request, response, spider</span>):</span></span><br><span class="line">        <span class="comment"># log test</span></span><br><span class="line">        spider.logger.info(<span class="string">f&#x27;Item2AgentMiddleware-process_response User-Agent of [<span class="subst">&#123;request.url&#125;</span>] is [<span class="subst">&#123;request.headers[<span class="string">&quot;User-Agent&quot;</span>]&#125;</span>]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>


<h3 id="Scrapy-API"><a href="#Scrapy-API" class="headerlink" title="Scrapy API"></a>Scrapy API</h3><h4 id="Quotes-to-Scrape"><a href="#Quotes-to-Scrape" class="headerlink" title="Quotes to Scrape"></a><a target="_blank" rel="noopener" href="http://quotes.toscrape.com/scroll">Quotes to Scrape</a></h4><h5 id="check-API-from-chrom"><a href="#check-API-from-chrom" class="headerlink" title="check API from chrom"></a>check API from chrom</h5><div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic15.png" class="" title="pic15">
</div>

<div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic16.png" class="" title="pic16">
</div>

<h5 id="create-project-and-spider"><a href="#create-project-and-spider" class="headerlink" title="create project and spider"></a>create project and spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject demo_api</span><br><span class="line">New Scrapy project <span class="string">&#x27;demo_api&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\demo_api</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> demo_api</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> demo_api</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_api&gt;scrapy genspider quotes quotes.toscrape.com</span><br><span class="line">Created spider <span class="string">&#x27;quotes&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_api.spiders.quotes</span><br></pre></td></tr></table></figure>

<h5 id="quotes-py"><a href="#quotes-py" class="headerlink" title="quotes.py"></a>quotes.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;quotes&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;quotes.toscrape.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://quotes.toscrape.com/api/quotes?page=1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># print(response.body)</span></span><br><span class="line">        resp = json.loads(response.body)</span><br><span class="line">        quotes = resp.get(<span class="string">&#x27;quotes&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(quotes)</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> quotes:</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;author&#x27;</span>: quote.get(<span class="string">&#x27;author&#x27;</span>).get(<span class="string">&#x27;name&#x27;</span>),</span><br><span class="line">                <span class="string">&#x27;tags&#x27;</span>: quote.get(<span class="string">&#x27;tags&#x27;</span>),</span><br><span class="line">                <span class="string">&#x27;quote_test&#x27;</span>: quote.get(<span class="string">&#x27;text&#x27;</span>)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        page_next = resp.get(<span class="string">&#x27;has_next&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> page_next:</span><br><span class="line">            next_page_number = resp.get(<span class="string">&#x27;page&#x27;</span>) + <span class="number">1</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                url=<span class="string">f&#x27;http://quotes.toscrape.com/api/quotes?page=<span class="subst">&#123;next_page_number&#125;</span>&#x27;</span>,</span><br><span class="line">                callback = self.parse</span><br><span class="line">            )</span><br></pre></td></tr></table></figure>

<h5 id="run-4"><a href="#run-4" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PS D:\work\run\python_crawler\101-scrapy\demo_api&gt; scrapy crawl quotes</span><br></pre></td></tr></table></figure>

<h4 id="OPEN-LIBRARY"><a href="#OPEN-LIBRARY" class="headerlink" title="OPEN LIBRARY"></a><a target="_blank" rel="noopener" href="https://openlibrary.org/subjects/picture_books">OPEN LIBRARY</a></h4><h5 id="check-API-from-chrome"><a href="#check-API-from-chrome" class="headerlink" title="check API from chrome"></a>check API from chrome</h5><div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic17.png" class="" title="pic17">
</div>

<div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic18.png" class="" title="pic18">
</div>

<div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic19.png" class="" title="pic19">
</div>

<div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic20.png" class="" title="pic20">
</div>

<h5 id="create-spider-1"><a href="#create-spider-1" class="headerlink" title="create spider"></a>create spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS D:\work\run\python_crawler\101-scrapy\demo_api&gt; scrapy genspider ebooks <span class="string">&quot;openlibrary.org/subjects/picture_books.json?limit=12&amp;offset=12&quot;</span></span><br><span class="line">Created spider <span class="string">&#x27;ebooks&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_api.spiders.ebooks</span><br></pre></td></tr></table></figure>

<h5 id="ebooks-py"><a href="#ebooks-py" class="headerlink" title="ebooks.py"></a>ebooks.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> CloseSpider</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EbookSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;ebooks&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;openlibrary.org&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://openlibrary.org/subjects/picture_books.json?limit=12&amp;offset=0&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    INCREMENT_BY = <span class="number">12</span></span><br><span class="line">    offset = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        resp = json.loads(response.body)</span><br><span class="line"></span><br><span class="line">        ebooks = resp.get(<span class="string">&#x27;works&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(ebooks)</span><br><span class="line">        <span class="keyword">for</span> ebook <span class="keyword">in</span> ebooks:</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span>: ebook.get(<span class="string">&#x27;title&#x27;</span>),</span><br><span class="line">                <span class="string">&#x27;subject&#x27;</span>: ebook.get(<span class="string">&#x27;subject&#x27;</span>)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ebooks) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> CloseSpider(<span class="string">&quot;Reached last page...&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.offset  += self.INCREMENT_BY</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">            url=<span class="string">f&#x27;https://openlibrary.org/subjects/picture_books.json?limit=12&amp;offset=<span class="subst">&#123;self.offset&#125;</span>&#x27;</span>,</span><br><span class="line">            callback = self.parse</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<h5 id="run-5"><a href="#run-5" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">PS D:\work\run\python_crawler\101-scrapy\demo_api&gt; scrapy crawl ebooks</span><br><span class="line">.....</span><br><span class="line">2022-12-28 17:18:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://openlibrary.org/subjects/picture_books.json?<span class="built_in">limit</span>=12&amp;offset=15192&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;The red tractor&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: [<span class="string">&#x27;Juvenile fiction&#x27;</span>, <span class="string">&#x27;Farm life&#x27;</span>, <span class="string">&#x27;Picture books&#x27;</span>, <span class="string">&#x27;Fiction&#x27;</span>]&#125;</span><br><span class="line">2022-12-28 17:18:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://openlibrary.org/subjects/picture_books.json?<span class="built_in">limit</span>=12&amp;offset=15204&gt; (referer: https://openlibrary.org/subjects/picture_books.json?<span class="built_in">limit</span>=12&amp;offset=15192)</span><br><span class="line">[]</span><br><span class="line">2022-12-28 17:18:34 [scrapy.core.engine] INFO: Closing spider (Reached last page...)</span><br><span class="line">2022-12-28 17:18:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 1525,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 5,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 5,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 55307,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 5,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 5,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 3.215997,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;Reached last page...&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 28, 9, 18, 34, 167565),</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_bytes&#x27;</span>: 199,</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;item_scraped_count&#x27;</span>: 25,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 33,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;request_depth_max&#x27;</span>: 3,</span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 5,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/200&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 4,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 4,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 4,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 4,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 28, 9, 18, 30, 951568)&#125;</span><br><span class="line">2022-12-28 17:18:34 [scrapy.core.engine] INFO: Spider closed (Reached last page...)</span><br></pre></td></tr></table></figure>

<h3 id="Login-to-websites"><a href="#Login-to-websites" class="headerlink" title="Login to websites"></a>Login to websites</h3><h4 id="Quote-to-Scrape"><a href="#Quote-to-Scrape" class="headerlink" title="Quote to Scrape"></a><a target="_blank" rel="noopener" href="https://quotes.toscrape.com/login">Quote to Scrape</a></h4><h5 id="check-from-chrome"><a href="#check-from-chrome" class="headerlink" title="check from chrome"></a>check from chrome</h5><div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic21.png" class="" title="pic21">
</div>

<div style="max-width:700px">
    <img src="/2022/12/15/python-9/pic22.png" class="" title="pic22">
</div>

<h5 id="create-project-and-spider-1"><a href="#create-project-and-spider-1" class="headerlink" title="create project and spider"></a>create project and spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject demo_login</span><br><span class="line">New Scrapy project <span class="string">&#x27;demo_login&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\demo_login</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> demo_login</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> demo_login</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy genspider quotes_login quotes.toscrape.com/login</span><br><span class="line">Created spider <span class="string">&#x27;quotes_login&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_login.spiders.quotes_login</span><br></pre></td></tr></table></figure>

<h5 id="quotes-login-py"><a href="#quotes-login-py" class="headerlink" title="quotes_login.py"></a>quotes_login.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesLoginSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;quotes_login&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;quotes.toscrape.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://quotes.toscrape.com/login&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        csrf_token = response.xpath(<span class="string">&#x27;//input[@name=&quot;csrf_token&quot;]/@value&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">yield</span> FormRequest.from_response(</span><br><span class="line">            response,</span><br><span class="line">            <span class="comment"># no formxpath also ok</span></span><br><span class="line">            <span class="comment"># formxpath=&#x27;//form&#x27;,</span></span><br><span class="line">            formdata= &#123;</span><br><span class="line">                <span class="string">&#x27;csrf_token&#x27;</span>: csrf_token,</span><br><span class="line">                <span class="string">&#x27;username&#x27;</span>: <span class="string">&#x27;admin&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;admin&#x27;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            callback = self.after_login</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_login</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">if</span> response.xpath(<span class="string">&quot;//a[@href=&#x27;/logout&#x27;]&quot;</span>).get():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;logged in...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-6"><a href="#run-6" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy crawl quotes_login</span><br><span class="line">......</span><br><span class="line">2022-12-29 11:48:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to &lt;GET http://quotes.toscrape.com/&gt; from &lt;POST https://quotes.toscrape.com/login&gt;</span><br><span class="line">2022-12-29 11:48:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/&gt; (referer: None)</span><br><span class="line">logged <span class="keyword">in</span>...</span><br><span class="line">2022-12-29 11:48:34 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="Open-Library"><a href="#Open-Library" class="headerlink" title="Open Library"></a><a target="_blank" rel="noopener" href="https://openlibrary.org/account/login">Open Library</a></h4><h5 id="create-spider-2"><a href="#create-spider-2" class="headerlink" title="create spider"></a>create spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy genspider openlibrary_login openlibrary.org/account/login</span><br><span class="line">Created spider <span class="string">&#x27;openlibrary_login&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_login.spiders.openlibrary_login</span><br></pre></td></tr></table></figure>

<h5 id="open-library-py"><a href="#open-library-py" class="headerlink" title="open_library.py"></a>open_library.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">username = <span class="string">&#x27;xxx@....&#x27;</span></span><br><span class="line">password = <span class="string">&#x27;p...&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="openlibrary-login-py"><a href="#openlibrary-login-py" class="headerlink" title="openlibrary_login.py"></a>openlibrary_login.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest</span><br><span class="line"><span class="keyword">import</span> open_library</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenlibaryLoginSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;openlibrary_login&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;openlibrary.org&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://openlibrary.org/account/login&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> FormRequest.from_response(</span><br><span class="line">            response,</span><br><span class="line">            formid=<span class="string">&#x27;register&#x27;</span>,</span><br><span class="line">            formdata = &#123;</span><br><span class="line">                <span class="string">&#x27;username&#x27;</span>: open_library.username,</span><br><span class="line">                <span class="string">&#x27;password&#x27;</span>: open_library.password,</span><br><span class="line">                <span class="string">&#x27;redirect&#x27;</span>: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;debug_token&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;login&#x27;</span>: <span class="string">&#x27;登录&#x27;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            callback = self.after_login</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_login</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=================&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span>  response.xpath(<span class="string">&quot;//input[@type=&#x27;password&#x27;]&quot;</span>).get():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;login failed...&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;logged in...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-7"><a href="#run-7" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy crawl openlibrary_login</span><br><span class="line">......</span><br><span class="line">=================</span><br><span class="line">logged <span class="keyword">in</span>...</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="Aarchive-Org"><a href="#Aarchive-Org" class="headerlink" title="Aarchive Org"></a><a target="_blank" rel="noopener" href="https://archive.org/account/login">Aarchive Org</a></h4><h5 id="create-spider-3"><a href="#create-spider-3" class="headerlink" title="create spider"></a>create spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy genspider openlibrary_login2 archive.org/account/login</span><br><span class="line">Created spider <span class="string">&#x27;openlibrary_login2&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_login.spiders.openlibrary_login2</span><br></pre></td></tr></table></figure>

<h5 id="openlibrary-login2-py"><a href="#openlibrary-login2-py" class="headerlink" title="openlibrary_login2.py"></a>openlibrary_login2.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> FormRequest</span><br><span class="line"><span class="keyword">import</span> open_library</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenlibaryLoginSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;openlibrary_login2&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;archive.org&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://archive.org/account/login&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> FormRequest.from_response(</span><br><span class="line">            response,</span><br><span class="line">            <span class="comment"># formxpath also need</span></span><br><span class="line">            formxpath=<span class="string">&#x27;//form[@class=&quot;iaform login-form&quot;]&#x27;</span>,</span><br><span class="line">            formdata = &#123;</span><br><span class="line">                <span class="string">&#x27;username&#x27;</span>: open_library.username,</span><br><span class="line">                <span class="string">&#x27;password&#x27;</span>: open_library.password,</span><br><span class="line">                <span class="comment"># &#x27;remember&#x27;: response.xpath(&quot;//input[@name=&#x27;remember&#x27;]/@value&quot;).get(),</span></span><br><span class="line">                <span class="comment"># &#x27;referer&#x27;: response.xpath(&quot;//input[@name=&#x27;referer&#x27;]/@value&quot;).get(),</span></span><br><span class="line">                <span class="comment"># &#x27;login&#x27;: response.xpath(&quot;//input[@name=&#x27;login&#x27;]/@value&quot;).get(),</span></span><br><span class="line">                <span class="string">&#x27;login&#x27;</span>: <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;remember&#x27;</span>: <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://archive.org/&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;submit-to-login&#x27;</span>: <span class="string">&#x27;Log in&#x27;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            callback = self.after_login</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_login</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=================&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span>  response.xpath(<span class="string">&quot;//input[@type=&#x27;password&#x27;]&quot;</span>).get():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;login failed...&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;logged in...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-8"><a href="#run-8" class="headerlink" title="run"></a>run</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy crawl openlibrary_login2</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">......</span><br><span class="line">logged in...</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="Quote-to-Scrape-Script"><a href="#Quote-to-Scrape-Script" class="headerlink" title="Quote to Scrape - Script"></a><a target="_blank" rel="noopener" href="https://quotes.toscrape.com/login">Quote to Scrape</a> - Script</h4><h5 id="create-spider-4"><a href="#create-spider-4" class="headerlink" title="create spider"></a>create spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy genspider quotes_login2 quotes.toscrape.com/login</span><br><span class="line">Created spider <span class="string">&#x27;quotes_login2&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_login.spiders.quotes_login2</span><br></pre></td></tr></table></figure>

<h5 id="quotes-login2-py"><a href="#quotes-login2-py" class="headerlink" title="quotes_login2.py"></a>quotes_login2.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest, SplashFormRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesLogin2Spider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;quotes_login2&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;quotes.toscrape.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://quotes.toscrape.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    script = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        -- https://quotes.toscrape.com/login</span></span><br><span class="line"><span class="string">        function main(splash, args)</span></span><br><span class="line"><span class="string">            assert(splash:go(args.url))</span></span><br><span class="line"><span class="string">            assert(splash:wait(0.5))</span></span><br><span class="line"><span class="string">            return splash:html()</span></span><br><span class="line"><span class="string">        en</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(</span><br><span class="line">            url=<span class="string">&#x27;https://quotes.toscrape.com/login&#x27;</span>,</span><br><span class="line">            endpoint=<span class="string">&#x27;execute&#x27;</span>,</span><br><span class="line">            args = &#123;</span><br><span class="line">                <span class="string">&#x27;lua_source&#x27;</span>: self.script</span><br><span class="line">            &#125;,</span><br><span class="line">            callback=self.parse</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        csrf_token = response.xpath(<span class="string">&#x27;//input[@name=&quot;csrf_token&quot;]/@value&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">yield</span> SplashFormRequest.from_response(</span><br><span class="line">            response,</span><br><span class="line">            <span class="comment"># no formxpath also ok</span></span><br><span class="line">            formxpath=<span class="string">&#x27;//form&#x27;</span>,</span><br><span class="line">            formdata= &#123;</span><br><span class="line">                <span class="string">&#x27;csrf_token&#x27;</span>: csrf_token,</span><br><span class="line">                <span class="string">&#x27;username&#x27;</span>: <span class="string">&#x27;admin&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;admin&#x27;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            callback = self.after_login</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_login</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">if</span> response.xpath(<span class="string">&quot;//a[@href=&#x27;/logout&#x27;]&quot;</span>).get():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;logged in...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-9"><a href="#run-9" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_login&gt;scrapy crawl openlibrary_login2</span><br><span class="line">......</span><br><span class="line">=================</span><br><span class="line">logged <span class="keyword">in</span>...</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h3 id="ByPass-Cloudflare"><a href="#ByPass-Cloudflare" class="headerlink" title="ByPass Cloudflare"></a>ByPass Cloudflare</h3><h4 id="CoinMarketCap-block-by-status-code-429-too-many-request"><a href="#CoinMarketCap-block-by-status-code-429-too-many-request" class="headerlink" title="CoinMarketCap - block by status code 429(too many request)"></a><a target="_blank" rel="noopener" href="https://web.archive.org/web/20190101085451/https://coinmarketcap.com/">CoinMarketCap</a> - block by status code 429(too many request)</h4><h5 id="create-project-and-spider-2"><a href="#create-project-and-spider-2" class="headerlink" title="create project and spider"></a>create project and spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject coinmarketcap</span><br><span class="line">New Scrapy project <span class="string">&#x27;coinmarketcap&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\coinmarketcap</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> coinmarketcap</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> coinmarketcap</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\coinmarketcap&gt;scrapy genspider -t crawl coins https://web.archive.org/web/20190101085451/https://coinmarketcap.com/</span><br><span class="line">Created spider <span class="string">&#x27;coins&#x27;</span> using template <span class="string">&#x27;crawl&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  coinmarketcap.spiders.coins</span><br></pre></td></tr></table></figure>

<h5 id="coins-py"><a href="#coins-py" class="headerlink" title="coins.py"></a>coins.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CoinsSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;coins&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://web.archive.org/web/20190101085451/https://coinmarketcap.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;//a[@class=&#x27;currency-name-container link-secondary&#x27;]&quot;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = &#123;&#125;</span><br><span class="line">        <span class="comment">#item[&#x27;domain_id&#x27;] = response.xpath(&#x27;//input[@id=&quot;sid&quot;]/@value&#x27;).get()</span></span><br><span class="line">        <span class="comment">#item[&#x27;name&#x27;] = response.xpath(&#x27;//div[@id=&quot;name&quot;]&#x27;).get()</span></span><br><span class="line">        <span class="comment">#item[&#x27;description&#x27;] = response.xpath(&#x27;//div[@id=&quot;description&quot;]&#x27;).get()</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: response.xpath(<span class="string">&quot;normalize-space((//h1/text())[2])&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;rank&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;label label-success&#x27;]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;price(USD)&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;h2 text-semi-bold details-panel-item--price__value&#x27;]/text()&quot;</span>).get()</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h5 id="run-10"><a href="#run-10" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\coinmarketcap&gt;scrapy crawl coins</span><br><span class="line">......</span><br><span class="line">2022-12-30 11:53:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101221303/https://coinmarketcap.com/currencies/ethereum/&gt; (referer: https://web.archive.org/web/20190101085451/https://coinmarketcap.com/)</span><br><span class="line">2022-12-30 11:53:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20181231070605/https://coinmarketcap.com/currencies/bitcoin-cash/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Bitcoin Cash&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 4&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;160.12&#x27;</span>&#125;</span><br><span class="line">2022-12-30 11:53:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101221303/https://coinmarketcap.com/currencies/ethereum/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Ethereum&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 3&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;139.89&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># return code 429</span></span><br><span class="line">2022-12-30 11:53:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying &lt;GET https://web.archive.org/web/20190104162538/https://coinmarketcap.com/currencies/bitcoin-sv/&gt; (failed 2 <span class="built_in">times</span>): 429 Unknown Status</span><br><span class="line">2022-12-30 11:53:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to &lt;GET https://web.archive.org/web/20190104162517/https://coinmarketcap.com/currencies/theta/&gt; from &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/theta/&gt;</span><br><span class="line">2022-12-30 11:53:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190104162631/https://coinmarketcap.com/currencies/iota/&gt; (referer: https://web.archive.org/web/20190101085451/https://coinmarketcap.com/)</span><br><span class="line">2022-12-30 11:53:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190104162631/https://coinmarketcap.com/currencies/iota/&gt;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="fix-block-by-status-code-429-依課程修改但沒有用"><a href="#fix-block-by-status-code-429-依課程修改但沒有用" class="headerlink" title="fix block by status code 429(依課程修改但沒有用)"></a>fix block by status code 429(依課程修改但沒有用)</h4><h5 id="install"><a href="#install" class="headerlink" title="install"></a>install</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy_cloudflare_middleware</span><br></pre></td></tr></table></figure>

<h5 id="settings-py-6"><a href="#settings-py-6" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="comment"># The priority of 560 is important, because we want this middleware to kick in just before the scrapy built-in `RetryMiddleware`.</span></span><br><span class="line">    <span class="string">&#x27;scrapy_cloudflare_middleware.middlewares.CloudFlareMiddleware&#x27;</span>: <span class="number">560</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="CloudFlare-Middleware-modify"><a href="#CloudFlare-Middleware-modify" class="headerlink" title="CloudFlare Middleware modify"></a>CloudFlare Middleware modify</h5><p>D:\app\python_env\myenv10_scrapy\Lib\site-packages\scrapy_cloudflare_middleware\middlewares.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CloudFlareMiddleware</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scrapy middleware to bypass the CloudFlare&#x27;s anti-bot protection&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_cloudflare_challenge</span>(<span class="params">response</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Test if the given response contains the cloudflare&#x27;s anti-bot protection&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            <span class="comment"># add handle for status code 429</span></span><br><span class="line">            <span class="comment"># response.status == 503</span></span><br><span class="line">            response.status == <span class="number">503</span> <span class="keyword">or</span> response.status == <span class="number">429</span></span><br><span class="line">            <span class="keyword">and</span> response.headers.get(<span class="string">&#x27;Server&#x27;</span>, <span class="string">&#x27;&#x27;</span>).startswith(<span class="string">b&#x27;cloudflare&#x27;</span>)</span><br><span class="line">            <span class="keyword">and</span> <span class="string">&#x27;jschl_vc&#x27;</span> <span class="keyword">in</span> response.text</span><br><span class="line">            <span class="keyword">and</span> <span class="string">&#x27;jschl_answer&#x27;</span> <span class="keyword">in</span> response.text</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<h5 id="run-11"><a href="#run-11" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\coinmarketcap&gt;scrapy crawl coins</span><br><span class="line">......</span><br><span class="line">2023-01-03 09:30:12 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190228115956/https://coinmarketcap.com/currencies/moac/&gt; (referer: https://web.archive.org/web/20190101085451/https://coinmarketcap.com/)</span><br><span class="line">2023-01-03 09:30:12 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190228115956/https://coinmarketcap.com/currencies/moac/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;MOAC&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 95&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;0.598146&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># also found stauso code 429</span></span><br><span class="line">2023-01-03 09:30:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying &lt;GET https://web.archive.org/web/20190104162556/https://coinmarketcap.com/currencies/tron/&gt; (failed 3 <span class="built_in">times</span>): 429 Unknown Status</span><br><span class="line">2023-01-03 09:30:12 [scrapy.core.engine] DEBUG: Crawled (429) &lt;GET https://web.archive.org/web/20190104162556/https://coinmarketcap.com/currencies/tron/&gt; (referer: https://web.archive.org/web/20190101085451/https://coinmarketcap.com/)</span><br><span class="line">2023-01-03 09:30:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to &lt;GET https://web.archive.org/web/20190209111611/https://coinmarketcap.com/currencies/maximine-coin/&gt; from &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/maximine-coin/&gt;</span><br><span class="line">2023-01-03 09:30:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying &lt;GET https://web.archive.org/web/20190104162547/https://coinmarketcap.com/currencies/litecoin/&gt; (failed 3 <span class="built_in">times</span>): 429 Unknown Status</span><br><span class="line">2023-01-03 09:30:12 [scrapy.core.engine] DEBUG: Crawled (429) &lt;GET https://web.archive.org/web/20190104162547/https://coinmarketcap.com/currencies/litecoin/&gt; (referer: https://web.archive.org/web/20190101085451/https://coinmarketcap.com/)</span><br><span class="line">2023-01-03 09:30:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to &lt;GET https://web.archive.org/web/20190104162550/https://coinmarketcap.com/currencies/mixin/&gt; from &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/mixin/&gt;</span><br><span class="line">2023-01-03 09:30:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to &lt;GET https://web.archive.org/web/20190104162513/https://coinmarketcap.com/currencies/hypercash/&gt; from &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/hypercash/&gt;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="fix-block-by-status-code-429-call-splash-還是會回429"><a href="#fix-block-by-status-code-429-call-splash-還是會回429" class="headerlink" title="fix block by status code 429 - call splash(還是會回429)"></a>fix block by status code 429 - call splash(還是會回429)</h4><h5 id="create-projector-and-spider"><a href="#create-projector-and-spider" class="headerlink" title="create projector and spider"></a>create projector and spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\106-scrapy-splash&gt;scrapy startproject coinmarketcap</span><br><span class="line">New Scrapy project <span class="string">&#x27;coinmarketcap&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\106-scrapy-splash\coinmarketcap</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> coinmarketcap</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\106-scrapy-splash&gt;<span class="built_in">cd</span> coinmarketcap</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\106-scrapy-splash\coinmarketcap&gt;scrapy genspider  coins2 web.archive.org/web/20190101085451/https://coinmarketcap.com/</span><br><span class="line">Created spider <span class="string">&#x27;coins2&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  coinmarketcap.spiders.coins2</span><br></pre></td></tr></table></figure>

<h5 id="basic-setting"><a href="#basic-setting" class="headerlink" title="basic setting"></a>basic setting</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># put lastest</span></span><br><span class="line">SPLASH_URL = <span class="string">&#x27;http://localhost:8050&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#DOWNLOADER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;livecoin.middlewares.LivecoinDownloaderMiddleware&#x27;: 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashCookiesMiddleware&#x27;</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashMiddleware&#x27;</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#x27;</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable spider middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"><span class="comment">#SPIDER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;livecoin.middlewares.LivecoinSpiderMiddleware&#x27;: 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashDeduplicateArgsMiddleware&#x27;</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&#x27;scrapy_splash.SplashAwareDupeFilter&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="coins2-py"><a href="#coins2-py" class="headerlink" title="coins2.py"></a>coins2.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Coins2Spider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;coins2&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://web.archive.org/web/20190101085451/https://coinmarketcap.com/&#x27;]</span></span><br><span class="line"></span><br><span class="line">    script = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        -- https://web.archive.org/web/20190101085451/https://coinmarketcap.com/</span></span><br><span class="line"><span class="string">        function main(splash, args)</span></span><br><span class="line"><span class="string">            assert(splash:go(args.url))</span></span><br><span class="line"><span class="string">            assert(splash:wait(5))</span></span><br><span class="line"><span class="string">            return splash:html()</span></span><br><span class="line"><span class="string">        end</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    script2 = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        -- https://web.archive.org/web/20190101085451/https://coinmarketcap.com/</span></span><br><span class="line"><span class="string">        function main(splash, args)</span></span><br><span class="line"><span class="string">            assert(splash:go(args.url))</span></span><br><span class="line"><span class="string">            assert(splash:wait(1))</span></span><br><span class="line"><span class="string">            return splash:html()</span></span><br><span class="line"><span class="string">        end</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(</span><br><span class="line">            url=<span class="string">&#x27;https://web.archive.org/web/20190101085451/https://coinmarketcap.com/&#x27;</span>,</span><br><span class="line">            endpoint=<span class="string">&#x27;execute&#x27;</span>,</span><br><span class="line">            args = &#123;</span><br><span class="line">                <span class="string">&#x27;lua_source&#x27;</span>: self.script</span><br><span class="line">            &#125;,</span><br><span class="line">            callback=self.parse</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        coins = response.xpath(<span class="string">&quot;//a[@class=&#x27;currency-name-container link-secondary&#x27;]&quot;</span>)</span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;(<span class="subst">&#123;i&#125;</span>)============&quot;</span>)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">yield</span> SplashRequest(</span><br><span class="line">                url = <span class="string">f&#x27;https://web.archive.org<span class="subst">&#123;coin.xpath(<span class="string">&quot;.//@href&quot;</span>).get()&#125;</span>&#x27;</span>,</span><br><span class="line">                endpoint=<span class="string">&#x27;execute&#x27;</span>,</span><br><span class="line">                args = &#123;</span><br><span class="line">                    <span class="string">&#x27;lua_source&#x27;</span>: self.script2</span><br><span class="line">                &#125;,</span><br><span class="line">                callback=self.parse_next</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_next</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;next ============&quot;</span>)</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: response.xpath(<span class="string">&quot;normalize-space((//h1/text())[2])&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;rank&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;label label-success&#x27;]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;price(USD)&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;h2 text-semi-bold details-panel-item--price__value&#x27;]/text()&quot;</span>).get()</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-12"><a href="#run-12" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\106-scrapy-splash\coinmarketcap&gt;scrapy crawl coins2</span><br><span class="line">......</span><br><span class="line">2023-01-03 09:59:04 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET https://web.archive.org/robots.txt&gt; (referer: None)</span><br><span class="line">2023-01-03 09:59:15 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">(1)============</span><br><span class="line">(2)============</span><br><span class="line">......</span><br><span class="line">(100)============</span><br><span class="line"><span class="comment"># found status code 429</span></span><br><span class="line">2023-01-03 09:59:19 [scrapy_splash.middleware] WARNING: Bad request to Splash: &#123;<span class="string">&#x27;error&#x27;</span>: 400, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;ScriptError&#x27;</span>, <span class="string">&#x27;description&#x27;</span>: <span class="string">&#x27;Error happened while executing Lua script&#x27;</span>, <span class="string">&#x27;info&#x27;</span>: &#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;[string &quot;...&quot;]&#x27;</span>, <span class="string">&#x27;line_number&#x27;</span>: 4, <span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;http429&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;LUA_ERROR&#x27;</span>, <span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;Lua error: [string &quot;...&quot;]:4: http429&#x27;</span>&#125;&#125;</span><br><span class="line">2023-01-03 09:59:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/waves/ via http://localhost:8050/execute&gt; (failed 1 <span class="built_in">times</span>): 429 Unknown Status</span><br><span class="line">2023-01-03 09:59:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/tezos/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/tezos/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Tezos&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 22&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;0.482671&#x27;</span>&#125;</span><br><span class="line">2023-01-03 09:59:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/usd-coin/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">2023-01-03 09:59:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/bitcoin/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/usd-coin/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;USD Coin&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 24&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;1.02&#x27;</span>&#125;</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/bitcoin/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Bitcoin&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 1&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;3763.14&#x27;</span>&#125;</span><br><span class="line">2023-01-03 09:59:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/ethereum-classic/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/ethereum-classic/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Ethereum Classic&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 17&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;5.11&#x27;</span>&#125;</span><br><span class="line">2023-01-03 09:59:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/dogecoin/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/dogecoin/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Dogecoin&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 23&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;0.002353&#x27;</span>&#125;</span><br><span class="line">2023-01-03 09:59:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/neo/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/neo/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;NEO&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 18&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;7.81&#x27;</span>&#125;</span><br><span class="line">2023-01-03 09:59:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/maker/ via http://localhost:8050/execute&gt; (referer: None)</span><br><span class="line">next ============</span><br><span class="line">2023-01-03 09:59:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/maker/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Maker&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>: <span class="string">&#x27; Rank 20&#x27;</span>, <span class="string">&#x27;price(USD)&#x27;</span>: <span class="string">&#x27;458.21&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># found status code 429</span></span><br><span class="line">2023-01-03 09:59:37 [scrapy_splash.middleware] WARNING: Bad request to Splash: &#123;<span class="string">&#x27;error&#x27;</span>: 400, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;ScriptError&#x27;</span>, <span class="string">&#x27;description&#x27;</span>: <span class="string">&#x27;Error happened while executing Lua script&#x27;</span>, <span class="string">&#x27;info&#x27;</span>: &#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;[string &quot;...&quot;]&#x27;</span>, <span class="string">&#x27;line_number&#x27;</span>: 4, <span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;http429&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;LUA_ERROR&#x27;</span>, <span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;Lua error: [string &quot;...&quot;]:4: http429&#x27;</span>&#125;&#125;</span><br><span class="line">2023-01-03 09:59:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying &lt;GET https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/cardano/ via http://localhost:8050/execute&gt; (failed 1 <span class="built_in">times</span>): 429 Unknown Status</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="CoinMarketCap-bs4-cloudscraper"><a href="#CoinMarketCap-bs4-cloudscraper" class="headerlink" title="CoinMarketCap - bs4 + cloudscraper"></a><a target="_blank" rel="noopener" href="https://web.archive.org/web/20190101085451/https://coinmarketcap.com/">CoinMarketCap</a> - bs4 + cloudscraper</h4><h5 id="install-beautifulsoup4"><a href="#install-beautifulsoup4" class="headerlink" title="install beautifulsoup4"></a>install beautifulsoup4</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br><span class="line">pip install cloudscraper</span><br></pre></td></tr></table></figure>

<h5 id="bypass-coinmarket-py"><a href="#bypass-coinmarket-py" class="headerlink" title="bypass_coinmarket.py"></a>bypass_coinmarket.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> beauty</span><br><span class="line"><span class="keyword">import</span> cloudscraper</span><br><span class="line"></span><br><span class="line">scraper = cloudscraper.create_scraper(delay=<span class="number">10</span>, browser=<span class="string">&#x27;chrome&#x27;</span>)</span><br><span class="line">url = <span class="string">&quot;https://web.archive.org/web/20190101085451/https://coinmarketcap.com/&quot;</span></span><br><span class="line"></span><br><span class="line">info = scraper.get(url).text</span><br><span class="line">soup = beauty(info, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">soup = soup.find_all(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;currency-name-container link-secondary&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> soup:</span><br><span class="line">    sub_url = <span class="string">f&quot;https://web.archive.org<span class="subst">&#123;data[<span class="string">&#x27;href&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===============&quot;</span>)</span><br><span class="line">    <span class="comment"># print(data.get_text())</span></span><br><span class="line">    <span class="built_in">print</span>(sub_url)</span><br><span class="line"></span><br><span class="line">    info2 = scraper.get(sub_url).text</span><br><span class="line">    soup2 = beauty(info2, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> soup2.find(<span class="string">&#x27;span&#x27;</span>, <span class="string">&#x27;label label-success&#x27;</span>):</span><br><span class="line">        h1_str = soup2.find(<span class="string">&#x27;h1&#x27;</span>).text.strip().split(<span class="string">&#x27;\x0a&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;h1_str[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;rank: <span class="subst">&#123;soup2.find(<span class="string">&#x27;span&#x27;</span>, <span class="string">&#x27;label label-success&#x27;</span>).text&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;price(USD): <span class="subst">&#123;soup2.find(<span class="string">&#x27;span&#x27;</span>, <span class="string">&#x27;h2 text-semi-bold details-panel-item--price__value&#x27;</span>).text&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;error link: <span class="subst">&#123;data.get_text()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-13"><a href="#run-13" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\simple&gt;python bypass_coinmarket.py</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/bitcoin/</span><br><span class="line">name: Bitcoin</span><br><span class="line">rank:  Rank 1</span><br><span class="line">price(USD): 3763.14</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/ripple/</span><br><span class="line">name: XRP</span><br><span class="line">rank:  Rank 2</span><br><span class="line">price(USD): 0.376038</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/ethereum/</span><br><span class="line">name: Ethereum</span><br><span class="line">rank:  Rank 3</span><br><span class="line">price(USD): 139.89</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/bitcoin-cash/</span><br><span class="line">name: Bitcoin Cash</span><br><span class="line">rank:  Rank 4</span><br><span class="line">price(USD): 160.12</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/eos/</span><br><span class="line">name: EOS</span><br><span class="line">rank:  Rank 5</span><br><span class="line">price(USD): 2.63</span><br><span class="line"><span class="comment"># some link have problem</span></span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/stellar/</span><br><span class="line">error link: Stellar</span><br><span class="line">......</span><br><span class="line"><span class="comment"># some link have problem</span></span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/crypto-com/</span><br><span class="line">error link</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/zcoin/</span><br><span class="line">name: Zcoin</span><br><span class="line">rank:  Rank 93</span><br><span class="line">price(USD): 5.43</span><br><span class="line">===============</span><br><span class="line">https://web.archive.org/web/20190101085451/https://coinmarketcap.com/currencies/theta/</span><br><span class="line">name: THETA</span><br><span class="line">rank:  Rank 98</span><br><span class="line">price(USD): 0.049800</span><br></pre></td></tr></table></figure>

<h4 id="fiverr-bs4-cloudscraper"><a href="#fiverr-bs4-cloudscraper" class="headerlink" title="fiverr - bs4 + cloudscraper"></a><a target="_blank" rel="noopener" href="https://www.fiverr.com/categories/online-marketing">fiverr</a> - bs4 + cloudscraper</h4><ul>
<li>debug&#x3D;True, 可顯示一些 message, return code 有時 307, 有時 403 不正確回應</li>
</ul>
<h5 id="bypass-fiverr-py"><a href="#bypass-fiverr-py" class="headerlink" title="bypass_fiverr.py"></a>bypass_fiverr.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> beauty</span><br><span class="line"><span class="keyword">import</span> cloudscraper</span><br><span class="line"></span><br><span class="line"><span class="comment"># scraper = cloudscraper.create_scraper(delay=10, browser=&#x27;chrome&#x27;,debug=True)</span></span><br><span class="line">scraper = cloudscraper.create_scraper(delay=<span class="number">10</span>, browser=<span class="string">&#x27;chrome&#x27;</span>)</span><br><span class="line">url = <span class="string">&quot;https://www.fiverr.com/categories/online-marketing&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">info = scraper.get(url).text</span><br><span class="line"><span class="comment"># print(&quot;0 ===============&quot;)</span></span><br><span class="line"><span class="comment"># print(info)</span></span><br><span class="line">soup = beauty(info, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="comment"># print(&quot;1 ===============&quot;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line">soup = soup.find_all(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;item-name&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;2 ===============&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> soup:</span><br><span class="line">    sub_url = <span class="string">&#x27;https://www.fiverr.com&#x27;</span>+data[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===============&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(data.get_text())</span><br><span class="line">    <span class="comment"># print(sub_url)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># info2 = scraper.get(sub_url).text</span></span><br><span class="line">    <span class="comment"># soup2 = beauty(info2, &quot;html.parser&quot;)</span></span><br><span class="line">    <span class="comment"># if soup2.find(&#x27;p&#x27;, &#x27;sc-subtitle&#x27;):</span></span><br><span class="line">    <span class="comment">#     print(f&quot;title: &#123;soup2.find(&#x27;h1&#x27;).text&#125;&quot;)</span></span><br><span class="line">    <span class="comment">#     print(f&quot;description: &#123;soup2.find(&#x27;p&#x27;, &#x27;sc-subtitle&#x27;).text&#125;&quot;)</span></span><br><span class="line">    <span class="comment"># else :</span></span><br><span class="line">    <span class="comment">#     print(&quot;error&quot;)</span></span><br><span class="line">    <span class="comment">#     print(f&quot;title: &#123;soup2.find(&#x27;h1&#x27;)&#125;&quot;)</span></span><br><span class="line">    <span class="comment">#     print(f&quot;description: &#123;soup2.find(&#x27;p&#x27;, &#x27;sc-subtitle&#x27;)&#125;&quot;)</span></span><br></pre></td></tr></table></figure>

<h5 id="run-14"><a href="#run-14" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\simple&gt;python bypass_fiverr.py</span><br><span class="line">2 ===============</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>

<h4 id="fiverr-block-403"><a href="#fiverr-block-403" class="headerlink" title="fiverr - block 403"></a><a target="_blank" rel="noopener" href="https://www.fiverr.com/categories/online-marketing">fiverr</a> - block 403</h4><ul>
<li>crawl_items, basic_items 執行都有問題</li>
<li>執行 crawl_items, 好像也會執行到 basic_items</li>
</ul>
<h5 id="create-project-and-spider-3"><a href="#create-project-and-spider-3" class="headerlink" title="create project and spider"></a>create project and spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy&gt;scrapy startproject fiverr</span><br><span class="line">New Scrapy project <span class="string">&#x27;fiverr&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\git\python_crawler\101-scrapy\fiverr</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> fiverr</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> fiverr</span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy\fiverr&gt;scrapy genspider -t crawl crawl_items www.fiverr.com/categories/online-marketing?<span class="built_in">source</span>=category_tree</span><br><span class="line">Created spider <span class="string">&#x27;crawl_items&#x27;</span> using template <span class="string">&#x27;crawl&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  fiverr.spiders.crawl_items</span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy\fiverr&gt;scrapy genspider basic_items www.fiverr.com/categories/online-marketing?<span class="built_in">source</span>=category_tree</span><br><span class="line">Created spider <span class="string">&#x27;basic_items&#x27;</span> using template <span class="string">&#x27;crawl&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  fiverr.spiders.basic_items</span><br></pre></td></tr></table></figure>

<h5 id="run-15"><a href="#run-15" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\fiverr&gt;scrapy crawl crawl_items</span><br><span class="line">10 ==============</span><br><span class="line">&lt;Selector xpath=None data=<span class="string">&#x27;&lt;html lang=&quot;en-US&quot;&gt;&lt;head&gt;&lt;meta charse...&#x27;</span>&gt;</span><br><span class="line">11 ==============</span><br><span class="line">[]</span><br><span class="line">12 ==============</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\fiverr&gt;scrapy crawl basic_items</span><br><span class="line">10 ==============</span><br><span class="line">&lt;Selector xpath=None data=<span class="string">&#x27;&lt;html lang=&quot;en-US&quot;&gt;&lt;head&gt;&lt;meta charse...&#x27;</span>&gt;</span><br><span class="line">11 ==============</span><br><span class="line">[]</span><br><span class="line">12 ==============</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h5 id="install-beautifulsoup4-and-cloudscraper"><a href="#install-beautifulsoup4-and-cloudscraper" class="headerlink" title="install beautifulsoup4 and cloudscraper"></a>install beautifulsoup4 and cloudscraper</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy\simple&gt;pip install beautifulsoup4</span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy\simple&gt;pip install cloudscraper</span><br></pre></td></tr></table></figure>

<h3 id="Downloading-Files-Using-Scrapy"><a href="#Downloading-Files-Using-Scrapy" class="headerlink" title="Downloading Files Using Scrapy"></a>Downloading Files Using Scrapy</h3><h4 id="mp3-59"><a href="#mp3-59" class="headerlink" title="mp3-59"></a><a target="_blank" rel="noopener" href="https://ftp.icm.edu.pl/packages/mp3/59/">mp3-59</a></h4><h5 id="create-project-and-spider-4"><a href="#create-project-and-spider-4" class="headerlink" title="create project and spider"></a>create project and spider</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject demo_downloader</span><br><span class="line">New Scrapy project <span class="string">&#x27;demo_downloader&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\demo_downloader</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> demo_downloader</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> demo_downloader</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_downloader&gt;scrapy genspider mp3_downloader ftp.icm.edu.pl/packages/mp3/59/</span><br><span class="line">Created spider <span class="string">&#x27;mp3_downloader&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  demo_downloader.spiders.mp3_downloader</span><br></pre></td></tr></table></figure>

<h5 id="mp3-downloader-py"><a href="#mp3-downloader-py" class="headerlink" title="mp3_downloader.py"></a>mp3_downloader.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mp3DownloaderSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;mp3_downloader&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;ftp.icm.edu.pl&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># //following::tr[4]/td[2]/a[not(contains(@href,&#x27;jpg&#x27;))] - also ok</span></span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> response.xpath(<span class="string">&quot;//following::tr[4]/td[2]/a[contains(@href,&#x27;mp3&#x27;)]&quot;</span>):</span><br><span class="line">            relative_url = link.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line">            absolute_url = response.urljoin(relative_url)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;==============&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;absolute_url : <span class="subst">&#123;absolute_url&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;Title&#x27;</span>:  relative_url,</span><br><span class="line">                <span class="string">&#x27;file_urls&#x27;</span>: [absolute_url]</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>

<h5 id="settings-py-7"><a href="#settings-py-7" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="comment">#ITEM_PIPELINES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;demo_downloader.pipelines.DemoDownloaderPipeline&#x27;: 300,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">&#x27;scrapy.pipelines.files.FilesPipeline&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="comment"># &#x27;demo_downloader.pipelines.CustomFilePipeLines&#x27;: 1,</span></span><br><span class="line">&#125;</span><br><span class="line">FILES_STORE = <span class="string">&#x27;mp3&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="items-py"><a href="#items-py" class="headerlink" title="items.py"></a>items.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoDownloaderItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="comment"># pass</span></span><br><span class="line">    Title = scrapy.Field()</span><br><span class="line">    file_urls = scrapy.Field()</span><br><span class="line">    files = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h5 id="run-16"><a href="#run-16" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_downloader&gt;scrapy crawl mp3_downloader</span><br><span class="line">.....</span><br><span class="line">2023-01-04 13:45:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/&gt; (referer: None)</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Feel_in_luv_with_an_alien__F_cK_K.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Feel_in_luv_with_an_alien__F_cK_K.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Oda_Do_Mlodosci.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Oda_Do_Mlodosci.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Shalala_Boom_Were_Going_to_Kiss_Uncle_Down.mp3</span><br><span class="line">2023-01-04 13:45:54 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Shalala_Boom_Were_Going_to_Kiss_Uncle_Down.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">2023-01-04 13:45:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line"><span class="comment"># scrapy.Field</span></span><br><span class="line"><span class="comment"># save file full/7d1835bbcc24b42fb05911df015306bfb3e80087.mp3</span></span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Blood__AAA_version.mp3&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&#x27;</span>], </span><br><span class="line"><span class="string">&#x27;files&#x27;</span>: [</span><br><span class="line">	&#123;	<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&#x27;</span>, </span><br><span class="line">		<span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;full/7d1835bbcc24b42fb05911df015306bfb3e80087.mp3&#x27;</span>, </span><br><span class="line">		<span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;8013d9ea5f6d3d596f76d8047b41a7f9&#x27;</span>, </span><br><span class="line">		<span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;uptodate&#x27;</span></span><br><span class="line">	&#125;]&#125;</span><br><span class="line">2023-01-04 13:45:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;full/cbccc9a40c2019c3ce88467c78191bfd8cd9af8f.mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;c323a1ff9802b7e4a5b2447350b388a9&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;uptodate&#x27;</span>&#125;]&#125;</span><br><span class="line">2023-01-04 13:45:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Feel_in_luv_with_an_alien__F_cK_K.mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Feel_in_luv_with_an_alien__F_cK_K.mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Feel_in_luv_with_an_alien__F_cK_K.mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;full/0d71bff3e1f0e797bb62f4c61428856110ecc123.mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;df42fcb95c2a89f57d75af27584f3634&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;uptodate&#x27;</span>&#125;]&#125;</span><br><span class="line">2023-01-04 13:45:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Klan_Soundtrack__hardcore_version.mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;full/666dda5772db9d8bc5a1d8829156b42f05d52e20.mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;e45ea17db6cb6d3a62a5fe2cad1aea54&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;uptodate&#x27;</span>&#125;]&#125;</span><br><span class="line">2023-01-04 13:45:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;full/15d1d6111af5b0ea7984fa70312d9c6cdce4287b.mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;815f83bd1d41fe0504fabe26569eb30d&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;uptodate&#x27;</span>&#125;]&#125;</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>

<h4 id="mp3-59-fix-file-name"><a href="#mp3-59-fix-file-name" class="headerlink" title="mp3-59 - fix file name"></a><a target="_blank" rel="noopener" href="https://ftp.icm.edu.pl/packages/mp3/59/">mp3-59</a> - fix file name</h4><h5 id="settings-py-8"><a href="#settings-py-8" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="comment">#ITEM_PIPELINES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;demo_downloader.pipelines.DemoDownloaderPipeline&#x27;: 300,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># &#x27;scrapy.pipelines.files.FilesPipeline&#x27;: 1,</span></span><br><span class="line">    <span class="string">&#x27;demo_downloader.pipelines.CustomFilePipeLines&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line">FILES_STORE = <span class="string">&#x27;mp3&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="pipelines-py-4"><a href="#pipelines-py-4" class="headerlink" title="pipelines.py"></a>pipelines.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="comment"># from itemadapter import ItemAdapter</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># class DemoDownloaderPipeline:</span></span><br><span class="line"><span class="comment">#     def process_item(self, item, spider):</span></span><br><span class="line"><span class="comment">#         return item</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># from scrapy.pipelines.files import FilesPipeline</span></span><br><span class="line"><span class="keyword">import</span> scrapy.pipelines.files <span class="keyword">as</span> scrapy_file</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomFilePipeLines</span>(<span class="params">scrapy_file.FilesPipeline</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span>, *, item=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;CustomFilePipeLines　===========&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(item.get(<span class="string">&#x27;Title&#x27;</span>))</span><br><span class="line">        <span class="keyword">return</span> item.get(<span class="string">&#x27;Title&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-17"><a href="#run-17" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\demo_downloader&gt;scrapy crawl mp3_downloader</span><br><span class="line">......</span><br><span class="line">2023-01-04 14:00:13 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/&gt; (referer: None)</span><br><span class="line"><span class="comment"># by mp3_downloader.py</span></span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3</span><br><span class="line"><span class="comment"># by pipelines.py</span></span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Blood__AAA_version.mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Feel_in_luv_with_an_alien__F_cK_K.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Feel_in_luv_with_an_alien__F_cK_K.mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Klan_Soundtrack__hardcore_version.mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Na_Na_Na__F_cK_K_Family_hardcore_remix.mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Oda_Do_Mlodosci.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Oda_Do_Mlodosci.mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Prognoza_Pogody.mp3</span><br><span class="line">==============</span><br><span class="line">absolute_url : https://ftp.icm.edu.pl/packages/mp3/59/Shalala_Boom_Were_Going_to_Kiss_Uncle_Down.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Shalala_Boom_Were_Going_to_Kiss_Uncle_Down.mp3</span><br><span class="line"><span class="comment"># get 1st </span></span><br><span class="line">2023-01-04 14:00:15 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&gt; (referer: None)</span><br><span class="line"><span class="comment"># download 1st </span></span><br><span class="line">2023-01-04 14:00:15 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Blood__AAA_version.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Blood__AAA_version.mp3</span><br><span class="line">2023-01-04 14:00:15 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line"><span class="comment"># scrapy.Field 1st</span></span><br><span class="line"><span class="comment"># save file Blood__AAA_version.mp3</span></span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Blood__AAA_version.mp3&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&#x27;</span>], </span><br><span class="line"><span class="string">&#x27;files&#x27;</span>: [</span><br><span class="line">	&#123;	<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Blood__AAA_version.mp3&#x27;</span>, </span><br><span class="line">		<span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;Blood__AAA_version.mp3&#x27;</span>, </span><br><span class="line">		<span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;8013d9ea5f6d3d596f76d8047b41a7f9&#x27;</span>, </span><br><span class="line">		<span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;downloaded&#x27;</span></span><br><span class="line">	&#125;]&#125;</span><br><span class="line">2023-01-04 14:00:15 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3&gt; (referer: None)</span><br><span class="line">2023-01-04 14:00:15 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Prognoza_Pogody.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Prognoza_Pogody.mp3</span><br><span class="line">2023-01-04 14:00:16 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Prognoza_Pogody.mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Prognoza_Pogody.mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;Prognoza_Pogody.mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;7adb9211d73199b0e6c347fff5b718cb&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;downloaded&#x27;</span>&#125;]&#125;</span><br><span class="line">2023-01-04 14:00:16 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&gt; (referer: None)</span><br><span class="line">2023-01-04 14:00:16 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Klan_Soundtrack__hardcore_version.mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">Klan_Soundtrack__hardcore_version.mp3</span><br><span class="line">2023-01-04 14:00:16 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;Klan_Soundtrack__hardcore_version.mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/Klan_Soundtrack__hardcore_version.mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;Klan_Soundtrack__hardcore_version.mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;e45ea17db6cb6d3a62a5fe2cad1aea54&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;downloaded&#x27;</span>&#125;]&#125;</span><br><span class="line">2023-01-04 14:00:16 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&gt; (referer: None)</span><br><span class="line">2023-01-04 14:00:16 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from &lt;GET https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&gt; referred <span class="keyword">in</span> &lt;None&gt;</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3</span><br><span class="line">CustomFilePipeLines　===========</span><br><span class="line">DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3</span><br><span class="line">2023-01-04 14:00:16 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://ftp.icm.edu.pl/packages/mp3/59/&gt;</span><br><span class="line">&#123;<span class="string">&#x27;Title&#x27;</span>: <span class="string">&#x27;DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>, <span class="string">&#x27;file_urls&#x27;</span>: [<span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>], <span class="string">&#x27;files&#x27;</span>: [&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://ftp.icm.edu.pl/packages/mp3/59/DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>, <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;DeeJay_Somic_-_Nowy_Vizir(the_commercial_compilation).mp3&#x27;</span>, <span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;c323a1ff9802b7e4a5b2447350b388a9&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;downloaded&#x27;</span>&#125;]&#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h3 id="download-image-by-python"><a href="#download-image-by-python" class="headerlink" title="download image by python"></a>download image by python</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"><span class="keyword">import</span> ppt.items <span class="keyword">as</span> items</span><br><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BeautySpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    JPG = <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">    PNG = <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">    IMAGE_FOLDER = <span class="string">&#x27;images&#x27;</span></span><br><span class="line">    IMAGE_MAX = <span class="number">5</span></span><br><span class="line">    name = <span class="string">&#x27;beauty&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.ptt.cc&#x27;</span>]</span><br><span class="line">    URL_ENTRY = <span class="string">&#x27;https://www.ptt.cc/bbs/Beauty/index.html&#x27;</span></span><br><span class="line">    index = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post_parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.index &lt; self.IMAGE_MAX:</span><br><span class="line">            title = response.xpath(<span class="string">&quot;(//div[@class=&#x27;article-metaline&#x27;]//span[@class=&#x27;article-meta-value&#x27;])[2]/text()&quot;</span>).get()</span><br><span class="line">            lists = response.xpath(<span class="string">&quot;//div[@class=&#x27;richcontent&#x27;]&quot;</span>)</span><br><span class="line">            list_index = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">list</span> <span class="keyword">in</span> lists:</span><br><span class="line">                image_url = <span class="built_in">list</span>.xpath(<span class="string">&quot;.//img/@src&quot;</span>).get()</span><br><span class="line">                loader = ItemLoader(item=items.PptPostItem())</span><br><span class="line">                loader.add_value(<span class="string">&#x27;image_urls&#x27;</span>, [image_url])</span><br><span class="line">                loader.add_value(<span class="string">&#x27;index&#x27;</span>, self.index)</span><br><span class="line">                <span class="keyword">if</span> self.PNG <span class="keyword">in</span> image_url:</span><br><span class="line">                    file_name = <span class="string">f&quot;<span class="subst">&#123;title&#125;</span><span class="subst">&#123;list_index&#125;</span><span class="subst">&#123;self.PNG&#125;</span>&quot;</span></span><br><span class="line">                <span class="keyword">elif</span> self.JPG <span class="keyword">in</span> image_url:</span><br><span class="line">                    file_name = <span class="string">f&quot;<span class="subst">&#123;title&#125;</span><span class="subst">&#123;list_index&#125;</span><span class="subst">&#123;self.JPG&#125;</span>&quot;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    file_name = <span class="string">f&quot;<span class="subst">&#123;title&#125;</span><span class="subst">&#123;list_index&#125;</span>None<span class="subst">&#123;self.JPG&#125;</span>&quot;</span></span><br><span class="line">                list_index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                self.image_download(image_url, file_name, self.IMAGE_FOLDER)</span><br><span class="line">                self.index += <span class="number">1</span></span><br><span class="line">                <span class="keyword">yield</span> loader.load_item()</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> self.index &gt; self.IMAGE_MAX:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">image_download</span>(<span class="params">self, url, name, folder</span>):</span></span><br><span class="line">        <span class="built_in">dir</span>=os.path.abspath(folder)</span><br><span class="line">        work_path=os.path.join(<span class="built_in">dir</span>,name)</span><br><span class="line">        urllib.request.urlretrieve(url, work_path)</span><br></pre></td></tr></table></figure>

<h3 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h3><h4 id="Parse-Command"><a href="#Parse-Command" class="headerlink" title="Parse Command"></a>Parse Command</h4><font color=red>
    Seem scrapy has issue
</font>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="comment"># from scrapy.shell import inspect_response</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">      name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">      link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="comment"># add meta for callback parameter</span></span><br><span class="line">      <span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country, meta=&#123;<span class="string">&#x27;country_name&#x27;</span>: name&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># inspect_response(response, self)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    name = response.request.meta[<span class="string">&#x27;country_name&#x27;</span>]</span><br><span class="line">    rows = response.xpath(<span class="string">&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">      year = row.xpath(<span class="string">&quot;./td[1]/text()&quot;</span>).get()</span><br><span class="line">      population = row.xpath(<span class="string">&quot;./td[2]/strong/text()&quot;</span>).get()</span><br><span class="line">      <span class="keyword">yield</span> &#123;</span><br><span class="line">        <span class="string">&#x27;country_name&#x27;</span> : name,</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span> : year,</span><br><span class="line">        <span class="string">&#x27;population&#x27;</span>: population</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># seem scrapy have meta&#x27;s issue</span></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;</span><br><span class="line">scrapy parse --spider=countries -c parse_country --meta=<span class="string">&#x27;&#123;&quot;country_name&quot; : &quot;China&quot;&#125;&#x27;</span> https://www.worldometers.info/world-population/china-population/</span><br><span class="line">Usage</span><br><span class="line">=====</span><br><span class="line">  scrapy parse [options] &lt;url&gt;</span><br><span class="line"><span class="comment"># issue for meta input</span></span><br><span class="line">parse: error: Invalid -m/--meta value, pass a valid json string to -m or --meta. Example: --meta=<span class="string">&#x27;&#123;&quot;foo&quot; : &quot;bar&quot;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="Scrapy-Shell"><a href="#Scrapy-Shell" class="headerlink" title="Scrapy Shell"></a>Scrapy Shell</h4><font color=red>
    Seem scrapy has issue
</font>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.shell <span class="keyword">import</span> inspect_response</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">      name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">      link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="comment"># add meta for callback parameter</span></span><br><span class="line">      <span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country, meta=&#123;<span class="string">&#x27;country_name&#x27;</span>: name&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    inspect_response(response, self)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    <span class="comment"># name = response.request.meta[&#x27;country_name&#x27;]</span></span><br><span class="line">    <span class="comment"># rows = response.xpath(&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;)</span></span><br><span class="line">    <span class="comment"># for row in rows:</span></span><br><span class="line">    <span class="comment">#   year = row.xpath(&quot;./td[1]/text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   population = row.xpath(&quot;./td[2]/strong/text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   yield &#123;</span></span><br><span class="line">    <span class="comment">#     &#x27;country_name&#x27; : name,</span></span><br><span class="line">    <span class="comment">#     &#x27;year&#x27; : year,</span></span><br><span class="line">    <span class="comment">#     &#x27;population&#x27;: population</span></span><br><span class="line">    <span class="comment">#   &#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl countries</span><br><span class="line"><span class="comment"># It doesn&#x27;t open scrapy shell after run</span></span><br><span class="line"><span class="comment"># seem scrapy issue </span></span><br></pre></td></tr></table></figure>

<h4 id="Open-in-browser"><a href="#Open-in-browser" class="headerlink" title="Open in browser"></a>Open in browser</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.response <span class="keyword">import</span> open_in_browser</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># countries = response.xpath(&quot;//td/a&quot;)</span></span><br><span class="line">    <span class="comment"># for country in countries:</span></span><br><span class="line">    <span class="comment">#   name = country.xpath(&quot;.//text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   link = country.xpath(&quot;.//@href&quot;).get()</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    <span class="keyword">yield</span> response.follow(url=<span class="string">&quot;https://www.worldometers.info/world-population/china-population/&quot;</span>, callback=self.parse_country, meta=&#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    open_in_browser(response)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    <span class="comment"># name = response.request.meta[&#x27;country_name&#x27;]</span></span><br><span class="line">    <span class="comment"># rows = response.xpath(&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;)</span></span><br><span class="line">    <span class="comment"># for row in rows:</span></span><br><span class="line">    <span class="comment">#   year = row.xpath(&quot;./td[1]/text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   population = row.xpath(&quot;./td[2]/strong/text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   yield &#123;</span></span><br><span class="line">    <span class="comment">#     &#x27;country_name&#x27; : name,</span></span><br><span class="line">    <span class="comment">#     &#x27;year&#x27; : year,</span></span><br><span class="line">    <span class="comment">#     &#x27;population&#x27;: population</span></span><br><span class="line">    <span class="comment">#   &#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl countries</span><br><span class="line"><span class="comment"># then browser open</span></span><br></pre></td></tr></table></figure>

<h4 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries_logging&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># countries = response.xpath(&quot;//td/a&quot;)</span></span><br><span class="line">    <span class="comment"># for country in countries:</span></span><br><span class="line">    <span class="comment">#   name = country.xpath(&quot;.//text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   link = country.xpath(&quot;.//@href&quot;).get()</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    <span class="keyword">yield</span> response.follow(url=<span class="string">&quot;https://www.worldometers.info/world-population/china-population/&quot;</span>, callback=self.parse_country, meta=&#123;<span class="string">&#x27;country_name&#x27;</span>: <span class="string">&#x27;China&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># logging.info(response.status)</span></span><br><span class="line">    <span class="comment"># 2022-12-19 17:08:59 [root] INFO: 200</span></span><br><span class="line">    <span class="comment"># 2022-12-19 17:08:59 [scrapy.core.engine] INFO: Closing spider (finished)</span></span><br><span class="line">    logging.warning(response.status)</span><br><span class="line">    <span class="comment"># 2022-12-19 17:10:58 [root] WARNING: 200</span></span><br><span class="line">    <span class="comment"># 2022-12-19 17:10:58 [scrapy.core.engine] INFO: Closing spider (finished)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    <span class="comment"># name = response.request.meta[&#x27;country_name&#x27;]</span></span><br><span class="line">    <span class="comment"># rows = response.xpath(&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;)</span></span><br><span class="line">    <span class="comment"># for row in rows:</span></span><br><span class="line">    <span class="comment">#   year = row.xpath(&quot;./td[1]/text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   population = row.xpath(&quot;./td[2]/strong/text()&quot;).get()</span></span><br><span class="line">    <span class="comment">#   yield &#123;</span></span><br><span class="line">    <span class="comment">#     &#x27;country_name&#x27; : name,</span></span><br><span class="line">    <span class="comment">#     &#x27;year&#x27; : year,</span></span><br><span class="line">    <span class="comment">#     &#x27;population&#x27;: population</span></span><br><span class="line">    <span class="comment">#   &#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run </span></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries_logging</span><br><span class="line">......</span><br><span class="line"><span class="comment"># logging show</span></span><br><span class="line">2022-12-19 17:10:58 [root] WARNING: 200</span><br><span class="line">2022-12-19 17:10:58 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">2022-12-19 17:10:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="run-python-debug-need-set-to-corect-python-enviroment"><a href="#run-python-debug-need-set-to-corect-python-enviroment" class="headerlink" title="run python debug(need set to corect python enviroment)"></a>run python debug(need set to corect python enviroment)</h4><h5 id="runner-py"><a href="#runner-py" class="headerlink" title="runner.py"></a>runner.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># runner.py for worldmeters.spiders.countries</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerProcess</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"><span class="comment"># set crawl code</span></span><br><span class="line"><span class="keyword">from</span> worldmeters.spiders.countries <span class="keyword">import</span> CountriesSpider</span><br><span class="line"></span><br><span class="line"><span class="comment"># get configure</span></span><br><span class="line">process = CrawlerProcess(settings=get_project_settings())</span><br><span class="line"><span class="comment"># set crawl entry</span></span><br><span class="line">process.crawl(CountriesSpider)</span><br><span class="line">process.start()</span><br></pre></td></tr></table></figure>

<h5 id="F5-run-debug"><a href="#F5-run-debug" class="headerlink" title="F5 run debug"></a>F5 run debug</h5><h4 id="Test-Scrapy"><a href="#Test-Scrapy" class="headerlink" title="Test Scrapy"></a>Test Scrapy</h4><ul>
<li>conda 3.7 scrapy 1.6 (wisted 21.7.0)<ul>
<li>scrapy shell - ok</li>
<li>scrapy shell(inspect_response) - ok </li>
<li>Parse Command - not ok</li>
</ul>
</li>
<li>conda 3.7 scrapy 2.62 (wisted 21.7.0)<ul>
<li>scrapy shell - ok</li>
<li>scrapy shell(inspect_response) - ok </li>
<li>Parse Command - not ok</li>
</ul>
</li>
<li>conda 3.9 scrapy 2.62 (wisted 21.7.0)<ul>
<li>scrapy shell - ok</li>
<li>scrapy shell(inspect_response) - not ok </li>
<li>Parse Command - not ok</li>
</ul>
</li>
<li>python 3.10 scrapy 2.71<ul>
<li>scrapy shell - ok</li>
<li>scrapy shell(inspect_response) - not ok </li>
<li>Parse Command - not ok</li>
</ul>
</li>
</ul>
<h3 id="XPath-expression"><a href="#XPath-expression" class="headerlink" title="XPath expression"></a>XPath expression</h3><h4 id="Xpath-guide"><a href="#Xpath-guide" class="headerlink" title="Xpath guide"></a>Xpath guide</h4><h5 id="function"><a href="#function" class="headerlink" title="function"></a>function</h5><ul>
<li>normalize-space<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># All leading whitespace is removed.</span></span><br><span class="line"><span class="comment"># All trailing whitespace is removed.</span></span><br><span class="line"><span class="comment"># Within the string, any sequence of whitespace characters is replaced with a single space.</span></span><br><span class="line"><span class="comment"># Removes all new lines and tabs present in a string</span></span><br><span class="line">category = listing.xpath(<span class="string">&quot;normalize-space(.//span[@class=&#x27;category&#x27;]/div/text())&quot;</span>).get()</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="test-html-for-XPath-expression"><a href="#test-html-for-XPath-expression" class="headerlink" title="test html for XPath expression"></a>test html for XPath expression</h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>XPath and CSS Selectors<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>XPath Selectors simplified<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;intro&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">            I&#x27;m paragraph within a div with a class set to intro</span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;location&quot;</span>&gt;</span>I&#x27;m a span with ID set to location and i&#x27;m within a paragraph<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;outside&quot;</span>&gt;</span>I&#x27;m a paragraph with ID set to outside and i&#x27;m within a div with a class set to intro<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;outro&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;unique&quot;</span>&gt;</span>I&#x27;m in a div with a class attribute set to outro<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Hi i&#x27;m placed immediately after a div<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&#x27;intro&#x27;</span>&gt;</span>Div with a class attribute set to intro<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span> <span class="attr">id</span>=<span class="string">&quot;items&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span> <span class="attr">data-identifier</span>=<span class="string">&quot;7&quot;</span>&gt;</span>Item 1<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span>&gt;</span>Item 2<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span>&gt;</span>Item 3<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span>&gt;</span>Item 4<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.google.com&quot;</span>&gt;</span>Google<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.google.fr&quot;</span>&gt;</span>Google France<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="XPath-expression-1"><a href="#XPath-expression-1" class="headerlink" title="XPath expression"></a>XPath expression</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">//div[@class=&quot;intro&quot; or @class=&#x27;outro&#x27;]/p/text()</span><br><span class="line">//a[starts-<span class="keyword">with</span>(@href,<span class="string">&#x27;https&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># not support XPath version 1</span></span><br><span class="line">//a[ends-<span class="keyword">with</span>(@href,<span class="string">&#x27;fr&#x27;</span>)] </span><br><span class="line"></span><br><span class="line">//a[contains(@href,<span class="string">&#x27;fr&#x27;</span>)]</span><br><span class="line">//a[contains(@href,<span class="string">&#x27;google&#x27;</span>)]</span><br><span class="line">//a[contains(text(),<span class="string">&#x27;France&#x27;</span>)]</span><br><span class="line">//ul[@<span class="built_in">id</span>=<span class="string">&#x27;items&#x27;</span>]/li[<span class="number">1</span>]</span><br><span class="line">//ul[@<span class="built_in">id</span>=<span class="string">&#x27;items&#x27;</span>]/li[position()=<span class="number">1</span> <span class="keyword">or</span> position()=<span class="number">4</span>]</span><br><span class="line">//ul[@<span class="built_in">id</span>=<span class="string">&#x27;items&#x27;</span>]/li[position()=<span class="number">1</span> <span class="keyword">or</span> position()=last()]</span><br><span class="line">//ul[@<span class="built_in">id</span>=<span class="string">&#x27;items&#x27;</span>]/li[position()&gt;<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/parent::div</span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/parent::node()</span><br><span class="line"><span class="comment"># 所有 ancestor</span></span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/ancestor::node()</span><br><span class="line"><span class="comment"># 包含本身</span></span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/ancestor-<span class="keyword">or</span>-self::node()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 之前的 element</span></span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/preceding::node()</span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/preceding::h1</span><br><span class="line"><span class="comment"># nothing</span></span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;unique&#x27;</span>]/preceding::body</span><br><span class="line"><span class="comment"># 之前的 element(同層)</span></span><br><span class="line">//p[@<span class="built_in">id</span>=<span class="string">&#x27;outside&#x27;</span>]/preceding-sibling::node()</span><br><span class="line"></span><br><span class="line">//div[@class=&#x27;intro&#x27;]/child::p</span><br><span class="line">//div[@class=&#x27;intro&#x27;]/child::node()</span><br><span class="line"><span class="comment"># 後面所有 element</span></span><br><span class="line">//div[@class=&#x27;intro&#x27;]/following::node() 後面所有 element</span><br><span class="line">//div[@class=&#x27;intro&#x27;]/following-sibling::node()</span><br><span class="line"><span class="comment"># 內層</span></span><br><span class="line">//div[@class=&#x27;intro&#x27;]/descendant::node()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2nd pattern (index 1)</span></span><br><span class="line">//a[@class=&#x27;lister-page-next next-page&#x27;])[2]</span><br><span class="line"></span><br><span class="line"><span class="comment"># contain class</span></span><br><span class="line">//div[contains(@class,&quot;ReactVirtualized__Table__row tableRow___3EtiS &quot;)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tag svg </span></span><br><span class="line">//*[local-name() = <span class="string">&#x27;svg&#x27;</span>][contains(@aria-label, <span class="string">&#x27;搜尋&#x27;</span>)]</span><br><span class="line"><span class="comment"># aria-label field</span></span><br><span class="line">//<span class="built_in">input</span>[contains(@aria-label, <span class="string">&#x27;搜尋輸入&#x27;</span>)]</span><br></pre></td></tr></table></figure>

<h3 id="CSS-selectors"><a href="#CSS-selectors" class="headerlink" title="CSS selectors"></a>CSS selectors</h3><h4 id="test-html-for-CSS-selectors"><a href="#test-html-for-CSS-selectors" class="headerlink" title="test html for CSS selectors"></a>test html for CSS selectors</h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>XPath and CSS Selectors<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>CSS Selectors simplified<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;intro&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">            I&#x27;m paragraph within a div with a class set to intro</span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;location&quot;</span>&gt;</span>I&#x27;m a span with ID set to location and i&#x27;m within a paragraph<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;outside&quot;</span>&gt;</span>I&#x27;m a paragraph with ID set to outside and i&#x27;m within a div with a class set to intro<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Hi i&#x27;m placed immediately after a div with a class set to intro<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&#x27;intro&#x27;</span>&gt;</span>Div with a class attribute set to intro<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span> <span class="attr">id</span>=<span class="string">&quot;items&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span> <span class="attr">data-identifier</span>=<span class="string">&quot;7&quot;</span>&gt;</span>Item 1<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span>&gt;</span>Item 2<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span>&gt;</span>Item 3<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">li</span>&gt;</span>Item 4<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.google.com&quot;</span>&gt;</span>Google<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.google.fr&quot;</span>&gt;</span>Google France<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&#x27;bold italic&#x27;</span>&gt;</span>Hi, I have two classes<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&#x27;bold&#x27;</span>&gt;</span>Hi i&#x27;m bold<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="CSS-selectors-1"><a href="#CSS-selectors-1" class="headerlink" title="CSS selectors"></a>CSS selectors</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">li[data-identifier&#x3D;7]</span><br><span class="line">a[href^&#x3D;&#39;https&#39;]</span><br><span class="line">a[href$&#x3D;&#39;fr&#39;]</span><br><span class="line">a[href*&#x3D;&#39;google&#39;]</span><br><span class="line"></span><br><span class="line">div.intro</span><br><span class="line">div.intro p, #location</span><br><span class="line"></span><br><span class="line"># all children</span><br><span class="line">div.intro &gt; p </span><br><span class="line">#items  &gt; li</span><br><span class="line"></span><br><span class="line"># 後面第一個(非內部)</span><br><span class="line">div.intro + p</span><br><span class="line"></span><br><span class="line"># 後面所有(非內部)</span><br><span class="line">div.intro ~ p</span><br><span class="line"></span><br><span class="line"># li 同層的 item</span><br><span class="line">li:nth-child(1), li:nth-child(3)</span><br><span class="line">li:nth-child(odd)</span><br><span class="line">li:nth-child(even)</span><br></pre></td></tr></table></figure>

<h3 id="run-by-python"><a href="#run-by-python" class="headerlink" title="run by python"></a>run by python</h3><h4 id="python-run-process"><a href="#python-run-process" class="headerlink" title="python run process"></a>python run process</h4><h5 id="run-scrapy-subprocess-py"><a href="#run-scrapy-subprocess-py" class="headerlink" title="run_scrapy_subprocess.py"></a>run_scrapy_subprocess.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line"><span class="comment"># python run process</span></span><br><span class="line">subprocess.run(<span class="string">&#x27;scrapy crawl articles&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="run-18"><a href="#run-18" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\109-scrapy-practice2\ithome2&gt;python run_scrapy_subprocess.py</span><br></pre></td></tr></table></figure>

<h4 id="scrapy-run-crawler-Process"><a href="#scrapy-run-crawler-Process" class="headerlink" title="scrapy run crawler Process"></a>scrapy run crawler Process</h4><h5 id="run-scrapy-crawlerprocess-py"><a href="#run-scrapy-crawlerprocess-py" class="headerlink" title="run_scrapy_crawlerprocess.py"></a>run_scrapy_crawlerprocess.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerProcess</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"></span><br><span class="line"><span class="comment"># scrapy run crawler Process</span></span><br><span class="line">process = CrawlerProcess(get_project_settings())</span><br><span class="line">process.crawl(<span class="string">&#x27;articles&#x27;</span>)</span><br><span class="line">process.start()</span><br></pre></td></tr></table></figure>

<h5 id="run-19"><a href="#run-19" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\109-scrapy-practice2\ithome2&gt;python run_scrapy_crawlerprocess.py</span><br></pre></td></tr></table></figure>


<h4 id="run-by-Twisted-reactor"><a href="#run-by-Twisted-reactor" class="headerlink" title="run by Twisted reactor"></a>run by Twisted reactor</h4><h5 id="run-scrapy-crawlerrunner-py"><a href="#run-scrapy-crawlerrunner-py" class="headerlink" title="run_scrapy_crawlerrunner.py"></a>run_scrapy_crawlerrunner.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span>  scrapy.crawler <span class="keyword">import</span> CrawlerRunner</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.reactor <span class="keyword">import</span> install_reactor</span><br><span class="line"><span class="comment"># need put in front of &quot;from twisted.internet import reactor&quot;</span></span><br><span class="line">install_reactor(<span class="string">&#x27;twisted.internet.asyncioreactor.AsyncioSelectorReactor&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> reactor</span><br><span class="line"></span><br><span class="line"><span class="comment"># run by Twisted reactor</span></span><br><span class="line">runner = CrawlerRunner(get_project_settings())</span><br><span class="line">d = runner.crawl(<span class="string">&#x27;articles&#x27;</span>)</span><br><span class="line"></span><br><span class="line">d.addBoth(<span class="keyword">lambda</span> _: reactor.stop())</span><br><span class="line">reactor.run()</span><br></pre></td></tr></table></figure>

<h5 id="run-20"><a href="#run-20" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\109-scrapy-practice2\ithome2&gt;python run_scrapy_crawlerrunner.py</span><br></pre></td></tr></table></figure>

<h3 id="Tool"><a href="#Tool" class="headerlink" title="Tool"></a>Tool</h3><h4 id="Evaluate-and-validate-XPath-x2F-CSS-selectors-in-Chrome-Developer-Tools"><a href="#Evaluate-and-validate-XPath-x2F-CSS-selectors-in-Chrome-Developer-Tools" class="headerlink" title="Evaluate and validate XPath&#x2F;CSS selectors in Chrome Developer Tools"></a>Evaluate and validate XPath&#x2F;CSS selectors in Chrome Developer Tools</h4><ul>
<li>open Chrome Devtools</li>
<li>select Elements</li>
<li>Press <code>Ctrl</code> + <code>F</code> enable DOM searching</li>
</ul>
<h4 id="VscCode-automatically-formatted-the-JSON-file"><a href="#VscCode-automatically-formatted-the-JSON-file" class="headerlink" title="VscCode automatically formatted the JSON file"></a>VscCode automatically formatted the JSON file</h4><ul>
<li>press <code>Alt</code> + <code>sheft</code> + <code>F</code></li>
</ul>
<h4 id="vs-code-plugin"><a href="#vs-code-plugin" class="headerlink" title="vs code plugin"></a>vs code plugin</h4><ul>
<li>Python extension for Visual Studio Code(Microsoft)</li>
<li>Python Environment Manager</li>
<li>SQLite : explore and query SQLite databases.</li>
<li>Sort JSON array : sort json array by certain field</li>
</ul>
<h4 id="excel-開-utf-8-csv-file"><a href="#excel-開-utf-8-csv-file" class="headerlink" title="excel 開  utf-8 .csv file"></a>excel 開  utf-8 .csv file</h4><div style="width:500px">
    <img src="/2022/12/15/python-9/pic11.png" class="" title="pic11">
</div>

<div style="width:500px">
    <img src="/2022/12/15/python-9/pic12.png" class="" title="pic12">
</div>

<h4 id="Chrome-plugin"><a href="#Chrome-plugin" class="headerlink" title="Chrome plugin"></a>Chrome plugin</h4><ul>
<li><a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/json-viewer/gbmdgpbipfallnflgajpaliibnhdgobh/related">JSON Viewer</a></li>
<li><a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/modheader-modify-http-hea/idgpnmonknjnojddfkpgkljpfnnfcklj?hl=en">ModHeader - Modify HTTP headers</a></li>
</ul>
<h3 id="Wait"><a href="#Wait" class="headerlink" title="Wait"></a>Wait</h3><ul>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html">scrapy detail</a></li>
<li>python 正規表達式 - import re</li>
<li>CSS selectors</li>
<li>python @classmethod</li>
<li>Python MongoDB</li>
<li>class str</li>
</ul>
<h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul>
<li><a target="_blank" rel="noopener" href="https://try.jsoup.org/">CSS selectors practice</a></li>
<li><a target="_blank" rel="noopener" href="https://scrapinghub.github.io/xpath-playground/">XPath expression practice</a></li>
<li><a target="_blank" rel="noopener" href="https://www.qafox.com/xpath-expressions-css-selectors/">XPath Expressions and CSS Selectors</a></li>
<li><a target="_blank" rel="noopener" href="https://www.w3schools.com/xml/xpath_intro.asp">W3C XPath Tutorial</a></li>
<li><a target="_blank" rel="noopener" href="https://www.w3schools.com/cssref/css_selectors.php">W3C CSS Selector Reference</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/debug.html">Debugging Spiders(document)</a></li>
<li><a target="_blank" rel="noopener" href="https://checkforcloudflare.selesti.com/">Check for Cloudflare</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/clemfromspace/scrapy-cloudflare-middleware">scrapy-cloudflare-middleware</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/XPath">XPath document</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tutorialspoint.com/xpath/index.htm">XPath Tutorial</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/media-pipeline.html">Downloading and processing files and images</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html">Architecture overview</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/fake-useragent/fake-useragent">fake-useragent</a></li>
<li><a target="_blank" rel="noopener" href="https://ithelp.ithome.com.tw/users/20107875/ironman/2209">爬蟲在手、資料我有 - 30 天 Scrapy 爬蟲實戰 系列</a></li>
<li><a target="_blank" rel="noopener" href="https://splash-cn-doc.readthedocs.io/zh_CN/latest/scrapy-splash-toturial.html">splash中文文件</a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/crawling/" rel="tag"># crawling</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/12/04/python-8/" rel="prev" title="Python Scrapy Example(爬蟲框架)">
                  <i class="fa fa-chevron-left"></i> Python Scrapy Example(爬蟲框架)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/12/22/python-10/" rel="next" title="Python Splash 說明">
                  Python Splash 說明 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Robert Kao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="總字數">2.7m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="所需總閱讀時間">40:58</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  


<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://hot5656-blog.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://hot5656.github.io/2022/12/15/python-9/";
    this.page.identifier = "2022/12/15/python-9/";
    this.page.title = "Python Scrapy 說明(爬蟲框架)";
    };
  NexT.utils.loadComments('#disqus_thread', () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://hot5656-blog.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
