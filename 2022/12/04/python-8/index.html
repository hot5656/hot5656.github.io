<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hot5656.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.2.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/search.json","localsearch":{"enable":"enable","trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="scrapy installinstallpython 3.11 有問題, python 3.10 ok 12345678# install myenv10_scrapyrem cd \app\python_env\rem py -3.10 -m virtualenv myenv10_scrapy# install pip install scrapy pip install pylint pip">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Scrapy Example(爬蟲框架)">
<meta property="og:url" content="https://hot5656.github.io/2022/12/04/python-8/index.html">
<meta property="og:site_name" content="Robert 雜記">
<meta property="og:description" content="scrapy installinstallpython 3.11 有問題, python 3.10 ok 12345678# install myenv10_scrapyrem cd \app\python_env\rem py -3.10 -m virtualenv myenv10_scrapy# install pip install scrapy pip install pylint pip">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://hot5656.github.io/2022/12/04/python-8/pic1.png">
<meta property="article:published_time" content="2022-12-04T13:06:54.000Z">
<meta property="article:modified_time" content="2024-04-23T09:22:41.733Z">
<meta property="article:author" content="Robert Kao">
<meta property="article:tag" content="python">
<meta property="article:tag" content="crawling">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hot5656.github.io/2022/12/04/python-8/pic1.png">


<link rel="canonical" href="https://hot5656.github.io/2022/12/04/python-8/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>
<title>Python Scrapy Example(爬蟲框架) | Robert 雜記</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Robert 雜記</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔列表</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#scrapy-install"><span class="nav-number">1.</span> <span class="nav-text">scrapy install</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#install"><span class="nav-number">1.1.</span> <span class="nav-text">install</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrapy-version-amp-help"><span class="nav-number">1.2.</span> <span class="nav-text">scrapy version &amp; help</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrapy-bench-simple-test"><span class="nav-number">1.3.</span> <span class="nav-text">scrapy bench(simple test)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrapy-fetch-get-web-page"><span class="nav-number">1.4.</span> <span class="nav-text">scrapy fetch(get web page)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#run-scrapy-for-worldometers"><span class="nav-number">2.</span> <span class="nav-text">run scrapy for worldometers</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#create-project"><span class="nav-number">2.1.</span> <span class="nav-text">create project</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#create-spider"><span class="nav-number">2.2.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrape-shell"><span class="nav-number">2.3.</span> <span class="nav-text">scrape shell</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#worldometers-not-support-Crawled-no-robots-txt"><span class="nav-number">2.4.</span> <span class="nav-text">worldometers not support Crawled(no robots.txt)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#show-body"><span class="nav-number">2.5.</span> <span class="nav-text">show body</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrape-view"><span class="nav-number">2.6.</span> <span class="nav-text">scrape view</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#XPath-expression-amp-CSS-selectors"><span class="nav-number">2.7.</span> <span class="nav-text">XPath expression &amp; CSS selectors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#modify-worldmeters-worldmeters-spiders-countries-py-for-XPath-expression"><span class="nav-number">2.8.</span> <span class="nav-text">modify worldmeters\worldmeters\spiders\countries.py for XPath expression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-scrapy-clawer"><span class="nav-number">2.9.</span> <span class="nav-text">run scrapy clawer</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Worldometers-Get-Countries-Population"><span class="nav-number">3.</span> <span class="nav-text">Worldometers Get Countries Population</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Get-country-name-and-link"><span class="nav-number">3.1.</span> <span class="nav-text">Get country name and link</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#try-xpath"><span class="nav-number">3.1.1.</span> <span class="nav-text">try xpath</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#countries-py"><span class="nav-number">3.1.2.</span> <span class="nav-text">countries.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run"><span class="nav-number">3.1.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fetch-country-link-page"><span class="nav-number">3.2.</span> <span class="nav-text">fetch country link page</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#countries-py-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">countries.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-1"><span class="nav-number">3.2.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#get-country%E2%80%99s-year-and-population"><span class="nav-number">3.3.</span> <span class="nav-text">get country’s year and population</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#countries-py-2"><span class="nav-number">3.3.1.</span> <span class="nav-text">countries.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-2"><span class="nav-number">3.3.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#class-use-global-variable-for-country-name-not-work-%E2%80%A6"><span class="nav-number">3.4.</span> <span class="nav-text">class use global variable for country name(not work …)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#countries-py-3"><span class="nav-number">3.4.1.</span> <span class="nav-text">countries.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-3"><span class="nav-number">3.4.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#add-meta-for-callback-parameter"><span class="nav-number">3.5.</span> <span class="nav-text">add meta for callback parameter</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#countries-py-4"><span class="nav-number">3.5.1.</span> <span class="nav-text">countries.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-4"><span class="nav-number">3.5.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#data-generate-by-dataset-json-csv-xml"><span class="nav-number">3.6.</span> <span class="nav-text">data generate by dataset(json, csv, xml)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Debt-to-GDP-ratio-by-country"><span class="nav-number">4.</span> <span class="nav-text">Debt to GDP ratio by country</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#create-spider-1"><span class="nav-number">4.1.</span> <span class="nav-text">create spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#countries-py-5"><span class="nav-number">4.2.</span> <span class="nav-text">countries.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-wait-new-method"><span class="nav-number">4.3.</span> <span class="nav-text">run(wait new method)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tinydeal"><span class="nav-number">5.</span> <span class="nav-text">tinydeal</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#open-robots-txt"><span class="nav-number">5.1.</span> <span class="nav-text">open robots.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#open-web-site-then-disable-Javascript"><span class="nav-number">5.2.</span> <span class="nav-text">open web site then disable Javascript</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#create-project-and-spider"><span class="nav-number">5.3.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#update-special-offers-py"><span class="nav-number">5.4.</span> <span class="nav-text">update special_offers.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#update-special-offers-py-get-product-information"><span class="nav-number">5.5.</span> <span class="nav-text">update special_offers.py (get product information)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-5"><span class="nav-number">5.6.</span> <span class="nav-text">run</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#settings-py-change-json-for-utf-8-format-no-show-unicode"><span class="nav-number">5.7.</span> <span class="nav-text">settings.py - change json for utf-8 format(no show unicode)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#special-offers-py-dealing-with-pagination-csv"><span class="nav-number">5.8.</span> <span class="nav-text">special_offers.py - dealing with pagination(csv)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#change-User-Agent"><span class="nav-number">5.9.</span> <span class="nav-text">change User-Agent</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#check-scrapy-heads"><span class="nav-number">5.9.1.</span> <span class="nav-text">check scrapy heads</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#check-browser-user-agent"><span class="nav-number">5.9.2.</span> <span class="nav-text">check browser user agent</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#change-User-Agent-by-settings-py-2-ways-option"><span class="nav-number">5.9.3.</span> <span class="nav-text">change User-Agent by settings.py(2 ways option)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#change-User-Agent-by-py"><span class="nav-number">5.9.4.</span> <span class="nav-text">change User-Agent by .py</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#glassesshop"><span class="nav-number">6.</span> <span class="nav-text">glassesshop</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#create-project-and-spider-1"><span class="nav-number">6.1.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#https-www-glassesshop-com-robots-txt"><span class="nav-number">6.2.</span> <span class="nav-text">https:&#x2F;&#x2F;www.glassesshop.com&#x2F;robots.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#products-py"><span class="nav-number">6.3.</span> <span class="nav-text">products.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-6"><span class="nav-number">6.4.</span> <span class="nav-text">run</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#json"><span class="nav-number">6.5.</span> <span class="nav-text">json</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#imdb-crawl-template"><span class="nav-number">7.</span> <span class="nav-text">imdb(crawl template)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#create-project-and-spider-2"><span class="nav-number">7.1.</span> <span class="nav-text">create project and spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#best-movies-py"><span class="nav-number">7.2.</span> <span class="nav-text">best_movies.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#get-link"><span class="nav-number">7.3.</span> <span class="nav-text">get link</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#best-movies-py-1"><span class="nav-number">7.3.1.</span> <span class="nav-text">best_movies.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#settings-py"><span class="nav-number">7.3.2.</span> <span class="nav-text">settings.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-7"><span class="nav-number">7.3.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#get-movies-information"><span class="nav-number">7.4.</span> <span class="nav-text">get movies information</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#runner-py"><span class="nav-number">7.4.1.</span> <span class="nav-text">runner.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#best-movies-py-2"><span class="nav-number">7.4.2.</span> <span class="nav-text">best_movies.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-8"><span class="nav-number">7.4.3.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Following-liks-in-pagination"><span class="nav-number">7.5.</span> <span class="nav-text">Following liks in pagination</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#best-movies-py-3"><span class="nav-number">7.5.1.</span> <span class="nav-text">best_movies.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-9"><span class="nav-number">7.5.2.</span> <span class="nav-text">run</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#add-reguest-heads"><span class="nav-number">7.6.</span> <span class="nav-text">add reguest heads</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#best-movies-py-4"><span class="nav-number">7.6.1.</span> <span class="nav-text">best_movies.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-10"><span class="nav-number">7.6.2.</span> <span class="nav-text">run</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#books-toscrape-com"><span class="nav-number">8.</span> <span class="nav-text">books.toscrape.com</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#generate-project-and-spider"><span class="nav-number">8.1.</span> <span class="nav-text">generate project and spider</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#books-py"><span class="nav-number">8.2.</span> <span class="nav-text">books.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-11"><span class="nav-number">8.3.</span> <span class="nav-text">run</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Robert Kao"
      src="/images/head.png">
  <p class="site-author-name" itemprop="name">Robert Kao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">171</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">66</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
        <div class="back-to-top animated" role="button">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://hot5656.github.io/2022/12/04/python-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="Robert Kao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Robert 雜記">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python Scrapy Example(爬蟲框架)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-12-04 21:06:54" itemprop="dateCreated datePublished" datetime="2022-12-04T21:06:54+08:00">2022-12-04</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新於</span>
        <time title="修改時間：2024-04-23 17:22:41" itemprop="dateModified" datetime="2024-04-23T17:22:41+08:00">2024-04-23</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Coding/" itemprop="url" rel="index"><span itemprop="name">Coding</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2022/12/04/python-8/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/12/04/python-8/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>94k</span>
    </span>
    <span class="post-meta-item" title="所需閱讀時間">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">所需閱讀時間 &asymp;</span>
      <span>1:26</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="scrapy-install"><a href="#scrapy-install" class="headerlink" title="scrapy install"></a>scrapy install</h3><h4 id="install"><a href="#install" class="headerlink" title="install"></a>install</h4><p>python 3.11 有問題, python 3.10 ok</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># install myenv10_scrapy</span><br><span class="line">rem cd \app\python_env\</span><br><span class="line">rem py -3.10 -m virtualenv myenv10_scrapy</span><br><span class="line"># install </span><br><span class="line">pip install scrapy </span><br><span class="line">pip install pylint </span><br><span class="line">pip install autopep8</span><br><span class="line">pip install ipython</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h4 id="scrapy-version-amp-help"><a href="#scrapy-version-amp-help" class="headerlink" title="scrapy version &amp; help"></a>scrapy version &amp; help</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># show version &amp; help</span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler&gt;scrapy</span><br><span class="line">Scrapy 2.7.1 - no active project</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  scrapy &lt;command&gt; [options] [args]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  bench         Run quick benchmark test</span><br><span class="line">  commands</span><br><span class="line">  fetch         Fetch a URL using the Scrapy downloader</span><br><span class="line">  genspider     Generate new spider using pre-defined templates</span><br><span class="line">  runspider     Run a self-contained spider (without creating a project)</span><br><span class="line">  settings      Get settings values</span><br><span class="line">  shell         Interactive scraping console</span><br><span class="line">  startproject  Create new project</span><br><span class="line">  version       Print Scrapy version</span><br><span class="line">  view          Open URL in browser, as seen by Scrapy</span><br><span class="line"></span><br><span class="line">  [ more ]      More commands available when run from project directory</span><br><span class="line"></span><br><span class="line">Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler&gt;</span><br></pre></td></tr></table></figure>

<h4 id="scrapy-bench-simple-test"><a href="#scrapy-bench-simple-test" class="headerlink" title="scrapy bench(simple test)"></a>scrapy bench(simple test)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler&gt;scrapy bench</span><br><span class="line">2022-12-02 22:22:22 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)</span><br><span class="line">2022-12-02 22:22:22 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.8 (tags&#x2F;v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19045-SP0</span><br><span class="line">2022-12-02 22:22:23 [scrapy.crawler] INFO: Overridden settings:</span><br><span class="line">&#123;&#39;CLOSESPIDER_TIMEOUT&#39;: 10, &#39;LOGSTATS_INTERVAL&#39;: 1, &#39;LOG_LEVEL&#39;: &#39;INFO&#39;&#125;</span><br><span class="line">2022-12-02 22:22:23 [py.warnings] WARNING: D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\utils\request.py:231: ScrapyDeprecationWarning: &#39;2.6&#39; is a deprecated value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting.</span><br><span class="line"></span><br><span class="line">It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.</span><br><span class="line"></span><br><span class="line">See the documentation of the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting for information on how to handle this deprecation.</span><br><span class="line">  return cls(crawler)</span><br><span class="line"></span><br><span class="line">2022-12-02 22:22:24 [scrapy.extensions.telnet] INFO: Telnet Password: e7858b3f4e0433a6</span><br><span class="line">2022-12-02 22:22:24 [scrapy.middleware] INFO: Enabled extensions:</span><br><span class="line">[&#39;scrapy.extensions.corestats.CoreStats&#39;,</span><br><span class="line"> &#39;scrapy.extensions.telnet.TelnetConsole&#39;,</span><br><span class="line"> &#39;scrapy.extensions.closespider.CloseSpider&#39;,</span><br><span class="line"> &#39;scrapy.extensions.logstats.LogStats&#39;]</span><br><span class="line">2022-12-02 22:22:24 [scrapy.middleware] INFO: Enabled downloader middlewares:</span><br><span class="line">[&#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]</span><br><span class="line">2022-12-02 22:22:24 [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]</span><br><span class="line">2022-12-02 22:22:25 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[]</span><br><span class="line">2022-12-02 22:22:25 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2022-12-02 22:22:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2022-12-02 22:22:26 [scrapy.extensions.logstats] INFO: Crawled 61 pages (at 3660 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:27 [scrapy.extensions.logstats] INFO: Crawled 109 pages (at 2880 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:28 [scrapy.extensions.logstats] INFO: Crawled 157 pages (at 2880 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:29 [scrapy.extensions.logstats] INFO: Crawled 205 pages (at 2880 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:30 [scrapy.extensions.logstats] INFO: Crawled 261 pages (at 3360 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:31 [scrapy.extensions.logstats] INFO: Crawled 293 pages (at 1920 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:32 [scrapy.extensions.logstats] INFO: Crawled 333 pages (at 2400 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:33 [scrapy.extensions.logstats] INFO: Crawled 365 pages (at 1920 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:34 [scrapy.extensions.logstats] INFO: Crawled 413 pages (at 2880 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:35 [scrapy.core.engine] INFO: Closing spider (closespider_timeout)</span><br><span class="line">2022-12-02 22:22:35 [scrapy.extensions.logstats] INFO: Crawled 445 pages (at 1920 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-02 22:22:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;&#39;downloader&#x2F;request_bytes&#39;: 192019,</span><br><span class="line"> &#39;downloader&#x2F;request_count&#39;: 461,</span><br><span class="line"> &#39;downloader&#x2F;request_method_count&#x2F;GET&#39;: 461,</span><br><span class="line"> &#39;downloader&#x2F;response_bytes&#39;: 1277946,</span><br><span class="line"> &#39;downloader&#x2F;response_count&#39;: 461,</span><br><span class="line"> &#39;downloader&#x2F;response_status_count&#x2F;200&#39;: 461,</span><br><span class="line"> &#39;elapsed_time_seconds&#39;: 10.698746,</span><br><span class="line"> &#39;finish_reason&#39;: &#39;closespider_timeout&#39;,</span><br><span class="line"> &#39;finish_time&#39;: datetime.datetime(2022, 12, 2, 14, 22, 36, 32014),</span><br><span class="line"> &#39;log_count&#x2F;INFO&#39;: 20,</span><br><span class="line"> &#39;log_count&#x2F;WARNING&#39;: 1,</span><br><span class="line"> &#39;request_depth_max&#39;: 16,</span><br><span class="line"> &#39;response_received_count&#39;: 461,</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#39;: 461,</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#x2F;memory&#39;: 461,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#39;: 9220,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#x2F;memory&#39;: 9220,</span><br><span class="line"> &#39;start_time&#39;: datetime.datetime(2022, 12, 2, 14, 22, 25, 333268)&#125;</span><br><span class="line">2022-12-02 22:22:36 [scrapy.core.engine] INFO: Spider closed (closespider_timeout)</span><br></pre></td></tr></table></figure>

<h4 id="scrapy-fetch-get-web-page"><a href="#scrapy-fetch-get-web-page" class="headerlink" title="scrapy fetch(get web page)"></a>scrapy fetch(get web page)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler&gt;scrapy fetch https:&#x2F;&#x2F;www.google.com</span><br><span class="line">2022-12-02 22:29:41 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)</span><br><span class="line">2022-12-02 22:29:41 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.8 (tags&#x2F;v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19045-SP0</span><br><span class="line">2022-12-02 22:29:41 [scrapy.crawler] INFO: Overridden settings:</span><br><span class="line">&#123;&#125;</span><br><span class="line">2022-12-02 22:29:41 [py.warnings] WARNING: D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\utils\request.py:231: ScrapyDeprecationWarning: &#39;2.6&#39; is a deprecated value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting.</span><br><span class="line"></span><br><span class="line">It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.</span><br><span class="line"></span><br><span class="line">See the documentation of the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting for information on how to handle this deprecation.</span><br><span class="line">  return cls(crawler)</span><br><span class="line"></span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h3 id="run-scrapy-for-worldometers"><a href="#run-scrapy-for-worldometers" class="headerlink" title="run scrapy for worldometers"></a>run scrapy for <a target="_blank" rel="noopener" href="https://www.worldometers.info/world-population/population-by-country/">worldometers</a></h3><h4 id="create-project"><a href="#create-project" class="headerlink" title="create project"></a>create project</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy&gt;scrapy startproject worldmeters</span><br><span class="line">New Scrapy project &#39;worldmeters&#39;, using template directory &#39;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#39;, created in:</span><br><span class="line">    D:\work\git\python_crawler\101-scrapy\worldmeters</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    cd worldmeters</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure>

<h4 id="create-spider"><a href="#create-spider" class="headerlink" title="create spider"></a>create spider</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;</span><br><span class="line"># default http:, removed &quot;&#x2F;&quot; (because scrape will auto add)</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy\worldmeters&gt;scrapy genspider countries www.worldometers.info&#x2F;world-population&#x2F;population-by-country</span><br><span class="line">Created spider &#39;countries&#39; using template &#39;basic&#39; in module:</span><br><span class="line">  worldmeters.spiders.countries</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># worldmeters\worldmeters\spiders\countries.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">		<span class="comment"># change http: to https:</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.worldometers.info&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h4 id="scrape-shell"><a href="#scrape-shell" class="headerlink" title="scrape shell"></a>scrape shell</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\git\python_crawler\101-scrapy\worldmeters&gt;scrapy shell</span><br><span class="line">D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\spiderloader.py:37: UserWarning: There are several spiders with the same name:</span><br><span class="line"></span><br><span class="line">  CountriesSpider named &#39;countries&#39; (in worldmeters.spiders.countries - 複製)</span><br><span class="line"></span><br><span class="line">  CountriesSpider named &#39;countries&#39; (in worldmeters.spiders.countries)</span><br><span class="line"></span><br><span class="line">  CountriesSpider named &#39;countries&#39; (in worldmeters.spiders.countries_update)</span><br><span class="line"></span><br><span class="line">  This can cause unexpected behavior.</span><br><span class="line">  warnings.warn(</span><br><span class="line">2022-12-03 10:04:03 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">2022-12-03 10:04:03 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.8 (tags&#x2F;v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19045-SP0</span><br><span class="line">2022-12-03 10:04:03 [scrapy.crawler] INFO: Overridden settings:</span><br><span class="line">&#123;&#39;BOT_NAME&#39;: &#39;worldmeters&#39;,</span><br><span class="line"> &#39;DUPEFILTER_CLASS&#39;: &#39;scrapy.dupefilters.BaseDupeFilter&#39;,</span><br><span class="line"> &#39;LOGSTATS_INTERVAL&#39;: 0,</span><br><span class="line"> &#39;NEWSPIDER_MODULE&#39;: &#39;worldmeters.spiders&#39;,</span><br><span class="line"> &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39;: &#39;2.7&#39;,</span><br><span class="line"> &#39;ROBOTSTXT_OBEY&#39;: True,</span><br><span class="line"> &#39;SPIDER_MODULES&#39;: [&#39;worldmeters.spiders&#39;],</span><br><span class="line"> &#39;TWISTED_REACTOR&#39;: &#39;twisted.internet.asyncioreactor.AsyncioSelectorReactor&#39;&#125;</span><br><span class="line">2022-12-03 10:04:03 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line">2022-12-03 10:04:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor</span><br><span class="line">2022-12-03 10:04:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop</span><br><span class="line">2022-12-03 10:04:03 [scrapy.extensions.telnet] INFO: Telnet Password: 896a4cf5aba51b02</span><br><span class="line">2022-12-03 10:04:03 [scrapy.middleware] INFO: Enabled extensions:</span><br><span class="line">[&#39;scrapy.extensions.corestats.CoreStats&#39;,</span><br><span class="line"> &#39;scrapy.extensions.telnet.TelnetConsole&#39;]</span><br><span class="line">2022-12-03 10:04:04 [scrapy.middleware] INFO: Enabled downloader middlewares:</span><br><span class="line">[&#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]</span><br><span class="line">2022-12-03 10:04:04 [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]</span><br><span class="line">2022-12-03 10:04:04 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[]</span><br><span class="line">2022-12-03 10:04:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2022-12-03 10:04:04 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x0000029E3EC8F3D0&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x0000029E3EC8F430&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect&#x3D;True]) Fetch URL and update local objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update local objects</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   view(response)    View response in a browser</span><br><span class="line">2022-12-03 10:04:05 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line">In [1]:</span><br></pre></td></tr></table></figure>

<h4 id="worldometers-not-support-Crawled-no-robots-txt"><a href="#worldometers-not-support-Crawled-no-robots-txt" class="headerlink" title="worldometers not support Crawled(no robots.txt)"></a>worldometers not support Crawled(no robots.txt)</h4><p>DEBUG: Crawled (404) &lt;GET <a target="_blank" rel="noopener" href="https://www.worldometers.info/robots.txt&gt;">https://www.worldometers.info/robots.txt&gt;</a> (referer: None)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">In [1]: fetch(&quot;https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-cou</span><br><span class="line">   ...: ntry&#x2F;&quot;)</span><br><span class="line">2022-12-03 10:08:03 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2022-12-03 10:08:05 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;robots.txt&gt; (referer: None)</span><br><span class="line">2022-12-03 10:08:05 [protego] DEBUG: Rule at line 2 without any user agent to enforce it on.</span><br><span class="line">2022-12-03 10:08:05 [protego] DEBUG: Rule at line 10 without any user agent to enforce it on.</span><br><span class="line">2022-12-03 10:08:05 [protego] DEBUG: Rule at line 12 without any user agent to enforce it on.</span><br><span class="line">2022-12-03 10:08:05 [protego] DEBUG: Rule at line 14 without any user agent to enforce it on.</span><br><span class="line">2022-12-03 10:08:05 [protego] DEBUG: Rule at line 16 without any user agent to enforce it on.</span><br><span class="line">2022-12-03 10:08:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt; (referer: None)</span><br><span class="line"></span><br><span class="line">In [2]: 2022-12-03 10:08:06 [scrapy.core.scraper] ERROR: Spider error processing &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt; (referer: None)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;D:\app\python_env\myenv10_scrapy\lib\site-packages\twisted\internet\defer.py&quot;, line 892, in _runCallbacks</span><br><span class="line">    current.result &#x3D; callback(  # type: ignore[misc]</span><br><span class="line">  File &quot;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\utils\defer.py&quot;, line 285, in f</span><br><span class="line">    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))</span><br><span class="line">  File &quot;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\utils\defer.py&quot;, line 272, in deferred_from_coro</span><br><span class="line">    event_loop &#x3D; get_asyncio_event_loop_policy().get_event_loop()</span><br><span class="line">  File &quot;D:\app\Python\Python310\lib\asyncio\events.py&quot;, line 656, in get_event_loop</span><br><span class="line">    raise RuntimeError(&#39;There is no current event loop in thread %r.&#39;</span><br><span class="line">RuntimeError: There is no current event loop in thread &#39;Thread-1 (start)&#39;.</span><br><span class="line">2022-12-03 10:08:06 [py.warnings] WARNING: D:\app\python_env\myenv10_scrapy\lib\site-packages\twisted\internet\defer.py:892: RuntimeWarning: coroutine &#39;SpiderMiddlewareManager.scrape_response.&lt;locals&gt;.process_callback_output&#39; was never awaited</span><br><span class="line">  current.result &#x3D; callback(  # type: ignore[misc]</span><br></pre></td></tr></table></figure>

<h4 id="show-body"><a href="#show-body" class="headerlink" title="show body"></a>show body</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [5]: response.body</span><br><span class="line">Out[5]: b&#39;\n\n&lt;!DOCTYPE html&gt;&lt;!--[if IE 8]&gt; &lt;html lang&#x3D;&quot;en&quot; class&#x3D;&quot;ie8&quot;&gt; &lt;![endif]--&gt;&lt;!--[if IE 9]&gt; &lt;html lang&#x3D;&quot;en&quot; class&#x3D;&quot;ie9&quot;&gt; &lt;![endif]--&gt;&lt;!--[if !IE]&gt;&lt;!--&gt; &lt;html lang&#x3D;&quot;en&quot;&gt; &lt;!--&lt;![endif]--&gt; &lt;head&gt; &lt;meta charset&#x3D;&quot;utf-8&quot;&gt; &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt; &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width, initial-scale&#x3D;1&quot;&gt; &lt;title&gt;Population by Country (2022) - Worldometer&lt;&#x2F;title&gt;&lt;meta name&#x3D;&quot;description&quot; content&#x3D;&quot;List of countries and dependencies in the world ranked by population, from the most populated. Growth rate, median age, fertility rate, area, density, population density, urbanization, urban population, share of world population.&quot;&gt;&lt;!-- Favicon --&gt;&lt;link rel&#x3D;&quot;shortcut icon&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;favicon.ico&quot; type&#x3D;&quot;image&#x2F;x-icon&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;57x57&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-57x57.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;60x60&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-60x60.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;72x72&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-72x72.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;76x76&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-76x76.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;114x114&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-114x114.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;120x120&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-120x120.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;144x144&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-144x144.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;152x152&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-152x152.png&quot;&gt;&lt;link rel&#x3D;&quot;apple-touch-icon&quot; sizes&#x3D;&quot;180x180&quot; href&#x3D;&quot;&#x2F;favicon&#x2F;apple-icon-180x180.png&quot;&gt;&lt;link rel&#x3D;&quot;icon&quot; </span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="scrape-view"><a href="#scrape-view" class="headerlink" title="scrape view"></a>scrape view</h4><ul>
<li>ctrl-shift i (run Chrome DevTools)</li>
<li>ctrl-shift p (command)<ul>
<li>javascript disable</li>
</ul>
</li>
<li>ctrl-r (refresh)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [6]: view(response)</span><br><span class="line">Out[6]: True</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="XPath-expression-amp-CSS-selectors"><a href="#XPath-expression-amp-CSS-selectors" class="headerlink" title="XPath expression &amp; CSS selectors"></a>XPath expression &amp; CSS selectors</h4><ul>
<li>ctrl-shift c (inspect)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"># XPath expression</span><br><span class="line">In [16]: title &#x3D; response.xpath(&quot;&#x2F;&#x2F;h1&quot;)</span><br><span class="line"></span><br><span class="line">In [17]: title</span><br><span class="line">Out[17]: [&lt;Selector xpath&#x3D;&#39;&#x2F;&#x2F;h1&#39; data&#x3D;&#39;&lt;h1&gt;Countries in the world by populat...&#39;&gt;]</span><br><span class="line"></span><br><span class="line">In [18]: title &#x3D; response.xpath(&quot;&#x2F;&#x2F;h1&#x2F;text()&quot;)</span><br><span class="line"></span><br><span class="line">In [19]: title</span><br><span class="line">Out[19]: [&lt;Selector xpath&#x3D;&#39;&#x2F;&#x2F;h1&#x2F;text()&#39; data&#x3D;&#39;Countries in the world by population ...&#39;&gt;]</span><br><span class="line"></span><br><span class="line">In [20]: title.get()</span><br><span class="line">Out[20]: &#39;Countries in the world by population (2022)&#39;</span><br><span class="line"></span><br><span class="line"># CSS selectors</span><br><span class="line">In [22]: title_css &#x3D; response.css(&quot;h1::text&quot;)</span><br><span class="line"></span><br><span class="line">In [23]: title_css</span><br><span class="line">Out[23]: [&lt;Selector xpath&#x3D;&#39;descendant-or-self::h1&#x2F;text()&#39; data&#x3D;&#39;Countries in the world by population ...&#39;&gt;]</span><br><span class="line"></span><br><span class="line">In [26]: title_css.get()</span><br><span class="line">Out[26]: &#39;Countries in the world by population (2022)&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># XPath expression</span><br><span class="line">In [30]: countries &#x3D; response.xpath(&quot;&#x2F;&#x2F;td&#x2F;a&#x2F;text()&quot;).getall()</span><br><span class="line"></span><br><span class="line">In [31]: countries</span><br><span class="line">Out[31]:</span><br><span class="line">[&#39;China&#39;,</span><br><span class="line"> &#39;India&#39;,</span><br><span class="line"> &#39;United States&#39;,</span><br><span class="line"> &#39;Indonesia&#39;,</span><br><span class="line"> &#39;Pakistan&#39;,</span><br><span class="line"> &#39;Brazil&#39;,</span><br><span class="line"> &#39;Nigeria&#39;,</span><br><span class="line"> ......</span><br><span class="line"></span><br><span class="line"> &#39;Holy See&#39;]</span><br><span class="line"></span><br><span class="line"># CSS selectors</span><br><span class="line">In [34]: countries_css &#x3D; response.css(&quot;td a::text&quot;).getall()</span><br><span class="line"></span><br><span class="line">In [35]: countries_css</span><br><span class="line">Out[35]:</span><br><span class="line">[&#39;China&#39;,</span><br><span class="line"> &#39;India&#39;,</span><br><span class="line"> &#39;United States&#39;,</span><br><span class="line"> &#39;Indonesia&#39;,</span><br><span class="line"> &#39;Pakistan&#39;,</span><br><span class="line"> &#39;Brazil&#39;,</span><br><span class="line"> &#39;Nigeria&#39;,</span><br><span class="line"> ......</span><br><span class="line"> </span><br><span class="line"> &#39;Holy See&#39;]</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="modify-worldmeters-worldmeters-spiders-countries-py-for-XPath-expression"><a href="#modify-worldmeters-worldmeters-spiders-countries-py-for-XPath-expression" class="headerlink" title="modify worldmeters\worldmeters\spiders\countries.py for XPath expression"></a>modify worldmeters\worldmeters\spiders\countries.py for XPath expression</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        title = response.xpath(<span class="string">&quot;//h1/text()&quot;</span>).get()</span><br><span class="line">        countries = response.xpath(<span class="string">&quot;//td/a/text()&quot;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">          <span class="string">&#x27;tittle&#x27;</span>: title,</span><br><span class="line">          <span class="string">&#x27;counties&#x27;</span>: countries</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="run-scrapy-clawer"><a href="#run-scrapy-clawer" class="headerlink" title="run scrapy clawer"></a>run scrapy clawer</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line">2022-12-06 12:03:18 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">2022-12-06 12:03:18 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.6 (tags&#x2F;v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0</span><br><span class="line">2022-12-06 12:03:18 [scrapy.crawler] INFO: Overridden settings:</span><br><span class="line">&#123;&#39;BOT_NAME&#39;: &#39;worldmeters&#39;,</span><br><span class="line"> &#39;NEWSPIDER_MODULE&#39;: &#39;worldmeters.spiders&#39;,</span><br><span class="line"> &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39;: &#39;2.7&#39;,</span><br><span class="line"> &#39;ROBOTSTXT_OBEY&#39;: True,</span><br><span class="line"> &#39;SPIDER_MODULES&#39;: [&#39;worldmeters.spiders&#39;],</span><br><span class="line"> &#39;TWISTED_REACTOR&#39;: &#39;twisted.internet.asyncioreactor.AsyncioSelectorReactor&#39;&#125;</span><br><span class="line">2022-12-06 12:03:18 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line">2022-12-06 12:03:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor</span><br><span class="line">2022-12-06 12:03:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop</span><br><span class="line">2022-12-06 12:03:18 [scrapy.extensions.telnet] INFO: Telnet Password: 6b21a23169d5dea4</span><br><span class="line">2022-12-06 12:03:18 [scrapy.middleware] INFO: Enabled extensions:</span><br><span class="line">[&#39;scrapy.extensions.corestats.CoreStats&#39;,</span><br><span class="line"> &#39;scrapy.extensions.telnet.TelnetConsole&#39;,</span><br><span class="line"> &#39;scrapy.extensions.logstats.LogStats&#39;]</span><br><span class="line">2022-12-06 12:03:18 [scrapy.middleware] INFO: Enabled downloader middlewares:</span><br><span class="line">[&#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]</span><br><span class="line">2022-12-06 12:03:18 [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,</span><br><span class="line"> &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]</span><br><span class="line">2022-12-06 12:03:18 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[]</span><br><span class="line">2022-12-06 12:03:18 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2022-12-06 12:03:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages&#x2F;min), scraped 0 items (at 0 items&#x2F;min)</span><br><span class="line">2022-12-06 12:03:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2022-12-06 12:03:19 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;robots.txt&gt; (referer: None)</span><br><span class="line">2022-12-06 12:03:19 [protego] DEBUG: Rule at line 2 without any user agent to enforce it on.</span><br><span class="line">2022-12-06 12:03:19 [protego] DEBUG: Rule at line 10 without any user agent to enforce it on.</span><br><span class="line">2022-12-06 12:03:19 [protego] DEBUG: Rule at line 12 without any user agent to enforce it on.</span><br><span class="line">2022-12-06 12:03:19 [protego] DEBUG: Rule at line 14 without any user agent to enforce it on.</span><br><span class="line">2022-12-06 12:03:19 [protego] DEBUG: Rule at line 16 without any user agent to enforce it on.</span><br><span class="line">2022-12-06 12:03:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt; (referer: None)</span><br><span class="line">2022-12-06 12:03:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt;</span><br><span class="line">&#123;&#39;tittle&#39;: &#39;Countries in the world by population (2022)&#39;, &#39;counties&#39;: [&#39;China&#39;, &#39;India&#39;, &#39;United States&#39;, &#39;Indonesia&#39;, &#39;Pakistan&#39;, &#39;Brazil&#39;, &#39;Nigeria&#39;, &#39;Bangladesh&#39;, &#39;Russia&#39;, &#39;Mexico&#39;, &#39;Japan&#39;, &#39;Ethiopia&#39;, &#39;Philippines&#39;, &#39;Egypt&#39;, &#39;Vietnam&#39;, &#39;DR Congo&#39;, &#39;Turkey&#39;, &#39;Iran&#39;, &#39;Germany&#39;, &#39;Thailand&#39;, &#39;United Kingdom&#39;, &#39;France&#39;, &#39;Italy&#39;, &#39;Tanzania&#39;, &#39;South Africa&#39;, &#39;Myanmar&#39;, &#39;Kenya&#39;, &#39;South Korea&#39;, &#39;Colombia&#39;, &#39;Spain&#39;, &#39;Uganda&#39;, &#39;Argentina&#39;, &#39;Algeria&#39;, &#39;Sudan&#39;, &#39;Ukraine&#39;, &#39;Iraq&#39;, &#39;Afghanistan&#39;, &#39;Poland&#39;, &#39;Canada&#39;, &#39;Morocco&#39;, &#39;Saudi Arabia&#39;, &#39;Uzbekistan&#39;, &#39;Peru&#39;, &#39;Angola&#39;, &#39;Malaysia&#39;, &#39;Mozambique&#39;, &#39;Ghana&#39;, &#39;Yemen&#39;, &#39;Nepal&#39;, &#39;Venezuela&#39;, &#39;Madagascar&#39;, &#39;Cameroon&#39;, &quot;Côte d&#39;Ivoire&quot;, &#39;North Korea&#39;, &#39;Australia&#39;, &#39;Niger&#39;, &#39;Taiwan&#39;, &#39;Sri Lanka&#39;, &#39;Burkina Faso&#39;, &#39;Mali&#39;, &#39;Romania&#39;, &#39;Malawi&#39;, &#39;Chile&#39;, &#39;Kazakhstan&#39;, &#39;Zambia&#39;, &#39;Guatemala&#39;, &#39;Ecuador&#39;, &#39;Syria&#39;, &#39;Netherlands&#39;, &#39;Senegal&#39;, &#39;Cambodia&#39;, &#39;Chad&#39;, &#39;Somalia&#39;, &#39;Zimbabwe&#39;, &#39;Guinea&#39;, &#39;Rwanda&#39;, &#39;Benin&#39;, &#39;Burundi&#39;, &#39;Tunisia&#39;, &#39;Bolivia&#39;, &#39;Belgium&#39;, &#39;Haiti&#39;, &#39;Cuba&#39;, &#39;South Sudan&#39;, &#39;Dominican Republic&#39;, &#39;Czech Republic (Czechia)&#39;, &#39;Greece&#39;, &#39;Jordan&#39;, &#39;Portugal&#39;, &#39;Azerbaijan&#39;, &#39;Sweden&#39;, &#39;Honduras&#39;, &#39;United Arab Emirates&#39;, &#39;Hungary&#39;, &#39;Tajikistan&#39;, &#39;Belarus&#39;, &#39;Austria&#39;, &#39;Papua New Guinea&#39;, &#39;Serbia&#39;, &#39;Israel&#39;, &#39;Switzerland&#39;, &#39;Togo&#39;, &#39;Sierra Leone&#39;, &#39;Hong Kong&#39;, &#39;Laos&#39;, &#39;Paraguay&#39;, &#39;Bulgaria&#39;, &#39;Libya&#39;, &#39;Lebanon&#39;, &#39;Nicaragua&#39;, &#39;Kyrgyzstan&#39;, &#39;El Salvador&#39;, &#39;Turkmenistan&#39;, &#39;Singapore&#39;, &#39;Denmark&#39;, &#39;Finland&#39;, &#39;Congo&#39;, &#39;Slovakia&#39;, &#39;Norway&#39;, &#39;Oman&#39;, &#39;State of Palestine&#39;, &#39;Costa Rica&#39;, &#39;Liberia&#39;, &#39;Ireland&#39;, &#39;Central African Republic&#39;, &#39;New Zealand&#39;, &#39;Mauritania&#39;, &#39;Panama&#39;, &#39;Kuwait&#39;, &#39;Croatia&#39;, &#39;Moldova&#39;, &#39;Georgia&#39;, &#39;Eritrea&#39;, &#39;Uruguay&#39;, &#39;Bosnia and Herzegovina&#39;, &#39;Mongolia&#39;, &#39;Armenia&#39;, &#39;Jamaica&#39;, &#39;Qatar&#39;, &#39;Albania&#39;, &#39;Puerto Rico&#39;, &#39;Lithuania&#39;, &#39;Namibia&#39;, &#39;Gambia&#39;, &#39;Botswana&#39;, &#39;Gabon&#39;, &#39;Lesotho&#39;, &#39;North Macedonia&#39;, &#39;Slovenia&#39;, &#39;Guinea-Bissau&#39;, &#39;Latvia&#39;, &#39;Bahrain&#39;, &#39;Equatorial Guinea&#39;, &#39;Trinidad and Tobago&#39;, &#39;Estonia&#39;, &#39;Timor-Leste&#39;, &#39;Mauritius&#39;, &#39;Cyprus&#39;, &#39;Eswatini&#39;, &#39;Djibouti&#39;, &#39;Fiji&#39;, &#39;Réunion&#39;, &#39;Comoros&#39;, &#39;Guyana&#39;, &#39;Bhutan&#39;, &#39;Solomon Islands&#39;, &#39;Macao&#39;, &#39;Montenegro&#39;, &#39;Luxembourg&#39;, &#39;Western Sahara&#39;, &#39;Suriname&#39;, &#39;Cabo Verde&#39;, &#39;Micronesia&#39;, &#39;Maldives&#39;, &#39;Malta&#39;, &#39;Brunei &#39;, &#39;Guadeloupe&#39;, &#39;Belize&#39;, &#39;Bahamas&#39;, &#39;Martinique&#39;, &#39;Iceland&#39;, &#39;Vanuatu&#39;, &#39;French Guiana&#39;, &#39;Barbados&#39;, &#39;New Caledonia&#39;, &#39;French Polynesia&#39;, &#39;Mayotte&#39;, &#39;Sao Tome &amp; Principe&#39;, &#39;Samoa&#39;, &#39;Saint Lucia&#39;, &#39;Channel Islands&#39;, &#39;Guam&#39;, &#39;Curaçao&#39;, &#39;Kiribati&#39;, &#39;Grenada&#39;, &#39;St. Vincent &amp; Grenadines&#39;, &#39;Aruba&#39;, &#39;Tonga&#39;, &#39;U.S. Virgin Islands&#39;, &#39;Seychelles&#39;, &#39;Antigua and Barbuda&#39;, &#39;Isle of Man&#39;, &#39;Andorra&#39;, &#39;Dominica&#39;, &#39;Cayman Islands&#39;, &#39;Bermuda&#39;, &#39;Marshall Islands&#39;, &#39;Northern Mariana Islands&#39;, &#39;Greenland&#39;, &#39;American Samoa&#39;, &#39;Saint Kitts &amp; Nevis&#39;, &#39;Faeroe Islands&#39;, &#39;Sint Maarten&#39;, &#39;Monaco&#39;, &#39;Turks and Caicos&#39;, &#39;Saint Martin&#39;, &#39;Liechtenstein&#39;, &#39;San Marino&#39;, &#39;Gibraltar&#39;, &#39;British Virgin Islands&#39;, &#39;Caribbean Netherlands&#39;, &#39;Palau&#39;, &#39;Cook Islands&#39;, &#39;Anguilla&#39;, &#39;Tuvalu&#39;, &#39;Wallis &amp; Futuna&#39;, &#39;Nauru&#39;, &#39;Saint Barthelemy&#39;, &#39;Saint Helena&#39;, &#39;Saint Pierre &amp; Miquelon&#39;, &#39;Montserrat&#39;, &#39;Falkland Islands&#39;, &#39;Niue&#39;, &#39;Tokelau&#39;, &#39;Holy See&#39;]&#125;</span><br><span class="line">2022-12-06 12:03:20 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">2022-12-06 12:03:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;&#39;downloader&#x2F;request_bytes&#39;: 491,</span><br><span class="line"> &#39;downloader&#x2F;request_count&#39;: 2,</span><br><span class="line"> &#39;downloader&#x2F;request_method_count&#x2F;GET&#39;: 2,</span><br><span class="line"> &#39;downloader&#x2F;response_bytes&#39;: 18989,</span><br><span class="line"> &#39;downloader&#x2F;response_count&#39;: 2,</span><br><span class="line"> &#39;downloader&#x2F;response_status_count&#x2F;200&#39;: 1,</span><br><span class="line"> &#39;downloader&#x2F;response_status_count&#x2F;404&#39;: 1,</span><br><span class="line"> &#39;elapsed_time_seconds&#39;: 1.387354,</span><br><span class="line"> &#39;finish_reason&#39;: &#39;finished&#39;,</span><br><span class="line"> &#39;finish_time&#39;: datetime.datetime(2022, 12, 6, 4, 3, 20, 290084),</span><br><span class="line"> &#39;httpcompression&#x2F;response_bytes&#39;: 96257,</span><br><span class="line"> &#39;httpcompression&#x2F;response_count&#39;: 2,</span><br><span class="line"> &#39;item_scraped_count&#39;: 1,</span><br><span class="line"> &#39;log_count&#x2F;DEBUG&#39;: 11,</span><br><span class="line"> &#39;log_count&#x2F;INFO&#39;: 10,</span><br><span class="line"> &#39;response_received_count&#39;: 2,</span><br><span class="line"> &#39;robotstxt&#x2F;request_count&#39;: 1,</span><br><span class="line"> &#39;robotstxt&#x2F;response_count&#39;: 1,</span><br><span class="line"> &#39;robotstxt&#x2F;response_status_count&#x2F;404&#39;: 1,</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#39;: 1,</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#x2F;memory&#39;: 1,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#39;: 1,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#x2F;memory&#39;: 1,</span><br><span class="line"> &#39;start_time&#39;: datetime.datetime(2022, 12, 6, 4, 3, 18, 902730)&#125;</span><br><span class="line">2022-12-06 12:03:20 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>

<h3 id="Worldometers-Get-Countries-Population"><a href="#Worldometers-Get-Countries-Population" class="headerlink" title="Worldometers Get Countries Population"></a><a target="_blank" rel="noopener" href="https://www.worldometers.info/world-population/population-by-country/">Worldometers</a> Get Countries Population</h3><h4 id="Get-country-name-and-link"><a href="#Get-country-name-and-link" class="headerlink" title="Get country name and link"></a>Get country name and link</h4><h5 id="try-xpath"><a href="#try-xpath" class="headerlink" title="try xpath"></a>try xpath</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy shell &quot;https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&quot;</span><br><span class="line">2022-12-09 12:24:35 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   view(response)    View response in a browser</span><br><span class="line">2022-12-09 12:24:37 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line">In [1]:</span><br><span class="line"></span><br><span class="line">In [1]: countries &#x3D; response.xpath(&quot;&#x2F;&#x2F;td&#x2F;a&quot;)</span><br><span class="line"></span><br><span class="line">In [2]: countries</span><br><span class="line">Out[2]:</span><br><span class="line">[&lt;Selector xpath&#x3D;&#39;&#x2F;&#x2F;td&#x2F;a&#39; data&#x3D;&#39;&lt;a href&#x3D;&quot;&#x2F;world-population&#x2F;china-popu...&#39;&gt;,</span><br><span class="line"> &lt;Selector xpath&#x3D;&#39;&#x2F;&#x2F;td&#x2F;a&#39; data&#x3D;&#39;&lt;a href&#x3D;&quot;&#x2F;world-population&#x2F;india-popu...&#39;&gt;,</span><br><span class="line"> ......</span><br><span class="line"> &lt;Selector xpath&#x3D;&#39;&#x2F;&#x2F;td&#x2F;a&#39; data&#x3D;&#39;&lt;a href&#x3D;&quot;&#x2F;world-population&#x2F;tokelau-po...&#39;&gt;,</span><br><span class="line"> &lt;Selector xpath&#x3D;&#39;&#x2F;&#x2F;td&#x2F;a&#39; data&#x3D;&#39;&lt;a href&#x3D;&quot;&#x2F;world-population&#x2F;holy-see-p...&#39;&gt;]</span><br><span class="line"></span><br><span class="line">In [3]:</span><br></pre></td></tr></table></figure>

<h5 id="countries-py"><a href="#countries-py" class="headerlink" title="countries.py"></a>countries.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">          name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">          link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">          <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;country_name&#x27;</span>: name,</span><br><span class="line">            <span class="string">&#x27;country_link&#x27;</span>: link</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run"><a href="#run" class="headerlink" title="run"></a>run</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line">2022-12-09 13:54:27 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">......</span><br><span class="line">2022-12-09 13:54:28 [protego] DEBUG: Rule at line 16 without any user agent to enforce it on.</span><br><span class="line">2022-12-09 13:54:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt; (referer: None)</span><br><span class="line">2022-12-09 13:54:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt;</span><br><span class="line">&#123;&#39;country_name&#39;: &#39;China&#39;, &#39;country_link&#39;: &#39;&#x2F;world-population&#x2F;china-population&#x2F;&#39;&#125;</span><br><span class="line">2022-12-09 13:54:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt;</span><br><span class="line">&#123;&#39;country_name&#39;: &#39;India&#39;, &#39;country_link&#39;: &#39;&#x2F;world-population&#x2F;india-population&#x2F;&#39;&#125;</span><br><span class="line">2022-12-09 13:54:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt;</span><br><span class="line">&#123;&#39;country_name&#39;: &#39;United States&#39;, &#39;country_link&#39;: &#39;&#x2F;world-population&#x2F;us-population&#x2F;&#39;&#125;</span><br><span class="line">......</span><br><span class="line">2022-12-09 13:54:29 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>

<h4 id="fetch-country-link-page"><a href="#fetch-country-link-page" class="headerlink" title="fetch country link page"></a>fetch country link page</h4><h5 id="countries-py-1"><a href="#countries-py-1" class="headerlink" title="countries.py"></a>countries.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">          name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">          link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">          <span class="comment"># absolute url</span></span><br><span class="line">          <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">          <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">          <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">          <span class="comment"># relative url</span></span><br><span class="line">          <span class="keyword">yield</span> response.follow(url=link)</span><br></pre></td></tr></table></figure>

<h5 id="run-1"><a href="#run-1" class="headerlink" title="run"></a>run</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line">2022-12-09 14:17:54 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">2022-12-09 14:17:54 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.0, Twisted 22.10.0, Python 3.10.6 (tags&#x2F;v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Windows-10-10.0.19044-SP0</span><br><span class="line">2022-12-09 14:17:54 [scrapy.crawler] INFO: Overridden settings:</span><br><span class="line">......</span><br><span class="line">2022-12-09 14:17:55 [protego] DEBUG: Rule at line 16 without any user agent to enforce it on.</span><br><span class="line">2022-12-09 14:17:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;&gt; (referer: None)</span><br><span class="line">2022-12-09 14:17:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;iran-population&#x2F;&gt; (referer: https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;)</span><br><span class="line">2022-12-09 14:17:57 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;mexico-population&#x2F;&gt; (referer: https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;population-by-country&#x2F;)</span><br><span class="line">......</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#x2F;memory&#39;: 236,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#39;: 236,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#x2F;memory&#39;: 236,</span><br><span class="line"> &#39;start_time&#39;: datetime.datetime(2022, 12, 9, 6, 17, 55, 174514)&#125;</span><br><span class="line">2022-12-09 14:18:05 [scrapy.core.engine] INFO: Spider closed (shutdown)</span><br></pre></td></tr></table></figure>

<h4 id="get-country’s-year-and-population"><a href="#get-country’s-year-and-population" class="headerlink" title="get country’s year and population"></a>get country’s year and population</h4><h5 id="countries-py-2"><a href="#countries-py-2" class="headerlink" title="countries.py"></a>countries.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">      name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">      link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># show log</span></span><br><span class="line">    <span class="comment"># logging.info(response.url)</span></span><br><span class="line">    rows = response.xpath(<span class="string">&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">      year = row.xpath(<span class="string">&quot;./td[1]/text()&quot;</span>).get()</span><br><span class="line">      population = row.xpath(<span class="string">&quot;./td[2]/strong/text()&quot;</span>).get()</span><br><span class="line">      <span class="keyword">yield</span> &#123;</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span> : year,</span><br><span class="line">        <span class="string">&#x27;population&#x27;</span>: population</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-2"><a href="#run-2" class="headerlink" title="run"></a>run</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line">2022-12-09 17:07:25 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: worldmeters)</span><br><span class="line">......</span><br><span class="line">2022-12-09 17:07:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;philippines-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;year&#39;: &#39;2020&#39;, &#39;population&#39;: &#39;109,581,078&#39;&#125;</span><br><span class="line">2022-12-09 17:07:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;philippines-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;year&#39;: &#39;2019&#39;, &#39;population&#39;: &#39;108,116,615&#39;&#125;</span><br><span class="line">2022-12-09 17:07:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;philippines-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;year&#39;: &#39;2018&#39;, &#39;population&#39;: &#39;106,651,394&#39;&#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="class-use-global-variable-for-country-name-not-work-…"><a href="#class-use-global-variable-for-country-name-not-work-…" class="headerlink" title="class use global variable for country name(not work …)"></a>class use global variable for country name(not work …)</h4><h5 id="countries-py-3"><a href="#countries-py-3" class="headerlink" title="countries.py"></a>countries.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line">  country_name = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">      name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">      link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># class use global variable for country name</span></span><br><span class="line">      self.country_name = name</span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># show log</span></span><br><span class="line">    <span class="comment"># logging.info(response.url)</span></span><br><span class="line">    rows = response.xpath(<span class="string">&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">      year = row.xpath(<span class="string">&quot;./td[1]/text()&quot;</span>).get()</span><br><span class="line">      population = row.xpath(<span class="string">&quot;./td[2]/strong/text()&quot;</span>).get()</span><br><span class="line">      <span class="keyword">yield</span> &#123;</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span> : self.country_name,</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span> : year,</span><br><span class="line">        <span class="string">&#x27;population&#x27;</span>: population</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-3"><a href="#run-3" class="headerlink" title="run"></a>run</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line">......</span><br><span class="line">2022-12-12 15:17:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;china-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;name&#39;: &#39;Denmark&#39;, &#39;year&#39;: &#39;2020&#39;, &#39;population&#39;: &#39;1,439,323,776&#39;&#125;</span><br><span class="line">2022-12-12 15:17:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;china-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;name&#39;: &#39;Norway&#39;, &#39;year&#39;: &#39;2019&#39;, &#39;population&#39;: &#39;1,433,783,686&#39;&#125;</span><br><span class="line">2022-12-12 15:17:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;china-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;name&#39;: &#39;Norway&#39;, &#39;year&#39;: &#39;2018&#39;, &#39;population&#39;: &#39;1,427,647,786&#39;&#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="add-meta-for-callback-parameter"><a href="#add-meta-for-callback-parameter" class="headerlink" title="add meta for callback parameter"></a>add meta for callback parameter</h4><h5 id="countries-py-4"><a href="#countries-py-4" class="headerlink" title="countries.py"></a>countries.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountriesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">  name = <span class="string">&#x27;countries&#x27;</span></span><br><span class="line">  allowed_domains = [<span class="string">&#x27;www.worldometers.info&#x27;</span>]</span><br><span class="line">  <span class="comment"># start_urls = [&#x27;https://www.worldometers.info/&#x27;]</span></span><br><span class="line">  start_urls = [<span class="string">&#x27;https://www.worldometers.info/world-population/population-by-country&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    countries = response.xpath(<span class="string">&quot;//td/a&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> country <span class="keyword">in</span> countries:</span><br><span class="line">      name = country.xpath(<span class="string">&quot;.//text()&quot;</span>).get()</span><br><span class="line">      link = country.xpath(<span class="string">&quot;.//@href&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># absolute url</span></span><br><span class="line">      <span class="comment"># absolute_url = f&#x27;https://www.worldometers.info&#123;link&#125;&#x27;</span></span><br><span class="line">      <span class="comment"># absolute_url = response.urljoin(link)</span></span><br><span class="line">      <span class="comment"># yield scrapy.Request(url=absolute_url)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># relative url</span></span><br><span class="line">      <span class="comment"># add meta for callback parameter</span></span><br><span class="line">      <span class="keyword">yield</span> response.follow(url=link, callback=self.parse_country, meta=&#123;<span class="string">&#x27;country_name&#x27;</span>: name&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parse_country</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># add meta for callback parameter</span></span><br><span class="line">    name = response.request.meta[<span class="string">&#x27;country_name&#x27;</span>]</span><br><span class="line">    rows = response.xpath(<span class="string">&quot;(//table[@class=&#x27;table table-striped table-bordered table-hover table-condensed table-list&#x27;])[1]/tbody/tr&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">      year = row.xpath(<span class="string">&quot;./td[1]/text()&quot;</span>).get()</span><br><span class="line">      population = row.xpath(<span class="string">&quot;./td[2]/strong/text()&quot;</span>).get()</span><br><span class="line">      <span class="keyword">yield</span> &#123;</span><br><span class="line">        <span class="string">&#x27;country_name&#x27;</span> : name,</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span> : year,</span><br><span class="line">        <span class="string">&#x27;population&#x27;</span>: population</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-4"><a href="#run-4" class="headerlink" title="run"></a>run</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy crawl countries</span><br><span class="line">......</span><br><span class="line">2022-12-12 15:25:10 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;uk-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;country_name&#39;: &#39;United Kingdom&#39;, &#39;year&#39;: &#39;2020&#39;, &#39;population&#39;: &#39;67,886,011&#39;&#125;</span><br><span class="line">2022-12-12 15:25:10 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;uk-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;country_name&#39;: &#39;United Kingdom&#39;, &#39;year&#39;: &#39;2019&#39;, &#39;population&#39;: &#39;67,530,172&#39;&#125;</span><br><span class="line">2022-12-12 15:25:10 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https:&#x2F;&#x2F;www.worldometers.info&#x2F;world-population&#x2F;uk-population&#x2F;&gt;</span><br><span class="line">&#123;&#39;country_name&#39;: &#39;United Kingdom&#39;, &#39;year&#39;: &#39;2018&#39;, &#39;population&#39;: &#39;67,141,684&#39;&#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="data-generate-by-dataset-json-csv-xml"><a href="#data-generate-by-dataset-json-csv-xml" class="headerlink" title="data generate by dataset(json, csv, xml)"></a>data generate by dataset(json, csv, xml)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate json file</span></span><br><span class="line">scrapy crawl countries -o population_dataset.json</span><br><span class="line"><span class="comment"># generate csv file</span></span><br><span class="line">scrapy crawl countries -o population_dataset.csv</span><br><span class="line"><span class="comment"># generate xml file</span></span><br><span class="line">scrapy crawl countries -o population_dataset.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">&#123;<span class="attr">&quot;country_name&quot;</span>: <span class="string">&quot;China&quot;</span>, <span class="attr">&quot;year&quot;</span>: <span class="string">&quot;2020&quot;</span>, <span class="attr">&quot;population&quot;</span>: <span class="string">&quot;1,439,323,776&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="attr">&quot;country_name&quot;</span>: <span class="string">&quot;China&quot;</span>, <span class="attr">&quot;year&quot;</span>: <span class="string">&quot;2019&quot;</span>, <span class="attr">&quot;population&quot;</span>: <span class="string">&quot;1,433,783,686&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="attr">&quot;country_name&quot;</span>: <span class="string">&quot;China&quot;</span>, <span class="attr">&quot;year&quot;</span>: <span class="string">&quot;2018&quot;</span>, <span class="attr">&quot;population&quot;</span>: <span class="string">&quot;1,427,647,786&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="attr">&quot;country_name&quot;</span>: <span class="string">&quot;China&quot;</span>, <span class="attr">&quot;year&quot;</span>: <span class="string">&quot;2017&quot;</span>, <span class="attr">&quot;population&quot;</span>: <span class="string">&quot;1,421,021,791&quot;</span>&#125;,</span><br><span class="line">......</span><br><span class="line">&#123;<span class="attr">&quot;country_name&quot;</span>: <span class="string">&quot;India&quot;</span>, <span class="attr">&quot;year&quot;</span>: <span class="string">&quot;1960&quot;</span>, <span class="attr">&quot;population&quot;</span>: <span class="string">&quot;450,547,679&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="attr">&quot;country_name&quot;</span>: <span class="string">&quot;India&quot;</span>, <span class="attr">&quot;year&quot;</span>: <span class="string">&quot;1955&quot;</span>, <span class="attr">&quot;population&quot;</span>: <span class="string">&quot;409,880,595&quot;</span>&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">country_name,year,population</span><br><span class="line">China,2020,&quot;1,439,323,776&quot;</span><br><span class="line">China,2019,&quot;1,433,783,686&quot;</span><br><span class="line">China,2018,&quot;1,427,647,786&quot;</span><br><span class="line">......</span><br><span class="line">DR Congo,1965,&quot;17,369,883&quot;</span><br><span class="line">DR Congo,1960,&quot;15,248,251&quot;</span><br><span class="line">DR Congo,1955,&quot;13,517,513&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">items</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">item</span>&gt;</span><span class="tag">&lt;<span class="name">country_name</span>&gt;</span>China<span class="tag">&lt;/<span class="name">country_name</span>&gt;</span><span class="tag">&lt;<span class="name">year</span>&gt;</span>2020<span class="tag">&lt;/<span class="name">year</span>&gt;</span><span class="tag">&lt;<span class="name">population</span>&gt;</span>1,439,323,776<span class="tag">&lt;/<span class="name">population</span>&gt;</span><span class="tag">&lt;/<span class="name">item</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">item</span>&gt;</span><span class="tag">&lt;<span class="name">country_name</span>&gt;</span>China<span class="tag">&lt;/<span class="name">country_name</span>&gt;</span><span class="tag">&lt;<span class="name">year</span>&gt;</span>2019<span class="tag">&lt;/<span class="name">year</span>&gt;</span><span class="tag">&lt;<span class="name">population</span>&gt;</span>1,433,783,686<span class="tag">&lt;/<span class="name">population</span>&gt;</span><span class="tag">&lt;/<span class="name">item</span>&gt;</span></span><br><span class="line">......</span><br><span class="line"><span class="tag">&lt;<span class="name">item</span>&gt;</span><span class="tag">&lt;<span class="name">country_name</span>&gt;</span>Philippines<span class="tag">&lt;/<span class="name">country_name</span>&gt;</span><span class="tag">&lt;<span class="name">year</span>&gt;</span>1960<span class="tag">&lt;/<span class="name">year</span>&gt;</span><span class="tag">&lt;<span class="name">population</span>&gt;</span>26,269,734<span class="tag">&lt;/<span class="name">population</span>&gt;</span><span class="tag">&lt;/<span class="name">item</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">item</span>&gt;</span><span class="tag">&lt;<span class="name">country_name</span>&gt;</span>Philippines<span class="tag">&lt;/<span class="name">country_name</span>&gt;</span><span class="tag">&lt;<span class="name">year</span>&gt;</span>1955<span class="tag">&lt;/<span class="name">year</span>&gt;</span><span class="tag">&lt;<span class="name">population</span>&gt;</span>22,177,058<span class="tag">&lt;/<span class="name">population</span>&gt;</span><span class="tag">&lt;/<span class="name">item</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">items</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Debt-to-GDP-ratio-by-country"><a href="#Debt-to-GDP-ratio-by-country" class="headerlink" title="Debt to GDP ratio by country"></a><a target="_blank" rel="noopener" href="http://worldpopulationreview.com/countries/countries-by-national-debt/">Debt to GDP ratio by country</a></h3><h4 id="create-spider-1"><a href="#create-spider-1" class="headerlink" title="create spider"></a>create spider</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\worldmeters&gt;scrapy genspider gdp_debt worldpopulationreview.com&#x2F;countries&#x2F;countries-by-national-debt</span><br><span class="line">Created spider &#39;gdp_debt&#39; using template &#39;basic&#39; in module:</span><br><span class="line">  worldmeters.spiders.gdp_debt</span><br></pre></td></tr></table></figure>

<h4 id="countries-py-5"><a href="#countries-py-5" class="headerlink" title="countries.py"></a>countries.py</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GdpDebtSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;gdp_debt&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;worldpopulationreview.com&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://worldpopulationreview.com/&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://worldpopulationreview.com/country-rankings/countries-by-national-debt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        rows = response.xpath(<span class="string">&quot;//tbody/tr&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">            name = row.xpath(<span class="string">&quot;./td[1]/a/text()&quot;</span>).get()</span><br><span class="line">            debt_rate = row.xpath(<span class="string">&quot;./td[2]/text()&quot;</span>).get()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;country_name&#x27;</span> : name,</span><br><span class="line">                <span class="string">&#x27;debt_rate&#x27;</span> : debt_rate</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>

<h4 id="run-wait-new-method"><a href="#run-wait-new-method" class="headerlink" title="run(wait new method)"></a>run(wait new method)</h4><font color=red>
    Cannot get table "Debt to GDP Ratio by Country" : the web site reason(data generate by JavaScript)
</font>

<h3 id="tinydeal"><a href="#tinydeal" class="headerlink" title="tinydeal"></a><a target="_blank" rel="noopener" href="https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html">tinydeal</a></h3><h4 id="open-robots-txt"><a href="#open-robots-txt" class="headerlink" title="open robots.txt"></a>open robots.txt</h4><p>search page name, if not found mean not restriction for scrape</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Allow: &#x2F;*main_page&#x3D;top_brands </span><br><span class="line">Allow: &#x2F;*main_page&#x3D;ws_search_result</span><br><span class="line">Allow: &#x2F;*index.php?main_page&#x3D;zone_2dollars</span><br><span class="line">Disallow: &#x2F;*main_page&#x3D;*</span><br><span class="line">Disallow: &#x2F;bg&#x2F;</span><br><span class="line">Disallow: &#x2F;cs&#x2F;</span><br><span class="line">Disallow: &#x2F;da&#x2F;</span><br><span class="line">Disallow: &#x2F;el&#x2F;</span><br><span class="line">Disallow: &#x2F;fi&#x2F;</span><br><span class="line">Disallow: &#x2F;hu&#x2F;</span><br><span class="line">Disallow: &#x2F;hr&#x2F;</span><br><span class="line">Disallow: &#x2F;lt&#x2F;</span><br><span class="line">Disallow: &#x2F;no&#x2F;</span><br><span class="line">Disallow: &#x2F;pl&#x2F;</span><br><span class="line">Disallow: &#x2F;ro&#x2F;</span><br><span class="line">Disallow: &#x2F;sk&#x2F;</span><br><span class="line">Disallow: &#x2F;sl&#x2F;</span><br><span class="line">Disallow: &#x2F;sv&#x2F;</span><br><span class="line">Disallow: &#x2F;tr&#x2F;</span><br><span class="line">Disallow: &#x2F;ja&#x2F;</span><br><span class="line">Disallow: &#x2F;jp&#x2F;</span><br><span class="line">Disallow: &#x2F;ko&#x2F;</span><br><span class="line">Disallow: &#x2F;wordpress&#x2F;</span><br><span class="line">Disallow: &#x2F;new&#x2F;</span><br><span class="line">Disallow: &#x2F;*&#x2F;includes&#x2F;</span><br><span class="line">Disallow: &#x2F;shop&#x2F;products&#x2F;</span><br><span class="line">Disallow: &#x2F;index.php&#x2F;*-si-*.html</span><br><span class="line">Disallow: &#x2F;*-c-*-pg-1.html</span><br><span class="line">Disallow: *&#x2F;buy&#x2F;*surl&#x3D;</span><br><span class="line">Disallow: *&#x2F;buy&#x2F;*-c-</span><br><span class="line">Disallow: &#x2F;*pagesize&#x3D;</span><br><span class="line">Disallow: &#x2F;*sk&#x3D;</span><br><span class="line">Disallow: &#x2F;*?dp&#x3D;</span><br><span class="line">Disallow: &#x2F;*fb_comment_id&#x3D;</span><br><span class="line">Disallow: &#x2F;*reviews_id&#x3D;</span><br><span class="line">Disallow: &#x2F;*gotowhere</span><br><span class="line">Disallow: &#x2F;*&#x2F;cheap-product</span><br><span class="line">Disallow: &#x2F;es&#x2F;compra*-t-*</span><br><span class="line">Disallow: &#x2F;pt&#x2F;compra*-t-*</span><br><span class="line">Disallow: &#x2F;fr&#x2F;bon*-t-*</span><br><span class="line">Disallow: &#x2F;de&#x2F;kaufen*-t-*</span><br><span class="line">Disallow: &#x2F;it&#x2F;economico*-t-*</span><br><span class="line">Disallow: &#x2F;ru&#x2F;Купи*-t-*</span><br><span class="line">Disallow: &#x2F;nl&#x2F;*goedkoop*-t-*</span><br><span class="line">Disallow: &#x2F;ar&#x2F;بالأسعار-المعقولة*-t-*</span><br><span class="line">Disallow: &#x2F;*is_input&#x3D;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">User-agent: Yandex</span><br><span class="line">Allow: &#x2F;*main_page&#x3D;top_brands </span><br><span class="line">Allow: &#x2F;*main_page&#x3D;ws_search_result</span><br><span class="line">Allow: &#x2F;*index.php?main_page&#x3D;zone_2dollars</span><br><span class="line">Disallow: &#x2F;*main_page&#x3D;*</span><br><span class="line">Disallow: &#x2F;es&#x2F;</span><br><span class="line">Disallow: &#x2F;it&#x2F;</span><br><span class="line">Disallow: &#x2F;pt&#x2F;</span><br><span class="line">Disallow: &#x2F;fr&#x2F;</span><br><span class="line">Disallow: &#x2F;de&#x2F;</span><br><span class="line">Disallow: &#x2F;ar&#x2F;</span><br><span class="line">Disallow: &#x2F;bg&#x2F;</span><br><span class="line">Disallow: &#x2F;cs&#x2F;</span><br><span class="line">Disallow: &#x2F;da&#x2F;</span><br><span class="line">Disallow: &#x2F;el&#x2F;</span><br><span class="line">Disallow: &#x2F;fi&#x2F;</span><br><span class="line">Disallow: &#x2F;hu&#x2F;</span><br><span class="line">Disallow: &#x2F;hr&#x2F;</span><br><span class="line">Disallow: &#x2F;lt&#x2F;</span><br><span class="line">Disallow: &#x2F;nl&#x2F;</span><br><span class="line">Disallow: &#x2F;no&#x2F;</span><br><span class="line">Disallow: &#x2F;pl&#x2F;</span><br><span class="line">Disallow: &#x2F;ro&#x2F;</span><br><span class="line">Disallow: &#x2F;sk&#x2F;</span><br><span class="line">Disallow: &#x2F;sl&#x2F;</span><br><span class="line">Disallow: &#x2F;sv&#x2F;</span><br><span class="line">Disallow: &#x2F;tr&#x2F;</span><br><span class="line">Disallow: &#x2F;ja&#x2F;</span><br><span class="line">Disallow: &#x2F;jp&#x2F;</span><br><span class="line">Disallow: &#x2F;ko&#x2F;</span><br><span class="line">Disallow: &#x2F;wordpress&#x2F;</span><br><span class="line">Disallow: &#x2F;customers_photo&#x2F;</span><br><span class="line">Disallow: &#x2F;new&#x2F;</span><br><span class="line">Disallow: &#x2F;*&#x2F;includes&#x2F;</span><br><span class="line">Disallow: &#x2F;shop&#x2F;products&#x2F;</span><br><span class="line">Disallow: &#x2F;index.php&#x2F;*-si-*.html</span><br><span class="line">Disallow: &#x2F;*-c-*-pg-1.html</span><br><span class="line">Disallow: *&#x2F;buy&#x2F;*surl&#x3D;</span><br><span class="line">Disallow: *&#x2F;buy&#x2F;*-c-</span><br><span class="line">Disallow: &#x2F;*pagesize&#x3D;</span><br><span class="line">Disallow: &#x2F;*sk&#x3D;</span><br><span class="line">Disallow: &#x2F;*?dp&#x3D;</span><br><span class="line">Disallow: &#x2F;*fb_comment_id&#x3D;</span><br><span class="line">Disallow: &#x2F;*reviews_id&#x3D;</span><br><span class="line">Disallow: &#x2F;*gotowhere</span><br><span class="line">Disallow: &#x2F;*&#x2F;cheap-product</span><br><span class="line">Disallow: &#x2F;es&#x2F;compra*-t-*</span><br><span class="line">Disallow: &#x2F;pt&#x2F;compra*-t-*</span><br><span class="line">Disallow: &#x2F;fr&#x2F;bon*-t-*</span><br><span class="line">Disallow: &#x2F;de&#x2F;kaufen*-t-*</span><br><span class="line">Disallow: &#x2F;it&#x2F;economico*-t-*</span><br><span class="line">Disallow: &#x2F;ru&#x2F;Купи*-t-*</span><br><span class="line">Disallow: &#x2F;nl&#x2F;*goedkoop*-t-*</span><br><span class="line">Disallow: &#x2F;ar&#x2F;بالأسعار-المعقولة*-t-*</span><br><span class="line">Disallow: &#x2F;*is_input&#x3D;</span><br><span class="line"></span><br><span class="line">User-Agent: Baiduspider</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line">User-Agent: 360Spider</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line">User-Agent: Sogouspider</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line">User-Agent: Sosospider</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line">User-agent: YoudaoBot</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line">User-agent: magpie-crawler</span><br><span class="line">Disallow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: AdsBot-Google</span><br><span class="line">Disallow:</span><br><span class="line">User-agent: Googlebot-Image</span><br><span class="line">Disallow:</span><br><span class="line"></span><br><span class="line">Sitemap: http:&#x2F;&#x2F;www.tinydeal.com&#x2F;sitemap.xml</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20190225123327&#x2F;https:&#x2F;&#x2F;www.tinydeal.com&#x2F;specials.html</span><br></pre></td></tr></table></figure>

<h4 id="open-web-site-then-disable-Javascript"><a href="#open-web-site-then-disable-Javascript" class="headerlink" title="open web site then disable Javascript"></a>open web site then disable Javascript</h4><ul>
<li>open Chrome devtools</li>
<li>run command(Ctrl+Shift+p) : Disable JavaScript</li>
<li>refresh web page</li>
</ul>
<h4 id="create-project-and-spider"><a href="#create-project-and-spider" class="headerlink" title="create project and spider"></a>create project and spider</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject tinydeal</span><br><span class="line">New Scrapy project &#39;tinydeal&#39;, using template directory &#39;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#39;, created in:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\tinydeal</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    cd tinydeal</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;cd tinydeal</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\tinydeal&gt;scrapy genspider special_offers https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20190225123327&#x2F;https:&#x2F;&#x2F;www.tinydeal.com&#x2F;specials.html</span><br><span class="line">Created spider &#39;special_offers&#39; using template &#39;basic&#39; in module:</span><br><span class="line">  tinydeal.spiders.special_offers</span><br></pre></td></tr></table></figure>

<h4 id="update-special-offers-py"><a href="#update-special-offers-py" class="headerlink" title="update special_offers.py"></a>update special_offers.py</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h4 id="update-special-offers-py-get-product-information"><a href="#update-special-offers-py-get-product-information" class="headerlink" title="update special_offers.py (get product information)"></a>update special_offers.py (get product information)</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul[@class=&quot;productlisting-ul&quot;]/div/li&#x27;</span>):</span><br><span class="line">          <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span> : product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/text()&#x27;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;url&#x27;</span> : response.urljoin(product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/@href&#x27;</span>).get()),</span><br><span class="line">            <span class="string">&#x27;discounted_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[1]/text()&#x27;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;original_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[2]/text()&#x27;</span>).get()</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure>

<h4 id="run-5"><a href="#run-5" class="headerlink" title="run"></a>run</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl special_offers  -o dataset.json</span><br></pre></td></tr></table></figure>

<h4 id="settings-py-change-json-for-utf-8-format-no-show-unicode"><a href="#settings-py-change-json-for-utf-8-format-no-show-unicode" class="headerlink" title="settings.py - change json for utf-8 format(no show unicode)"></a>settings.py - change json for utf-8 format(no show unicode)</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set JSON utf-8 format</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">&#x27;utf-8&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;SanDisk A1 32GB UHS-I / Class 10 up to 98MB / s Micro SDHC Memory Card\u00a0EFM-530161&quot;</span>,</span><br><span class="line">    <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://web.archive.org/web/20190225123327/https:/www.tinydeal.com/sandisk-a1-32gb-uhs-i-class-10-up-to-98mb-s-micro-sdhc-memory-card-p-165914.html&quot;</span>,</span><br><span class="line">    <span class="string">&quot;discounted_price&quot;</span>: <span class="string">&quot;<span class="variable">$6</span>.72&quot;</span>,</span><br><span class="line">    <span class="string">&quot;original_price&quot;</span>: <span class="string">&quot;<span class="variable">$12</span>.09 &quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;18g Super Strong Sealant Fix Metal Adhesive Sealing Glue Bond\u00a0HHI-557389&quot;</span>,</span><br><span class="line">    <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://web.archive.org/web/20190225123327/https:/www.tinydeal.com/18g-super-strong-sealant-fix-metal-adhesive-sealing-glue-bond-p-177571.html&quot;</span>,</span><br><span class="line">    <span class="string">&quot;discounted_price&quot;</span>: <span class="string">&quot;<span class="variable">$1</span>.40&quot;</span>,</span><br><span class="line">    <span class="string">&quot;original_price&quot;</span>: <span class="string">&quot;<span class="variable">$3</span>.76 &quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># set FEED_EXPORT_ENCODING = &#x27;utf-8&#x27;</span></span><br><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;SanDisk A1 32GB UHS-I / Class 10 up to 98MB / s Micro SDHC Memory Card EFM-530161&quot;</span>,</span><br><span class="line">    <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://web.archive.org/web/20190225123327/https:/www.tinydeal.com/sandisk-a1-32gb-uhs-i-class-10-up-to-98mb-s-micro-sdhc-memory-card-p-165914.html&quot;</span>,</span><br><span class="line">    <span class="string">&quot;discounted_price&quot;</span>: <span class="string">&quot;<span class="variable">$6</span>.72&quot;</span>,</span><br><span class="line">    <span class="string">&quot;original_price&quot;</span>: <span class="string">&quot;<span class="variable">$12</span>.09 &quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;18g Super Strong Sealant Fix Metal Adhesive Sealing Glue Bond HHI-557389&quot;</span>,</span><br><span class="line">    <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://web.archive.org/web/20190225123327/https:/www.tinydeal.com/18g-super-strong-sealant-fix-metal-adhesive-sealing-glue-bond-p-177571.html&quot;</span>,</span><br><span class="line">    <span class="string">&quot;discounted_price&quot;</span>: <span class="string">&quot;<span class="variable">$1</span>.40&quot;</span>,</span><br><span class="line">    <span class="string">&quot;original_price&quot;</span>: <span class="string">&quot;<span class="variable">$3</span>.76 &quot;</span></span><br><span class="line">  &#125;,</span><br></pre></td></tr></table></figure>

<h4 id="special-offers-py-dealing-with-pagination-csv"><a href="#special-offers-py-dealing-with-pagination-csv" class="headerlink" title="special_offers.py - dealing with pagination(csv)"></a>special_offers.py - dealing with pagination(csv)</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul[@class=&quot;productlisting-ul&quot;]/div/li&#x27;</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span> : product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;url&#x27;</span> : response.urljoin(product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/@href&#x27;</span>).get()),</span><br><span class="line">                <span class="string">&#x27;discounted_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[1]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;original_price&#x27;</span> : product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[2]/text()&#x27;</span>).get()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.xpath(<span class="string">&#x27;//a[@class=&quot;nextPage&quot;]/@href&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># only get until page 9</span></span><br><span class="line">scrapy crawl special_offers -o dataset.csv</span><br><span class="line">......</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 7557,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 19,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 19,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 541040,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 19,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 9,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/302&#x27;</span>: 9,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/404&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 7.098086,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;finished&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 14, 6, 8, 40, 825326),</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_bytes&#x27;</span>: 3199518,</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_count&#x27;</span>: 9,</span><br><span class="line"> <span class="string">&#x27;item_scraped_count&#x27;</span>: 495,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 517,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;request_depth_max&#x27;</span>: 8,</span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/404&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 18,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 18,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 18,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 18,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 14, 6, 8, 33, 727240)&#125;</span><br><span class="line">2022-12-14 14:08:40 [scrapy.core.engine] INFO: Spider closed (finished)</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\tinydeal&gt;</span><br></pre></td></tr></table></figure>

<h4 id="change-User-Agent"><a href="#change-User-Agent" class="headerlink" title="change User-Agent"></a>change User-Agent</h4><h5 id="check-scrapy-heads"><a href="#check-scrapy-heads" class="headerlink" title="check scrapy heads"></a>check scrapy heads</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\tinydeal&gt;scrapy shell <span class="string">&quot;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&quot;</span></span><br><span class="line">......</span><br><span class="line">2022-12-14 14:19:55 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line"><span class="comment"># show the flow</span></span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x00000265CAFC3850&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&gt;</span><br><span class="line">[s]   response   &lt;200 https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x00000265CAFC37F0&gt;</span><br><span class="line">[s]   spider     &lt;SpecialOffersSpider <span class="string">&#x27;special_offers&#x27;</span> at 0x265cb41db70&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update <span class="built_in">local</span> objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update <span class="built_in">local</span> objects</span><br><span class="line">[s]   shelp()           Shell <span class="built_in">help</span> (<span class="built_in">print</span> this <span class="built_in">help</span>)</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> a browser</span><br><span class="line">2022-12-14 14:19:56 [asyncio] DEBUG: Using selector: SelectSelector</span><br><span class="line"><span class="comment"># request header</span></span><br><span class="line">In [1]: request.headers</span><br><span class="line">Out[1]:</span><br><span class="line">&#123;b<span class="string">&#x27;Accept&#x27;</span>: b<span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line"> b<span class="string">&#x27;Accept-Language&#x27;</span>: b<span class="string">&#x27;en&#x27;</span>,</span><br><span class="line"> b<span class="string">&#x27;User-Agent&#x27;</span>: b<span class="string">&#x27;Scrapy/2.7.1 (+https://scrapy.org)&#x27;</span>,</span><br><span class="line"> b<span class="string">&#x27;Accept-Encoding&#x27;</span>: b<span class="string">&#x27;gzip, deflate&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># response request headers</span></span><br><span class="line">In [3]: response.request.headers</span><br><span class="line">Out[3]:</span><br><span class="line">&#123;b<span class="string">&#x27;Accept&#x27;</span>: b<span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line"> b<span class="string">&#x27;Accept-Language&#x27;</span>: b<span class="string">&#x27;en&#x27;</span>,</span><br><span class="line"> b<span class="string">&#x27;User-Agent&#x27;</span>: b<span class="string">&#x27;Scrapy/2.7.1 (+https://scrapy.org)&#x27;</span>,</span><br><span class="line"> b<span class="string">&#x27;Accept-Encoding&#x27;</span>: b<span class="string">&#x27;gzip, deflate&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">In [4]:</span><br></pre></td></tr></table></figure>

<h5 id="check-browser-user-agent"><a href="#check-browser-user-agent" class="headerlink" title="check browser user agent"></a>check browser user agent</h5><div style="max-width:1000px">
    <img src="/2022/12/04/python-8/pic1.png" class="" title="pic1">
</div>

<h5 id="change-User-Agent-by-settings-py-2-ways-option"><a href="#change-User-Agent-by-settings-py-2-ways-option" class="headerlink" title="change User-Agent by settings.py(2 ways option)"></a>change User-Agent by settings.py(2 ways option)</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line"><span class="comment">#USER_AGENT = &#x27;tinydeal (+http://www.yourdomain.com)&#x27;</span></span><br><span class="line"><span class="comment"># change user agent</span></span><br><span class="line">USER_AGENT = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Override the default request headers:</span></span><br><span class="line"><span class="comment">#DEFAULT_REQUEST_HEADERS = &#123;</span></span><br><span class="line"><span class="comment">#   &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;Accept-Language&#x27;: &#x27;en&#x27;,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"><span class="comment"># change default heads</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">  <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="change-User-Agent-by-py"><a href="#change-User-Agent-by-py" class="headerlink" title="change User-Agent by .py"></a>change User-Agent by .py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpecialOffersSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;special_offers&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;web.archive.org&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://web.archive.org/&#x27;]</span></span><br><span class="line">    <span class="comment"># change web site</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># change user agent</span></span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=<span class="string">&#x27;https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&#x27;</span>, callback=self.parse, headers=&#123;</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul[@class=&quot;productlisting-ul&quot;]/div/li&#x27;</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;title&#x27;</span>: product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;url&#x27;</span>: response.urljoin(product.xpath(<span class="string">&#x27;.//a[@class=&quot;p_box_title&quot;]/@href&#x27;</span>).get()),</span><br><span class="line">                <span class="string">&#x27;discounted_price&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[1]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;original_price&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;p_box_price&quot;]/span[2]/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="comment"># show response.request User-Agent</span></span><br><span class="line">                <span class="string">&#x27;User-Agent&#x27;</span>: response.request.headers[<span class="string">&#x27;User-Agent&#x27;</span>]</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.xpath(<span class="string">&#x27;//a[@class=&quot;nextPage&quot;]/@href&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            <span class="comment"># change user agent</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=next_page, callback=self.parse, headers=&#123;</span><br><span class="line">                <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\tinydeal&gt;scrapy crawl special_offers</span><br><span class="line">......</span><br><span class="line">2022-12-14 15:20:51 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;18g Super Strong Sealant Fix Metal Adhesive Sealing Glue Bond\xa0HHI-557389&#x27;</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://web.archive.org/web/20190225123327/https:/www.tinydeal.com/18g-super-strong-sealant-fix-metal-adhesive-sealing-glue-bond-p-177571.html&#x27;</span>, <span class="string">&#x27;discounted_price&#x27;</span>: <span class="string">&#x27;$1.40&#x27;</span>, <span class="string">&#x27;original_price&#x27;</span>: <span class="string">&#x27;$3.76 &#x27;</span>, <span class="string">&#x27;User-Agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-14 15:20:51 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://web.archive.org/web/20190225123327/https://www.tinydeal.com/specials.html&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;64GB USB 2.0 Flash Drive USB Pen Drive U Disk\xa0EFM-561923&#x27;</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://web.archive.org/web/20190225123327/https:/www.tinydeal.com/64gb-usb-20-flash-drive-usb-pen-drive-u-disk-p-178875.html&#x27;</span>, <span class="string">&#x27;discounted_price&#x27;</span>: <span class="string">&#x27;$6.42&#x27;</span>, <span class="string">&#x27;original_price&#x27;</span>: <span class="string">&#x27;$19.08 &#x27;</span>, <span class="string">&#x27;User-Agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<h3 id="glassesshop"><a href="#glassesshop" class="headerlink" title="glassesshop"></a>glassesshop</h3><h4 id="create-project-and-spider-1"><a href="#create-project-and-spider-1" class="headerlink" title="create project and spider"></a>create project and spider</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject glassesshop</span><br><span class="line">New Scrapy project <span class="string">&#x27;glassesshop&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\glassesshop</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> glassesshop</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> glassesshop</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\glassesshop&gt;scrapy genspider products https://www.glassesshop.com/bestsellers</span><br><span class="line">Created spider <span class="string">&#x27;products&#x27;</span> using template <span class="string">&#x27;basic&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  glassesshop.spiders.products</span><br></pre></td></tr></table></figure>

<h4 id="https-www-glassesshop-com-robots-txt"><a href="#https-www-glassesshop-com-robots-txt" class="headerlink" title="https://www.glassesshop.com/robots.txt"></a><a target="_blank" rel="noopener" href="https://www.glassesshop.com/robots.txt">https://www.glassesshop.com/robots.txt</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Disallow: &#x2F;login&#x2F;</span><br><span class="line">Disallow: &#x2F;register&#x2F;</span><br><span class="line">Disallow: &#x2F;promotion&#x2F;</span><br><span class="line">Disallow: &#x2F;cart&#x2F;</span><br><span class="line">Disallow: &#x2F;lens?*</span><br><span class="line">Disallow: &#x2F;lens&#x2F;new?*</span><br><span class="line">Disallow: *?currency*</span><br><span class="line">Disallow: *?source*</span><br><span class="line">Disallow: *?sort*</span><br><span class="line">Disallow: *?utm_source*</span><br><span class="line">Disallow: *&amp;currency*</span><br><span class="line">Disallow: *?referer*</span><br><span class="line">Disallow: *?PageSpeed*</span><br><span class="line"></span><br><span class="line">Sitemap: https:&#x2F;&#x2F;www.glassesshop.com&#x2F;sitemap.xml</span><br></pre></td></tr></table></figure>

<h4 id="products-py"><a href="#products-py" class="headerlink" title="products.py"></a>products.py</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProductsSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;products&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.glassesshop.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.glassesshop.com/bestsellers&#x27;</span>]</span><br><span class="line">    page_index = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//div[@class=&quot;col-12 pb-5 mb-lg-3 col-lg-4 product-list-row text-center product-list-item&quot;]&#x27;</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;product_name&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;p-title&quot;]/a/text()&#x27;</span>).get().strip(),</span><br><span class="line">                <span class="string">&#x27;product_price&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;p-price&quot;]/div/span/text()&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;product_url&#x27;</span>: product.xpath(<span class="string">&#x27;.//div[@class=&quot;product-img-outer&quot;]/a/@href&#x27;</span>).getall(),</span><br><span class="line">                <span class="string">&#x27;product_image&#x27;</span>: product.xpath(<span class="string">&#x27;.//img[@class=&quot;lazy d-block w-100 product-img-default&quot;]/@data-src&#x27;</span>).get().split(<span class="string">&#x27;?&#x27;</span>)[<span class="number">0</span>],</span><br><span class="line">                <span class="string">&#x27;page_number&#x27;</span>: self.page_index</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        self.page_index += <span class="number">1</span></span><br><span class="line">        next_page = response.xpath(<span class="string">&#x27;//a[@class=&quot;page-link&quot;][@rel=&quot;next&quot;]/@href&#x27;</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page:</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;link&#x27;</span> : next_page</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>

<h4 id="run-6"><a href="#run-6" class="headerlink" title="run"></a>run</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl products -o products.json</span><br></pre></td></tr></table></figure>

<h4 id="json"><a href="#json" class="headerlink" title="json"></a>json</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;product_name&quot;</span>: <span class="string">&quot;Union&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;product_price&quot;</span>: <span class="string">&quot;$35.95&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;product_url&quot;</span>: [</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz1750&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz1733&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz1731&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">&quot;product_image&quot;</span>: <span class="string">&quot;https://res.glassesshop.com/products/202108/610a547c82bdc.jpg&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;page_number&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;product_name&quot;</span>: <span class="string">&quot;Placerville&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;product_price&quot;</span>: <span class="string">&quot;$14.98&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;product_url&quot;</span>: [</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz2025&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz2022&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz2023&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/fz2024&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">&quot;product_image&quot;</span>: <span class="string">&quot;https://res.glassesshop.com/products/202209/63292118e1589.jpg&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;page_number&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;,</span><br><span class="line">		......</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">&quot;product_name&quot;</span>: <span class="string">&quot;Cloud&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;product_price&quot;</span>: <span class="string">&quot;$45.95&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;product_url&quot;</span>: [</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/sup1238&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/sup1239&quot;</span>,</span><br><span class="line">            <span class="string">&quot;https://www.glassesshop.com/eyeglasses/sup1240&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">&quot;product_image&quot;</span>: <span class="string">&quot;https://res.glassesshop.com/products/202109/613efbdd8b577.jpg&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;page_number&quot;</span>: <span class="number">4</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h3 id="imdb-crawl-template"><a href="#imdb-crawl-template" class="headerlink" title="imdb(crawl template)"></a>imdb(crawl template)</h3><h4 id="create-project-and-spider-2"><a href="#create-project-and-spider-2" class="headerlink" title="create project and spider"></a>create project and spider</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject imdb</span><br><span class="line">New Scrapy project <span class="string">&#x27;imdb&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\imdb</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> imdb</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> imdb</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy genspider -t crawl best_movies imdb.com</span><br><span class="line">Created spider <span class="string">&#x27;best_movies&#x27;</span> using template <span class="string">&#x27;crawl&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  imdb.spiders.best_movies</span><br></pre></td></tr></table></figure>

<h4 id="best-movies-py"><a href="#best-movies-py" class="headerlink" title="best_movies.py"></a>best_movies.py</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BestMoviesSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;best_movies&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;imdb.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://imdb.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r&#x27;Items/&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">        <span class="comment"># other link extractor condition</span></span><br><span class="line">        <span class="comment"># Rule(LinkExtractor(deny=r&#x27;Items/&#x27;), callback=&#x27;parse_item&#x27;, follow=True),</span></span><br><span class="line">        <span class="comment"># Rule(LinkExtractor(restrict_xpaths=&#x27;//a[@class=&quot;active&quot;]&#x27;), callback=&#x27;parse_item&#x27;, follow=True),</span></span><br><span class="line">        <span class="comment"># Rule(LinkExtractor(restrict_css=&#x27;&#x27;), callback=&#x27;parse_item&#x27;, follow=True),</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = &#123;&#125;</span><br><span class="line">        <span class="comment">#item[&#x27;domain_id&#x27;] = response.xpath(&#x27;//input[@id=&quot;sid&quot;]/@value&#x27;).get()</span></span><br><span class="line">        <span class="comment">#item[&#x27;name&#x27;] = response.xpath(&#x27;//div[@id=&quot;name&quot;]&#x27;).get()</span></span><br><span class="line">        <span class="comment">#item[&#x27;description&#x27;] = response.xpath(&#x27;//div[@id=&quot;description&quot;]&#x27;).get()</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h4 id="get-link"><a href="#get-link" class="headerlink" title="get link"></a>get link</h4><h5 id="best-movies-py-1"><a href="#best-movies-py-1" class="headerlink" title="best_movies.py"></a>best_movies.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># best_movies.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BestMoviesSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;best_movies&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;imdb.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&#x27;//h3[@class=&quot;lister-item-header&quot;]/a&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;************&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(response.url)</span><br></pre></td></tr></table></figure>

<h5 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a>settings.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># settings.py</span></span><br><span class="line"><span class="comment"># if no change head, reaposne code 403</span></span><br><span class="line"><span class="comment"># change default heads</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">  <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<h5 id="run-7"><a href="#run-7" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run</span></span><br><span class="line">myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br><span class="line">......</span><br><span class="line">2022-12-21 11:35:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&gt; (referer: None)</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">************</span><br><span class="line">https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0071562/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">************</span><br><span class="line">https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt</span><br><span class="line">************</span><br><span class="line">https://www.imdb.com/title/tt0071562/?ref_=adv_li_tt</span><br><span class="line">************</span><br><span class="line">https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">************</span><br><span class="line">https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 11:35:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="get-movies-information"><a href="#get-movies-information" class="headerlink" title="get movies information"></a>get movies information</h4><h5 id="runner-py"><a href="#runner-py" class="headerlink" title="runner.py"></a>runner.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># runner.py for imdb.spiders.best_movies</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerProcess</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"><span class="comment"># set crawl code</span></span><br><span class="line"><span class="keyword">from</span> imdb.spiders.best_movies <span class="keyword">import</span> BestMoviesSpider</span><br><span class="line"></span><br><span class="line"><span class="comment"># get configure</span></span><br><span class="line">process = CrawlerProcess(settings=get_project_settings())</span><br><span class="line"><span class="comment"># set crawl entry</span></span><br><span class="line">process.crawl(BestMoviesSpider)</span><br><span class="line">process.start()</span><br></pre></td></tr></table></figure>

<h5 id="best-movies-py-2"><a href="#best-movies-py-2" class="headerlink" title="best_movies.py"></a>best_movies.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># best_movies.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BestMoviesSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;best_movies&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;imdb.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&#x27;//h3[@class=&quot;lister-item-header&quot;]/a&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;sc-80d4314-1 fbQftq&#x27;]/h1/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;year&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;sc-8c396aa2-2 itZqyK&#x27;]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;&#x27;</span>.join(response.xpath(<span class="string">&quot;//ul[@class=&#x27;ipc-inline-list ipc-inline-list--show-dividers sc-8c396aa2-0 kqWovI baseAlt&#x27;]/li[3]/text()&quot;</span>).getall()),</span><br><span class="line">            <span class="string">&#x27;genre&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;ipc-chip-list__scroller&#x27;]/a/span/text()&quot;</span>).getall(),</span><br><span class="line">            <span class="string">&#x27;rating&#x27;</span>: response.xpath(<span class="string">&quot;//div[@data-testid=&#x27;hero-rating-bar__aggregate-rating__score&#x27;]/span[1]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;movie_url&#x27;</span>: response.url</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-8"><a href="#run-8" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br><span class="line">......</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;十二怒漢&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1957&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;1h 36m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;辛德勒的名單&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1993&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;3h 15m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Biography&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>, <span class="string">&#x27;History&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;教父&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1972&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 55m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.2&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0110912/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 15:57:52 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 15:57:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0110912/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;黑色追緝令&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1994&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 34m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;8.9&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0110912/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 15:57:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt&gt;</span><br><span class="line">......</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 30424,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 52,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 52,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 9412156,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 52,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 52,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 15.156407,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;finished&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 21, 9, 5, 16, 429558),</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_bytes&#x27;</span>: 51156690,</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_count&#x27;</span>: 50,</span><br><span class="line"> <span class="comment"># item_scraped_count</span></span><br><span class="line"> <span class="string">&#x27;item_scraped_count&#x27;</span>: 50,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 109,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;request_depth_max&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 52,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/200&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 51,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 51,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 51,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 51,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 21, 9, 5, 1, 273151)&#125;</span><br><span class="line">2022-12-21 17:05:16 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>

<h4 id="Following-liks-in-pagination"><a href="#Following-liks-in-pagination" class="headerlink" title="Following liks in pagination"></a>Following liks in pagination</h4><h5 id="best-movies-py-3"><a href="#best-movies-py-3" class="headerlink" title="best_movies.py"></a>best_movies.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># best_movies.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BestMoviesSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;best_movies&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;imdb.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;//h3[@class=&#x27;lister-item-header&#x27;]/a&quot;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">		Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;(//a[@class=&#x27;lister-page-next next-page&#x27;])[2]&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;sc-80d4314-1 fbQftq&#x27;]/h1/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;year&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;sc-8c396aa2-2 itZqyK&#x27;]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;&#x27;</span>.join(response.xpath(<span class="string">&quot;//ul[@class=&#x27;ipc-inline-list ipc-inline-list--show-dividers sc-8c396aa2-0 kqWovI baseAlt&#x27;]/li[3]/text()&quot;</span>).getall()),</span><br><span class="line">            <span class="string">&#x27;genre&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;ipc-chip-list__scroller&#x27;]/a/span/text()&quot;</span>).getall(),</span><br><span class="line">            <span class="string">&#x27;rating&#x27;</span>: response.xpath(<span class="string">&quot;//div[@data-testid=&#x27;hero-rating-bar__aggregate-rating__score&#x27;]/span[1]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;movie_url&#x27;</span>: response.url</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-9"><a href="#run-9" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run</span></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br><span class="line">......</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;十二怒漢&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1957&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;1h 36m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;辛德勒的名單&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1993&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;3h 15m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Biography&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>, <span class="string">&#x27;History&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;黑暗騎士&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2008&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 32m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Action&#x27;</span>, <span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">2022-12-21 17:12:56 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;刺激1995&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1994&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 22m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.3&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&#x27;</span>&#125;</span><br><span class="line">......</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 135320,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 33685481,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 37.338221,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;finished&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 21, 9, 15, 57, 911814),</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_bytes&#x27;</span>: 183562546,</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_count&#x27;</span>: 181,</span><br><span class="line"> <span class="string">&#x27;item_scraped_count&#x27;</span>: 181,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 374,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;request_depth_max&#x27;</span>: 4,</span><br><span class="line">  <span class="comment"># item_scraped_count</span></span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/200&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 21, 9, 15, 20, 573593)&#125;</span><br><span class="line">2022-12-21 17:15:57 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>

<h4 id="add-reguest-heads"><a href="#add-reguest-heads" class="headerlink" title="add reguest heads"></a>add reguest heads</h4><h5 id="best-movies-py-4"><a href="#best-movies-py-4" class="headerlink" title="best_movies.py"></a>best_movies.py</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># best_movies.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BestMoviesSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;best_movies&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;imdb.com&#x27;</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># change user agent</span></span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;]</span></span><br><span class="line">    user_agent = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=<span class="string">&#x27;https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&#x27;</span>, headers=&#123;</span><br><span class="line">        	<span class="string">&#x27;User-Agent&#x27;</span>: self.user_agent</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;//h3[@class=&#x27;lister-item-header&#x27;]/a&quot;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>, process_request=<span class="string">&#x27;set_user_agent&#x27;</span>),</span><br><span class="line">		<span class="comment"># add next page rule</span></span><br><span class="line">		Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;(//a[@class=&#x27;lister-page-next next-page&#x27;])[2]&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment"># for scrappier 2.0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_user_agent</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = self.user_agent</span><br><span class="line">        <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;sc-80d4314-1 fbQftq&#x27;]/h1/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;year&#x27;</span>: response.xpath(<span class="string">&quot;//span[@class=&#x27;sc-8c396aa2-2 itZqyK&#x27;]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;&#x27;</span>.join(response.xpath(<span class="string">&quot;//ul[@class=&#x27;ipc-inline-list ipc-inline-list--show-dividers sc-8c396aa2-0 kqWovI baseAlt&#x27;]/li[3]/text()&quot;</span>).getall()),</span><br><span class="line">            <span class="string">&#x27;genre&#x27;</span>: response.xpath(<span class="string">&quot;//div[@class=&#x27;ipc-chip-list__scroller&#x27;]/a/span/text()&quot;</span>).getall(),</span><br><span class="line">            <span class="string">&#x27;rating&#x27;</span>: response.xpath(<span class="string">&quot;//div[@data-testid=&#x27;hero-rating-bar__aggregate-rating__score&#x27;]/span[1]/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;movie_url&#x27;</span>: response.url,</span><br><span class="line">            <span class="string">&#x27;user-agent&#x27;</span>: response.request.headers[<span class="string">&#x27;User-Agent&#x27;</span>]</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h5 id="run-10"><a href="#run-10" class="headerlink" title="run"></a>run</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\imdb&gt;scrapy crawl best_movies</span><br><span class="line">......</span><br><span class="line">2022-12-21 20:08:51 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc&gt; (referer: None)</span><br><span class="line">2022-12-21 20:08:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0110912/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0110912/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;Pulp Fiction&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1994&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 34m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;8.9&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0110912/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0071562/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0071562/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;The Godfather Part II&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1974&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;3h 22m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0071562/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;The Lord of the Rings: The Return of the King&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2003&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;3h 21m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Action&#x27;</span>, <span class="string">&#x27;Adventure&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0167260/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;The Dark Knight&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;2008&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 32m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Action&#x27;</span>, <span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0468569/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;The Shawshank Redemption&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1994&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 22m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.3&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0111161/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&quot;Schindler&#x27;s List&quot;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1993&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;3h 15m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Biography&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>, <span class="string">&#x27;History&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0108052/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;12 Angry Men&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1957&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;1h 36m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.0&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0050083/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&gt;</span><br><span class="line">&#123;<span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;The Godfather&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="string">&#x27;1972&#x27;</span>, <span class="string">&#x27;duration&#x27;</span>: <span class="string">&#x27;2h 55m&#x27;</span>, <span class="string">&#x27;genre&#x27;</span>: [<span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>], <span class="string">&#x27;rating&#x27;</span>: <span class="string">&#x27;9.2&#x27;</span>, <span class="string">&#x27;movie_url&#x27;</span>: <span class="string">&#x27;https://www.imdb.com/title/tt0068646/?ref_=adv_li_tt&#x27;</span>, <span class="string">&#x27;user-agent&#x27;</span>: b<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">2022-12-21 20:08:55 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.imdb.com/title/tt15097216/?ref_=adv_li_tt&gt; (referer: https://www.imdb.com/search/title/?genres=drama&amp;groups=top_250&amp;sort=user_rating,desc)</span><br><span class="line">2022-12-21 20:08:55 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://www.imdb.com/title/tt15097216/?ref_=adv_li_tt&gt;</span><br><span class="line">.....</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 153035,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 33336260,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 37.364846,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;finished&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 21, 12, 9, 27, 445944),</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_bytes&#x27;</span>: 182944864,</span><br><span class="line"> <span class="string">&#x27;httpcompression/response_count&#x27;</span>: 181,</span><br><span class="line"> <span class="string">&#x27;item_scraped_count&#x27;</span>: 181,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 374,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 10,</span><br><span class="line"> <span class="string">&#x27;request_depth_max&#x27;</span>: 4,</span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 186,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/200&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 185,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 21, 12, 8, 50, 81098)&#125;</span><br><span class="line">2022-12-21 20:09:27 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>

<h3 id="books-toscrape-com"><a href="#books-toscrape-com" class="headerlink" title="books.toscrape.com"></a>books.toscrape.com</h3><h4 id="generate-project-and-spider"><a href="#generate-project-and-spider" class="headerlink" title="generate project and spider"></a>generate project and spider</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;scrapy startproject toscrape</span><br><span class="line">New Scrapy project <span class="string">&#x27;toscrape&#x27;</span>, using template directory <span class="string">&#x27;D:\app\python_env\myenv10_scrapy\lib\site-packages\scrapy\templates\project&#x27;</span>, created <span class="keyword">in</span>:</span><br><span class="line">    D:\work\run\python_crawler\101-scrapy\toscrape</span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> toscrape</span><br><span class="line">    scrapy genspider example example.com</span><br><span class="line"></span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy&gt;<span class="built_in">cd</span> toscrape</span><br><span class="line">(myenv10_scrapy) D:\work\run\python_crawler\101-scrapy\toscrape&gt;scrapy genspider -t crawl books www.udemy.com/course/web-scraping-in-python-using-scrapy-and-splash/learn/lecture/16263060<span class="comment">#overview</span></span><br><span class="line">Created spider <span class="string">&#x27;books&#x27;</span> using template <span class="string">&#x27;crawl&#x27;</span> <span class="keyword">in</span> module:</span><br><span class="line">  toscrape.spiders.books</span><br></pre></td></tr></table></figure>

<h4 id="books-py"><a href="#books-py" class="headerlink" title="books.py"></a>books.py</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BooksSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;books&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;books.toscrape.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://books.toscrape.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&#x27;//h3/a&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">        Rule(LinkExtractor(restrict_xpaths=<span class="string">&quot;//li[@class=&#x27;next&#x27;]/a&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;book_name&#x27;</span>: response.xpath(<span class="string">&quot;//h1/text()&quot;</span>).get(),</span><br><span class="line">            <span class="string">&#x27;book_price&#x27;</span>: response.xpath(<span class="string">&quot;//p[@class=&#x27;price_color&#x27;]/text()&quot;</span>).get()</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="run-11"><a href="#run-11" class="headerlink" title="run"></a>run</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl books -o books.csv</span><br><span class="line">......</span><br><span class="line">2022-12-21 22:31:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://books.toscrape.com/catalogue/jane-eyre_27/index.html&gt;</span><br><span class="line">&#123;<span class="string">&#x27;book_name&#x27;</span>: <span class="string">&#x27;Jane Eyre&#x27;</span>, <span class="string">&#x27;book_price&#x27;</span>: <span class="string">&#x27;£38.43&#x27;</span>&#125;</span><br><span class="line">2022-12-21 22:31:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://books.toscrape.com/catalogue/page-50.html&gt; (referer: http://books.toscrape.com/catalogue/page-49.html)</span><br><span class="line">2022-12-21 22:31:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://books.toscrape.com/catalogue/frankenstein_20/index.html&gt; (referer: http://books.toscrape.com/catalogue/page-50.html)</span><br><span class="line">2022-12-21 22:31:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://books.toscrape.com/catalogue/frankenstein_20/index.html&gt;</span><br><span class="line">&#123;<span class="string">&#x27;book_name&#x27;</span>: <span class="string">&#x27;Frankenstein&#x27;</span>, <span class="string">&#x27;book_price&#x27;</span>: <span class="string">&#x27;£38.00&#x27;</span>&#125;</span><br><span class="line">2022-12-21 22:31:41 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">2022-12-21 22:31:41 [scrapy.extensions.feedexport] INFO: Stored csv feed (1000 items) <span class="keyword">in</span>: books.csv</span><br><span class="line">2022-12-21 22:31:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;<span class="string">&#x27;downloader/request_bytes&#x27;</span>: 379636,</span><br><span class="line"> <span class="string">&#x27;downloader/request_count&#x27;</span>: 1051,</span><br><span class="line"> <span class="string">&#x27;downloader/request_method_count/GET&#x27;</span>: 1051,</span><br><span class="line"> <span class="string">&#x27;downloader/response_bytes&#x27;</span>: 22126017,</span><br><span class="line"> <span class="string">&#x27;downloader/response_count&#x27;</span>: 1051,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/200&#x27;</span>: 1050,</span><br><span class="line"> <span class="string">&#x27;downloader/response_status_count/404&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;dupefilter/filtered&#x27;</span>: 5979,</span><br><span class="line"> <span class="string">&#x27;elapsed_time_seconds&#x27;</span>: 50.440181,</span><br><span class="line"> <span class="string">&#x27;feedexport/success_count/FileFeedStorage&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;finished&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;finish_time&#x27;</span>: datetime.datetime(2022, 12, 21, 14, 31, 41, 402564),</span><br><span class="line"> <span class="string">&#x27;item_scraped_count&#x27;</span>: 1000,</span><br><span class="line"> <span class="string">&#x27;log_count/DEBUG&#x27;</span>: 2055,</span><br><span class="line"> <span class="string">&#x27;log_count/INFO&#x27;</span>: 11,</span><br><span class="line"> <span class="string">&#x27;request_depth_max&#x27;</span>: 51,</span><br><span class="line"> <span class="string">&#x27;response_received_count&#x27;</span>: 1051,</span><br><span class="line"> <span class="string">&#x27;robotstxt/request_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_count&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;robotstxt/response_status_count/404&#x27;</span>: 1,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued&#x27;</span>: 1050,</span><br><span class="line"> <span class="string">&#x27;scheduler/dequeued/memory&#x27;</span>: 1050,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued&#x27;</span>: 1050,</span><br><span class="line"> <span class="string">&#x27;scheduler/enqueued/memory&#x27;</span>: 1050,</span><br><span class="line"> <span class="string">&#x27;start_time&#x27;</span>: datetime.datetime(2022, 12, 21, 14, 30, 50, 962383)&#125;</span><br><span class="line">2022-12-21 22:31:41 [scrapy.core.engine] INFO: Spider closed (finished)</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/crawling/" rel="tag"># crawling</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/11/11/python-7/" rel="prev" title="Matplotlib (Python)">
                  <i class="fa fa-chevron-left"></i> Matplotlib (Python)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/12/15/python-9/" rel="next" title="Python Scrapy 說明(爬蟲框架)">
                  Python Scrapy 說明(爬蟲框架) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Robert Kao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="總字數">2.7m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="所需總閱讀時間">41:16</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  


<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://hot5656-blog.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://hot5656.github.io/2022/12/04/python-8/";
    this.page.identifier = "2022/12/04/python-8/";
    this.page.title = "Python Scrapy Example(爬蟲框架)";
    };
  NexT.utils.loadComments('#disqus_thread', () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://hot5656-blog.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
