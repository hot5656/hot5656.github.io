<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hot5656.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.2.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/search.json","localsearch":{"enable":"enable","trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="邏輯迴歸 - 信用卡,葡萄酒,糖尿病">
<meta property="og:type" content="article">
<meta property="og:title" content="(2) 機器學習最強入門:基礎數學&#x2F;機率&#x2F;統計邁向AI真實數據">
<meta property="og:url" content="https://hot5656.github.io/2024/06/27/python-33/index.html">
<meta property="og:site_name" content="Robert 雜記">
<meta property="og:description" content="邏輯迴歸 - 信用卡,葡萄酒,糖尿病">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic1.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic2.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic3.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic4.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic5.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic6.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic7.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic8.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic12.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic9.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic10.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic11.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic13.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic14.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic15.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic16.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic17.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic18.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic19.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic20.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic21.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic22.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic23.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic24.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic25.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic26.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic27.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic28.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic29.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic30.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic31.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic32.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic33.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic34.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic35.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic36.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic37.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic38.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic39.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic40.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic41.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic42.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic43.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic44.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic45.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic46.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic47.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic48.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic49.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic50.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic51.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic52.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic53.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic54.png">
<meta property="og:image" content="https://hot5656.github.io/2024/06/27/python-33/pic55.png">
<meta property="article:published_time" content="2024-06-27T07:05:38.000Z">
<meta property="article:modified_time" content="2024-08-05T07:15:17.135Z">
<meta property="article:author" content="Robert Kao">
<meta property="article:tag" content="book">
<meta property="article:tag" content="python">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hot5656.github.io/2024/06/27/python-33/pic1.png">


<link rel="canonical" href="https://hot5656.github.io/2024/06/27/python-33/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>
<title>(2) 機器學習最強入門:基礎數學/機率/統計邁向AI真實數據 | Robert 雜記</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Robert 雜記</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔列表</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8-%E4%BF%A1%E7%94%A8%E5%8D%A1-%E8%91%A1%E8%90%84%E9%85%92-%E7%B3%96%E5%B0%BF%E7%97%85"><span class="nav-number">1.</span> <span class="nav-text">邏輯迴歸 - 信用卡,葡萄酒,糖尿病</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8%E8%A7%80%E5%BF%B5"><span class="nav-number">1.1.</span> <span class="nav-text">邏輯迴歸觀念</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%87%89%E7%94%A8%E9%82%8F%E8%BC%AF%E5%87%BD%E6%95%B8"><span class="nav-number">1.1.1.</span> <span class="nav-text">應用邏輯函數</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A4%8E%E6%87%89%E7%94%A8"><span class="nav-number">1.2.</span> <span class="nav-text">邏輯迴歸模型基礎應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B%E8%AA%9E%E6%B3%95%E5%9F%BA%E7%A4%8E"><span class="nav-number">1.2.1.</span> <span class="nav-text">邏輯迴歸模型語法基礎</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%9A%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95"><span class="nav-number">1.2.2.</span> <span class="nav-text">多分類演算法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%95%B8%E6%93%9A%E9%9B%86%E8%A8%88%E7%AE%97"><span class="nav-number">1.3.</span> <span class="nav-text">信用卡數據集計算</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B8%E6%93%9A%E9%9B%86%E5%85%A7%E5%AE%B9"><span class="nav-number">1.3.1.</span> <span class="nav-text">數據集內容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8C%91%E9%81%B8%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%B5"><span class="nav-number">1.3.2.</span> <span class="nav-text">挑選重要特徵</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8%E6%9C%80%E7%9B%B8%E9%97%9C2%E5%80%8B%E7%89%B9%E5%BE%B5-%E8%A8%AD%E8%A8%88%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.3.</span> <span class="nav-text">用最相關2個特徵,設計邏輯迴歸模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8%E6%9C%80%E5%85%A8%E9%83%A8%E7%89%B9%E5%BE%B5-%E8%A8%AD%E8%A8%88%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B-%E5%B7%AE%E7%95%B0%E4%B8%8D%E5%A4%A7"><span class="nav-number">1.3.4.</span> <span class="nav-text">用最全部特徵,設計邏輯迴歸模型(差異不大)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%91%A1%E8%90%84%E9%85%92%E6%95%B8%E6%93%9A"><span class="nav-number">1.4.</span> <span class="nav-text">葡萄酒數據</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B8%E6%93%9A%E5%85%A7%E5%AE%B9"><span class="nav-number">1.4.1.</span> <span class="nav-text">數據內容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%82%8F%E8%BC%AF%E6%BC%94%E7%AE%97%E6%B3%95%E5%9F%B7%E8%A1%8C%E8%91%A1%E8%90%84%E9%85%92%E5%88%86%E9%A1%9E"><span class="nav-number">1.4.2.</span> <span class="nav-text">使用邏輯演算法執行葡萄酒分類</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B3%96%E5%B0%BF%E7%97%85%E6%95%B8%E6%93%9A"><span class="nav-number">1.5.</span> <span class="nav-text">糖尿病數據</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B8%E6%93%9A%E5%85%A7%E5%AE%B9-1"><span class="nav-number">1.5.1.</span> <span class="nav-text">數據內容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%99%95%E7%90%86%E6%BD%9B%E5%9C%A8%E7%BC%BA%E5%A4%B1%E5%80%BC-0"><span class="nav-number">1.5.2.</span> <span class="nav-text">處理潛在缺失值(0)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%B5%E7%9B%B4%E6%96%B9%E5%9C%96"><span class="nav-number">1.5.3.</span> <span class="nav-text">特徵直方圖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%B5%E7%AE%B1%E5%BD%A2%E5%9C%96"><span class="nav-number">1.5.4.</span> <span class="nav-text">特徵箱形圖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8%E6%89%80%E6%9C%89%E7%89%B9%E5%BE%B5%E5%81%9A%E7%B3%96%E5%B0%BF%E7%97%85%E6%82%A3%E8%80%85%E9%A0%90%E4%BC%B0"><span class="nav-number">1.5.5.</span> <span class="nav-text">用所有特徵做糖尿病患者預估</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E7%9A%AE%E7%88%BE%E9%81%9C%E7%9B%B8%E9%97%9C%E4%BF%82%E6%95%B8%E7%86%B1%E5%9C%96"><span class="nav-number">1.5.6.</span> <span class="nav-text">繪製皮爾遜相關係數熱圖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8%E6%9C%80%E7%9B%B8%E9%97%9C%E7%9A%AE%E7%88%BE%E9%81%9C%E7%9B%B8%E9%97%9C%E4%BF%82%E6%95%B8%E5%81%9A%E7%B3%96%E5%B0%BF%E7%97%85%E9%A0%90%E4%BC%B0"><span class="nav-number">1.5.7.</span> <span class="nav-text">用最相關皮爾遜相關係數做糖尿病預估</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B1%BA%E7%AD%96%E6%A8%B9-%E8%91%A1%E8%90%84%E9%85%92-%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F-Telco-Retail"><span class="nav-number">2.</span> <span class="nav-text">決策樹 - 葡萄酒,鐵達尼號,Telco,Retail</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B1%BA%E7%AD%96%E6%A8%B9%E8%A7%80%E5%BF%B5"><span class="nav-number">2.1.</span> <span class="nav-text">決策樹觀念</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%87%89%E7%94%A8%E5%9C%A8%E5%88%86%E9%A1%9E%E5%95%8F%E9%A1%8C"><span class="nav-number">2.1.1.</span> <span class="nav-text">應用在分類問題</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%87%89%E7%94%A8%E5%9C%A8%E8%BF%B4%E6%AD%B8%E5%95%8F%E9%A1%8C"><span class="nav-number">2.1.2.</span> <span class="nav-text">應用在迴歸問題</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%A9%E6%B0%A3%E6%95%B8%E6%93%9A%E6%87%89%E7%94%A8"><span class="nav-number">2.2.</span> <span class="nav-text">天氣數據應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E6%B1%BA%E7%AD%96%E6%A8%B9%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.2.1.</span> <span class="nav-text">建立決策樹模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%A9%E6%B0%A3%E6%95%B8%E6%93%9A%E5%AF%A6%E4%BE%8B"><span class="nav-number">2.2.2.</span> <span class="nav-text">天氣數據實例</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%91%A1%E8%90%84%E9%85%92%E6%95%B8%E6%93%9A-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">2.3.</span> <span class="nav-text">葡萄酒數據 - 分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%A0%90%E8%A8%AD%E6%A2%9D%E4%BB%B6%E8%99%95%E7%90%86%E8%91%A1%E8%90%84%E9%85%92%E6%95%B8%E6%93%9A"><span class="nav-number">2.3.1.</span> <span class="nav-text">預設條件處理葡萄酒數據</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%85%A9%E5%80%8B%E7%89%B9%E5%BE%B5-%E6%9B%B4%E6%94%B9%E6%B7%B1%E5%BA%A6"><span class="nav-number">2.3.2.</span> <span class="nav-text">使用兩個特徵,更改深度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E6%B1%BA%E7%AD%96%E6%A8%B9"><span class="nav-number">2.3.3.</span> <span class="nav-text">繪製決策樹</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%89%E8%A3%9D"><span class="nav-number">2.3.3.1.</span> <span class="nav-text">安裝</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD"><span class="nav-number">2.3.3.2.</span> <span class="nav-text">繪製</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">2.4.</span> <span class="nav-text">鐵達尼號 - 分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%90%B5%E9%81%94%E5%B0%BC%E6%95%B8%E6%93%9A"><span class="nav-number">2.4.1.</span> <span class="nav-text">鐵達尼數據</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B1%BA%E7%AD%96%E6%A8%B9%E8%A8%AD%E8%A8%88%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E9%A0%90%E6%B8%AC"><span class="nav-number">2.4.2.</span> <span class="nav-text">決策樹設計鐵達尼號預測</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E5%88%86%E6%9E%90%E8%A1%A8%E6%A0%BC%E4%BB%8B%E7%B4%B9"><span class="nav-number">2.4.3.</span> <span class="nav-text">交叉分析表格介紹</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E4%BA%A4%E5%8F%89%E5%88%86%E6%9E%90"><span class="nav-number">2.4.4.</span> <span class="nav-text">鐵達尼號交叉分析</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Telco-%E9%9B%BB%E4%BF%A1%E5%85%AC%E5%8F%B8-from-Kaggle-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">2.5.</span> <span class="nav-text">Telco 電信公司(from Kaggle) - 分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B8%E6%93%9A%E5%85%A7%E5%AE%B9-2"><span class="nav-number">2.5.1.</span> <span class="nav-text">數據內容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B1%BA%E7%AD%96%E6%A8%B9%E6%95%B8%E6%93%9A%E5%88%86%E6%9E%90"><span class="nav-number">2.5.2.</span> <span class="nav-text">決策樹數據分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%86%E8%A7%A3%E7%89%B9%E5%BE%B5%E5%B0%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7"><span class="nav-number">2.5.3.</span> <span class="nav-text">了解特徵對模型的重要性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%9C%80%E9%87%8D%E8%A6%815%E5%80%8B%E7%89%B9%E5%BE%B5%E5%81%9A%E6%B1%BA%E7%AD%96%E6%A8%B9%E6%95%B8%E6%93%9A%E5%88%86%E6%9E%90"><span class="nav-number">2.5.4.</span> <span class="nav-text">使用最重要5個特徵做決策樹數據分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89-%E6%B1%BA%E7%AD%96%E6%A8%B9%E6%9C%80%E4%BD%B3%E6%B7%B1%E5%BA%A6%E8%AA%BF%E6%95%B4"><span class="nav-number">2.5.5.</span> <span class="nav-text">交叉驗證 - 決策樹最佳深度調整</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Retail-Data-Analytics-%E8%BF%B4%E6%AD%B8%E6%87%89%E7%94%A8"><span class="nav-number">2.6.</span> <span class="nav-text">Retail Data Analytics - 迴歸應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8%E7%B0%A1%E5%96%AE%E6%95%B8%E6%93%9A%E9%A0%90%E4%BC%B0%E6%88%BF%E5%83%B9"><span class="nav-number">2.6.1.</span> <span class="nav-text">用簡單數據預估房價</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Retail-Data-Analytics"><span class="nav-number">2.6.2.</span> <span class="nav-text">Retail Data Analytics</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97%E6%A8%B9-%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9-%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F-Telco-%E6%94%B6%E5%85%A5%E5%88%86%E6%9E%90"><span class="nav-number">3.</span> <span class="nav-text">隨機森林樹-波士頓房價,鐵達尼號,Telco,收入分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9-%E8%BF%B4%E6%AD%B8%E6%87%89%E7%94%A8"><span class="nav-number">3.1.</span> <span class="nav-text">波士頓房價 - 迴歸應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B0%A1%E5%96%AE%E6%95%B8%E6%93%9A%E5%9F%B7%E8%A1%8C%E6%A3%AE%E6%9E%97%E6%A8%B9%E7%9A%84%E6%87%89%E7%94%A8"><span class="nav-number">3.1.1.</span> <span class="nav-text">簡單數據執行森林樹的應用</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9%E6%A3%AE%E6%9E%97%E6%A8%B9%E7%9A%84%E6%87%89%E7%94%A8"><span class="nav-number">3.1.2.</span> <span class="nav-text">波士頓房價森林樹的應用</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8-1"><span class="nav-number">3.2.</span> <span class="nav-text">鐵達尼號 - 分類應用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Telco-%E5%AE%A2%E6%88%B6%E6%B5%81%E5%A4%B1-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">3.3.</span> <span class="nav-text">Telco 客戶流失 - 分類應用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BE%8E%E5%9C%8B%E6%88%90%E5%B9%B4%E4%BA%BA%E6%94%B6%E5%85%A5%E5%88%86%E6%9E%90-kaggle-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">3.4.</span> <span class="nav-text">美國成年人收入分析(kaggle) - 分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#adult-csv-%E6%95%B8%E6%93%9A"><span class="nav-number">3.4.1.</span> <span class="nav-text">adult.csv 數據</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%B1%BA%E7%AD%96%E6%A8%B9%E8%99%95%E7%90%86%E5%B9%B4%E6%94%B6%E5%85%A5%E9%A0%90%E4%BC%B0"><span class="nav-number">3.4.2.</span> <span class="nav-text">使用決策樹處理年收入預估</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%B5%E4%B9%8B%E9%87%8D%E8%A6%81%E6%80%A7"><span class="nav-number">3.4.3.</span> <span class="nav-text">特徵之重要性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%BF%E7%94%A87%E5%80%8B%E6%9C%80%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%B5%E5%81%9A%E6%B1%BA%E7%AD%96%E6%A8%B9%E8%99%95%E7%90%86%E5%B9%B4%E6%94%B6%E5%85%A5%E9%A0%90%E4%BC%B0-%E4%B8%A6%E6%B2%92%E6%9C%89%E6%AF%94%E8%BC%83%E5%A5%BD"><span class="nav-number">3.4.4.</span> <span class="nav-text">使用7個最重要特徵做決策樹處理年收入預估 - 並沒有比較好</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97%E8%99%95%E7%90%86%E6%94%B6%E5%85%A5%E9%A0%90%E4%BC%B0-%E5%BE%97%E5%88%B0%E8%BC%83%E6%BA%96%E7%A2%BA%E7%B5%90%E6%9E%9C"><span class="nav-number">3.4.5.</span> <span class="nav-text">使用隨機森林處理收入預估 - 得到較準確結果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN-%E6%BC%94%E7%AE%97%E6%B3%95-%E9%B3%B6%E5%B0%BE%E8%8A%B1-%E5%B0%8F%E8%A1%8C%E6%98%9F%E6%92%9E%E5%9C%B0%E7%90%83"><span class="nav-number">4.</span> <span class="nav-text">KNN 演算法 - 鳶尾花,小行星撞地球</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#KNN-K-Nearest-Neighbors-K-%E6%9C%80%E8%BF%91%E9%84%B0-%E6%BC%94%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A4%8E%E8%A7%80%E5%BF%B5"><span class="nav-number">4.1.</span> <span class="nav-text">KNN(K-Nearest Neighbors K-最近鄰) 演算法基礎觀念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%BB%E5%BD%B1%E6%8E%A8%E8%96%A6-%E8%B6%B3%E7%90%83%E5%B0%84%E9%96%80-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">4.2.</span> <span class="nav-text">電影推薦,足球射門 - 分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B0%A1%E5%96%AE%E4%BE%8B%E5%AD%90"><span class="nav-number">4.2.1.</span> <span class="nav-text">簡單例子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%BB%E5%BD%B1%E6%8E%A8%E8%96%A6"><span class="nav-number">4.2.2.</span> <span class="nav-text">電影推薦</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B6%B3%E7%90%83%E9%80%B2%E7%90%83%E5%88%86%E6%9E%90"><span class="nav-number">4.2.3.</span> <span class="nav-text">足球進球分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E5%88%86%E9%A1%9E%E6%B1%BA%E7%AD%96%E9%82%8A%E7%95%8C-ecision-Boundary"><span class="nav-number">4.2.4.</span> <span class="nav-text">繪製分類決策邊界(ecision Boundary)</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8%E6%95%B8%E6%93%9A%E9%9B%86-%E7%B9%AA%E8%A3%BD%E6%95%A3%E9%BB%9E%E5%9C%96"><span class="nav-number">4.2.4.1.</span> <span class="nav-text">線性回歸數據集-繪製散點圖</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E5%88%86%E9%A1%9E%E9%82%8A%E7%95%8C"><span class="nav-number">4.2.4.2.</span> <span class="nav-text">繪製分類邊界</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E5%88%86%E9%A1%9E%E9%82%8A%E7%95%8C-%E8%AA%BF%E6%95%B4%E9%9A%A8%E6%A9%9F%E7%A8%AE%E5%AD%90%E5%8F%8Ak%E5%80%BC"><span class="nav-number">4.2.4.3.</span> <span class="nav-text">繪製分類邊界 - 調整隨機種子及k值</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%A4%9A%E9%A1%9E%E5%88%86%E6%9E%90"><span class="nav-number">4.2.4.4.</span> <span class="nav-text">多類分析</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%88%BF%E5%83%B9%E8%A8%88%E7%AE%97-%E9%81%B8%E8%88%89%E6%BA%96%E5%82%99%E9%A6%99%E8%85%B8-%E8%BF%B4%E6%AD%B8%E6%87%89%E7%94%A8"><span class="nav-number">4.3.</span> <span class="nav-text">房價計算,選舉準備香腸 - 迴歸應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#KNN%E8%BF%B4%E6%AD%B8%E6%87%89%E7%94%A8-%E7%B0%A1%E5%96%AE%E5%AF%A6%E4%BE%8B"><span class="nav-number">4.3.1.</span> <span class="nav-text">KNN迴歸應用 - 簡單實例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#KNN%E8%BF%B4%E6%AD%B8%E6%87%89%E7%94%A8-%E6%88%BF%E5%83%B9%E9%A0%90%E4%BC%B0"><span class="nav-number">4.3.2.</span> <span class="nav-text">KNN迴歸應用 - 房價預估</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%81%B8%E8%88%89%E9%80%A0%E5%8B%A2%E8%88%87%E6%BA%96%E5%82%99%E7%83%A4%E9%A6%99%E8%85%B8%E6%95%B8%E9%87%8F"><span class="nav-number">4.3.3.</span> <span class="nav-text">選舉造勢與準備烤香腸數量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#KKK-%E6%A8%A1%E5%9E%8B%E5%9B%9E%E6%AD%B8%E7%B7%9A%E5%88%86%E6%9E%90"><span class="nav-number">4.3.4.</span> <span class="nav-text">KKK 模型回歸線分析</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E6%95%A3%E9%BB%9E%E5%9C%96"><span class="nav-number">4.3.4.1.</span> <span class="nav-text">繪製散點圖</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BDKNN%E8%BF%B4%E6%AD%B8%E6%9B%B2%E7%B7%9A"><span class="nav-number">4.3.4.2.</span> <span class="nav-text">繪製KNN迴歸曲線</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%B3%B6%E5%B0%BE%E8%8A%B1%E6%95%B8%E6%93%9A-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">4.4.</span> <span class="nav-text">鳶尾花數據-分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%B3%B6%E5%B0%BE%E8%8A%B1%E6%95%B8%E6%93%9A%E5%85%A7%E5%AE%B9"><span class="nav-number">4.4.1.</span> <span class="nav-text">鳶尾花數據內容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BC%B8%E5%87%BA%E6%95%B8%E6%93%9A%E9%9B%86"><span class="nav-number">4.4.2.</span> <span class="nav-text">輸出數據集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8-Pandas-%E9%A1%AF%E7%A4%BA%E9%B3%B6%E5%B0%BE%E8%8A%B1%E6%95%B8%E6%93%9A"><span class="nav-number">4.4.3.</span> <span class="nav-text">用 Pandas 顯示鳶尾花數據</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E7%89%B9%E5%BE%B5%E6%95%A3%E9%BB%9E%E5%9C%96"><span class="nav-number">4.4.4.</span> <span class="nav-text">繪製特徵散點圖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E6%88%90%E5%B0%8D%E6%95%B8%E6%93%9A%E7%89%B9%E5%BE%B5%E6%95%A3%E9%BB%9E%E5%9C%96"><span class="nav-number">4.4.5.</span> <span class="nav-text">繪製成對數據特徵散點圖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E9%B3%B6%E5%B0%BE%E8%8A%B1%E6%B1%BA%E7%AD%96%E9%82%8A%E7%95%8C"><span class="nav-number">4.4.6.</span> <span class="nav-text">繪製鳶尾花決策邊界</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B9%AA%E8%A3%BD%E9%B3%B6%E5%B0%BE%E8%8A%B1%E6%B1%BA%E7%AD%96%E9%82%8A%E7%95%8C-%E4%B8%8D%E5%90%8Ck%E5%80%BC"><span class="nav-number">4.4.7.</span> <span class="nav-text">繪製鳶尾花決策邊界(不同k值)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A8%88%E7%AE%97%E6%9C%80%E5%84%AAk%E5%80%BC"><span class="nav-number">4.4.8.</span> <span class="nav-text">計算最優k值</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%8F%E8%A1%8C%E6%98%9F%E6%92%9E%E5%9C%B0%E7%90%83-%E5%88%86%E9%A1%9E%E6%87%89%E7%94%A8"><span class="nav-number">4.5.</span> <span class="nav-text">小行星撞地球-分類應用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Kaggle-NANA-ASteroids-Classification-%E6%95%B8%E6%93%9A"><span class="nav-number">4.5.1.</span> <span class="nav-text">Kaggle NANA ASteroids Classification 數據</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%A0%90%E8%99%95%E7%90%86%E8%B3%87%E6%96%99"><span class="nav-number">4.5.2.</span> <span class="nav-text">預處理資料</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%A0%90%E6%B8%AC%E5%B0%8F%E8%A1%8C%E6%98%9F%E6%92%9E%E5%9C%B0%E7%90%83%E6%BA%96%E7%A2%BA%E7%8E%87"><span class="nav-number">4.5.3.</span> <span class="nav-text">預測小行星撞地球準確率</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Robert Kao"
      src="/images/head.png">
  <p class="site-author-name" itemprop="name">Robert Kao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">170</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">66</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
        <div class="back-to-top animated" role="button">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://hot5656.github.io/2024/06/27/python-33/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="Robert Kao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Robert 雜記">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          (2) 機器學習最強入門:基礎數學/機率/統計邁向AI真實數據
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-06-27 15:05:38" itemprop="dateCreated datePublished" datetime="2024-06-27T15:05:38+08:00">2024-06-27</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新於</span>
        <time title="修改時間：2024-08-05 15:15:17" itemprop="dateModified" datetime="2024-08-05T15:15:17+08:00">2024-08-05</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Coding/" itemprop="url" rel="index"><span itemprop="name">Coding</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2024/06/27/python-33/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2024/06/27/python-33/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>88k</span>
    </span>
    <span class="post-meta-item" title="所需閱讀時間">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">所需閱讀時間 &asymp;</span>
      <span>1:20</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="邏輯迴歸-信用卡-葡萄酒-糖尿病"><a href="#邏輯迴歸-信用卡-葡萄酒-糖尿病" class="headerlink" title="邏輯迴歸 - 信用卡,葡萄酒,糖尿病"></a>邏輯迴歸 - 信用卡,葡萄酒,糖尿病</h3><span id="more"></span>

<h4 id="邏輯迴歸觀念"><a href="#邏輯迴歸觀念" class="headerlink" title="邏輯迴歸觀念"></a>邏輯迴歸觀念</h4><p>邏輯迴歸(logistic Regression)是一種常見的統計分析模型,邏輯迴歸經過一個邏輯(或稱 sigmoid)函數轉換,將輸出限制在0~1之間</p>
<h5 id="應用邏輯函數"><a href="#應用邏輯函數" class="headerlink" title="應用邏輯函數"></a>應用邏輯函數</h5><p>線性函數觀念 :<br>$y &#x3D; \beta_0 + \beta_1x$<br>將上述函數玷辱 Sigmoid 函數得到以下結果 :<br>$ f(x) &#x3D; \frac{1}{e^{-x}} &#x3D; \frac{1}{e^{-(\beta_0 + \beta_1x)}} $<br>有時以下列公式表示邏輯迴歸模型 :<br>$ P(Y&#x3D;1|X) &#x3D; \frac{1}{e^{-(\beta_0 + \beta_1x)}} $<br>P(Y&#x3D;1|X) 代表給定變數X下,Y等於1的機率,實務上是使用大概似估計法(Maximum Linkelihood Estimation,MLE)來進行求解</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 邏輯迴歸運算</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic_regression</span>(<span class="params">beta0, beta1, x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/( <span class="number">1</span> + np.exp(-(beta0 + beta1 * x)))</span><br><span class="line"></span><br><span class="line">beta0 = -<span class="number">6.5</span>                                                                         </span><br><span class="line">beta1 = <span class="number">0.0002</span></span><br><span class="line"></span><br><span class="line">x_values = [<span class="number">4000</span>, <span class="number">80000</span>]</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_values:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;x = <span class="subst">&#123;x:5d&#125;</span>, logistic迴歸輸出 <span class="subst">&#123;logistic_regression(beta0, beta1, x)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x =  4000, logistic迴歸輸出 0.0033348073074133443</span></span><br><span class="line"><span class="comment"># x = 80000, logistic迴歸輸出 0.9999251537724895</span></span><br></pre></td></tr></table></figure>

<h4 id="邏輯迴歸模型基礎應用"><a href="#邏輯迴歸模型基礎應用" class="headerlink" title="邏輯迴歸模型基礎應用"></a>邏輯迴歸模型基礎應用</h4><h5 id="邏輯迴歸模型語法基礎"><a href="#邏輯迴歸模型語法基礎" class="headerlink" title="邏輯迴歸模型語法基礎"></a>邏輯迴歸模型語法基礎</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> dump</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 20 個申請人年齡,年收入,已有債務</span></span><br><span class="line">applicants = np.array([</span><br><span class="line">    [<span class="number">25</span>, <span class="number">50000</span>, <span class="number">10000</span>],</span><br><span class="line">    [<span class="number">35</span>, <span class="number">60000</span>,  <span class="number">8000</span>],</span><br><span class="line">    [<span class="number">45</span>, <span class="number">70000</span>, <span class="number">12000</span>],</span><br><span class="line">    [<span class="number">55</span>, <span class="number">80000</span>, <span class="number">00000</span>],</span><br><span class="line">    [<span class="number">65</span>, <span class="number">60000</span>,  <span class="number">9000</span>],</span><br><span class="line">    [<span class="number">30</span>, <span class="number">40000</span>, <span class="number">12000</span>],</span><br><span class="line">    [<span class="number">40</span>, <span class="number">70000</span>,  <span class="number">8000</span>],</span><br><span class="line">    [<span class="number">50</span>, <span class="number">80000</span>, <span class="number">10000</span>],</span><br><span class="line">    [<span class="number">60</span>, <span class="number">80000</span>,  <span class="number">8000</span>],</span><br><span class="line">    [<span class="number">33</span>, <span class="number">50000</span>, <span class="number">11000</span>],</span><br><span class="line">    [<span class="number">26</span>, <span class="number">55000</span>, <span class="number">15000</span>],</span><br><span class="line">    [<span class="number">36</span>, <span class="number">65000</span>,  <span class="number">7500</span>],</span><br><span class="line">    [<span class="number">46</span>, <span class="number">75000</span>, <span class="number">13000</span>],</span><br><span class="line">    [<span class="number">56</span>, <span class="number">85000</span>, <span class="number">10000</span>],</span><br><span class="line">    [<span class="number">66</span>, <span class="number">65000</span>,  <span class="number">8500</span>],</span><br><span class="line">    [<span class="number">31</span>, <span class="number">45000</span>, <span class="number">11000</span>],</span><br><span class="line">    [<span class="number">41</span>, <span class="number">75000</span>,  <span class="number">8500</span>],</span><br><span class="line">    [<span class="number">51</span>, <span class="number">65000</span>,  <span class="number">9500</span>],</span><br><span class="line">    [<span class="number">61</span>, <span class="number">85000</span>,  <span class="number">8500</span>],</span><br><span class="line">    [<span class="number">34</span>, <span class="number">55000</span>, <span class="number">12000</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 違約紀錄 1:違約</span></span><br><span class="line">defaults = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分訓練集及測試集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(applicants,\</span><br><span class="line">                        defaults, test_size=<span class="number">0.2</span>, random_state=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立邏輯迴歸模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"><span class="comment"># 使用訓練集訓練模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型進行測試</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="comment"># 計算準確度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確度 : <span class="subst">&#123;accuracy_score(y_test, y_pred)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;真實數據\n <span class="subst">&#123;y_test&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;估計數據\n <span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">dump(model, <span class="string">&#x27;bank_ch24_1_2.joblib&#x27;</span>)</span><br><span class="line"><span class="comment"># 準確度 : 1.0</span></span><br><span class="line"><span class="comment"># 真實數據</span></span><br><span class="line"><span class="comment">#  [0 1 1 0]</span></span><br><span class="line"><span class="comment"># 估計數據</span></span><br><span class="line"><span class="comment">#  [0 1 1 0]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 測試應用公式</span></span><br><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">model = load(<span class="string">&#x27;bank_ch24_1_2.joblib&#x27;</span>)</span><br><span class="line">age = <span class="built_in">eval</span>(<span class="built_in">input</span>(<span class="string">&quot;請輸入年齡 : &quot;</span>))</span><br><span class="line">income = <span class="built_in">eval</span>(<span class="built_in">input</span>(<span class="string">&quot;請輸入年收入 :&quot;</span>))</span><br><span class="line">debt = <span class="built_in">eval</span>(<span class="built_in">input</span>(<span class="string">&quot;請輸入債務 :&quot;</span>))</span><br><span class="line"></span><br><span class="line">y_pred = model.predict([[age, income, debt]])</span><br><span class="line"><span class="keyword">if</span> y_pred[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;違規&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;未違規&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 請輸入年齡 : 50</span></span><br><span class="line"><span class="comment"># 請輸入年收入 :60000</span></span><br><span class="line"><span class="comment"># 請輸入債務 :1000</span></span><br><span class="line"><span class="comment"># 未違規</span></span><br><span class="line"><span class="comment"># 請輸入年齡 : 50</span></span><br><span class="line"><span class="comment"># 請輸入年收入 :60000</span></span><br><span class="line"><span class="comment"># 請輸入債務 :2000</span></span><br><span class="line"><span class="comment"># 違規</span></span><br></pre></td></tr></table></figure>

<h5 id="多分類演算法"><a href="#多分類演算法" class="headerlink" title="多分類演算法"></a>多分類演算法</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic1.png" class="" title="pic1">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic2.png" class="" title="pic2">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic3.png" class="" title="pic3">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic4.png" class="" title="pic4">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> exp</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">non_softmax</span>(<span class="params">input_vector</span>):</span></span><br><span class="line">    molecular = [j <span class="keyword">for</span> j <span class="keyword">in</span> input_vector]</span><br><span class="line">    p = [<span class="built_in">round</span>(i/<span class="built_in">sum</span>(molecular),<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> input_vector]</span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">input_vector</span>):</span></span><br><span class="line">    <span class="comment"># 計算分子</span></span><br><span class="line">    exponents = [exp(j) <span class="keyword">for</span> j <span class="keyword">in</span> input_vector]</span><br><span class="line">    <span class="comment"># 先加總分母</span></span><br><span class="line">    <span class="comment"># 分子除以分母</span></span><br><span class="line">    p = [<span class="built_in">round</span>(exp(i)/<span class="built_in">sum</span>(exponents), <span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> input_vector]</span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;一般公式    : <span class="subst">&#123;non_softmax([<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>])&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;softmax公式: <span class="subst">&#123;softmax([<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>])&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一般公式    : [0.1, 0.3, 0.6]</span></span><br><span class="line"><span class="comment"># softmax公式: [0.006, 0.047, 0.946]</span></span><br></pre></td></tr></table></figure>

<h4 id="信用卡數據集計算"><a href="#信用卡數據集計算" class="headerlink" title="信用卡數據集計算"></a>信用卡數據集計算</h4><h5 id="數據集內容"><a href="#數據集內容" class="headerlink" title="數據集內容"></a>數據集內容</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic5.png" class="" title="pic5">
</div>

<h5 id="挑選重要特徵"><a href="#挑選重要特徵" class="headerlink" title="挑選重要特徵"></a>挑選重要特徵</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 繪出特徵值</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;UCI_Credit_Card.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 顯示所有 columns</span></span><br><span class="line"><span class="comment"># pd.set_option(&#x27;display.max_columns&#x27;, None)</span></span><br><span class="line"><span class="comment"># # 設定顯示每 row 長度</span></span><br><span class="line"><span class="comment"># pd.set_option(&#x27;display.width&#x27;, 300)</span></span><br><span class="line"><span class="comment"># print(data.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵和目標變數</span></span><br><span class="line">features = data.drop([<span class="string">&quot;ID&quot;</span>, <span class="string">&quot;default.payment.next.month&quot;</span>], axis=<span class="number">1</span>)</span><br><span class="line">X = features</span><br><span class="line">y = data[<span class="string">&quot;default.payment.next.month&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵縮放(標準化)</span></span><br><span class="line"><span class="comment"># fit_transform 用於訓練數據：</span></span><br><span class="line"><span class="comment">#     fit 計算訓練數據的均值和方差</span></span><br><span class="line"><span class="comment">#     transform 使用這些計算出的均值和方差對訓練數據進行標準化</span></span><br><span class="line"><span class="comment"># transform 用於測試數據：</span></span><br><span class="line"><span class="comment">#     只使用訓練數據計算出的均值和方差來標準化測試數據，不會重新計算均值和方差</span></span><br><span class="line"><span class="comment"># 這樣做是為了避免數據洩漏，確保測試數據的標準化過程不受訓練數據的影響，同時保持測試數據的獨立性和真實性</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立邏輯迴歸模型 + 使用訓練集訓練模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 獲取特徵重要性</span></span><br><span class="line">importance = model.coef_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 總結特徵重要性</span></span><br><span class="line"><span class="keyword">for</span> i, score <span class="keyword">in</span> <span class="built_in">enumerate</span>(importance):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;特徵: <span class="subst">&#123;features.columns[i]:10s&#125;</span>, 分數: <span class="subst">&#123;score:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 繪製特徵重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.bar([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(importance))], importance)</span><br><span class="line"><span class="comment"># plt.xticks([x for x in range(len(importance))], features, rotation=&#x27;vertical&#x27;)</span></span><br><span class="line">plt.xticks([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(importance))], features, rotation=<span class="number">90</span>)</span><br><span class="line">plt.xticks()</span><br><span class="line">plt.title(<span class="string">&#x27;UCI_Credit_Card.csv&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵: LIMIT_BAL , 分數: -0.09251</span></span><br><span class="line"><span class="comment"># 特徵: SEX       , 分數: -0.05675</span></span><br><span class="line"><span class="comment"># 特徵: EDUCATION , 分數: -0.07002</span></span><br><span class="line"><span class="comment"># 特徵: MARRIAGE  , 分數: -0.08346</span></span><br><span class="line"><span class="comment"># 特徵: AGE       , 分數: 0.06998</span></span><br><span class="line"><span class="comment"># 特徵: PAY_0     , 分數: 0.63988</span></span><br><span class="line"><span class="comment"># 特徵: PAY_2     , 分數: 0.10731</span></span><br><span class="line"><span class="comment"># 特徵: PAY_3     , 分數: 0.09626</span></span><br><span class="line"><span class="comment"># 特徵: PAY_4     , 分數: 0.01599</span></span><br><span class="line"><span class="comment"># 特徵: PAY_5     , 分數: 0.03251</span></span><br><span class="line"><span class="comment"># 特徵: PAY_6     , 分數: 0.02136</span></span><br><span class="line"><span class="comment"># 特徵: BILL_AMT1 , 分數: -0.41557</span></span><br><span class="line"><span class="comment"># 特徵: BILL_AMT2 , 分數: 0.20846</span></span><br><span class="line"><span class="comment"># 特徵: BILL_AMT3 , 分數: 0.08524</span></span><br><span class="line"><span class="comment"># 特徵: BILL_AMT4 , 分數: 0.03273</span></span><br><span class="line"><span class="comment"># 特徵: BILL_AMT5 , 分數: -0.05235</span></span><br><span class="line"><span class="comment"># 特徵: BILL_AMT6 , 分數: 0.04633</span></span><br><span class="line"><span class="comment"># 特徵: PAY_AMT1  , 分數: -0.24341</span></span><br><span class="line"><span class="comment"># 特徵: PAY_AMT2  , 分數: -0.19772</span></span><br><span class="line"><span class="comment"># 特徵: PAY_AMT3  , 分數: -0.05722</span></span><br><span class="line"><span class="comment"># 特徵: PAY_AMT4  , 分數: -0.07154</span></span><br><span class="line"><span class="comment"># 特徵: PAY_AMT5  , 分數: -0.04787</span></span><br><span class="line"><span class="comment"># 特徵: PAY_AMT6  , 分數: -0.02067</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic6.png" class="" title="pic6">
</div>

<h5 id="用最相關2個特徵-設計邏輯迴歸模型"><a href="#用最相關2個特徵-設計邏輯迴歸模型" class="headerlink" title="用最相關2個特徵,設計邏輯迴歸模型"></a>用最相關2個特徵,設計邏輯迴歸模型</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用最相關2個特徵,設計邏輯迴歸模型</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;UCI_Credit_Card.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵和目標變數</span></span><br><span class="line">X = data[[<span class="string">&#x27;PAY_0&#x27;</span>,<span class="string">&#x27;BILL_AMT1&#x27;</span>]]</span><br><span class="line">y = data[<span class="string">&quot;default.payment.next.month&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵縮放(標準化)</span></span><br><span class="line"><span class="comment"># fit_transform 用於訓練數據：</span></span><br><span class="line"><span class="comment">#     fit 計算訓練數據的均值和方差</span></span><br><span class="line"><span class="comment">#     transform 使用這些計算出的均值和方差對訓練數據進行標準化</span></span><br><span class="line"><span class="comment"># transform 用於測試數據：</span></span><br><span class="line"><span class="comment">#     只使用訓練數據計算出的均值和方差來標準化測試數據，不會重新計算均值和方差</span></span><br><span class="line"><span class="comment"># 這樣做是為了避免數據洩漏，確保測試數據的標準化過程不受訓練數據的影響，同時保持測試數據的獨立性和真實性</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立邏輯迴歸模型 + 使用訓練集訓練模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在訓練集進行預測並計算準確率</span></span><br><span class="line">train_pred = model.predict(X_train)</span><br><span class="line">train_accuracy = accuracy_score(y_train, train_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;訓練集數據準確率 Accuracy: <span class="subst">&#123;train_accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">test_pred = model.predict(X_test)</span><br><span class="line">test_accuracy = accuracy_score(y_test, test_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試集數據準確率 Accuracy: <span class="subst">&#123;test_accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練集數據準確率 Accuracy: 81.15%</span></span><br><span class="line"><span class="comment"># 測試集數據準確率 Accuracy: 81.67%</span></span><br></pre></td></tr></table></figure>

<h5 id="用最全部特徵-設計邏輯迴歸模型-差異不大"><a href="#用最全部特徵-設計邏輯迴歸模型-差異不大" class="headerlink" title="用最全部特徵,設計邏輯迴歸模型(差異不大)"></a>用最全部特徵,設計邏輯迴歸模型(差異不大)</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用最全部特徵,設計邏輯迴歸模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵和目標變數</span></span><br><span class="line">X = data.drop([<span class="string">&quot;ID&quot;</span>, <span class="string">&quot;default.payment.next.month&quot;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&quot;default.payment.next.month&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練集數據準確率 Accuracy: 81.01%</span></span><br><span class="line"><span class="comment"># 測試集數據準確率 Accuracy: 81.30%</span></span><br></pre></td></tr></table></figure>

<h4 id="葡萄酒數據"><a href="#葡萄酒數據" class="headerlink" title="葡萄酒數據"></a>葡萄酒數據</h4><h5 id="數據內容"><a href="#數據內容" class="headerlink" title="數據內容"></a>數據內容</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic7.png" class="" title="pic7">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">wine = datasets.load_wine()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;自變數 樣本外型 : <span class="subst">&#123;wine.data.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目標變數樣本外型 : <span class="subst">&#123;wine.target.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出特徵值名稱</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自變數特徵值名稱&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.feature_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出三組自變數</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自變數特徵值&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.data[:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出三組目標變數</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;目標變數特徵值&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.target[:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 描述特徵值名稱</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;描述特徵值名稱&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.DESCR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自變數 樣本外型 : (178, 13)</span></span><br><span class="line"><span class="comment"># 目標變數樣本外型 : (178,)</span></span><br><span class="line"><span class="comment"># 自變數特徵值名稱</span></span><br><span class="line"><span class="comment"># [&#x27;alcohol&#x27;, &#x27;malic_acid&#x27;, &#x27;ash&#x27;, &#x27;alcalinity_of_ash&#x27;, &#x27;maglavanoids&#x27;, &#x27;nonflavanoid_phenols&#x27;, &#x27;proanthocyanins&#x27;, &#x27;co0/od315_of_diluted_wines&#x27;, &#x27;proline&#x27;]</span></span><br><span class="line"><span class="comment"># 自變數特徵值</span></span><br><span class="line"><span class="comment"># [[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e</span></span><br><span class="line"><span class="comment">#   2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e</span></span><br><span class="line"><span class="comment">#  [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e</span></span><br><span class="line"><span class="comment">#   2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e</span></span><br><span class="line"><span class="comment">#  [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e</span></span><br><span class="line"><span class="comment">#   3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e</span></span><br><span class="line"><span class="comment"># 目標變數特徵值</span></span><br><span class="line"><span class="comment"># [0 0 0]</span></span><br><span class="line"><span class="comment"># 描述特徵值名稱</span></span><br><span class="line"><span class="comment">#     ...</span></span><br></pre></td></tr></table></figure>

<h5 id="使用邏輯演算法執行葡萄酒分類"><a href="#使用邏輯演算法執行葡萄酒分類" class="headerlink" title="使用邏輯演算法執行葡萄酒分類"></a>使用邏輯演算法執行葡萄酒分類</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 葡萄酒數據</span></span><br><span class="line">wine = load_wine()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(wine.data, wine.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立邏輯迴歸分類器,使用 OvR</span></span><br><span class="line"><span class="comment"># multi_class: ovr, multination and auto</span></span><br><span class="line"><span class="comment"># max_iter 最大迭代數,達到後將停止最佳化,default 100</span></span><br><span class="line">log_reg = LogisticRegression(multi_class=<span class="string">&#x27;ovr&#x27;</span>, max_iter=<span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練分類器</span></span><br><span class="line">log_reg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = log_reg.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算準確度</span></span><br><span class="line">acc = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確度(Accuracy Score):<span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分類報告(Classification Report)\n<span class="subst">&#123;report&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 準確度(Accuracy Score):1.00</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[17  0  0]</span></span><br><span class="line"><span class="comment">#  [ 0 11  0]</span></span><br><span class="line"><span class="comment">#  [ 0  0  8]]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       1.00      1.00      1.00        17</span></span><br><span class="line"><span class="comment">#            1       1.00      1.00      1.00        11</span></span><br><span class="line"><span class="comment">#            2       1.00      1.00      1.00         8</span></span><br><span class="line"><span class="comment">#     accuracy                           1.00        36</span></span><br><span class="line"><span class="comment">#    macro avg       1.00      1.00      1.00        36</span></span><br><span class="line"><span class="comment"># weighted avg       1.00      1.00      1.00        36</span></span><br></pre></td></tr></table></figure>

<h4 id="糖尿病數據"><a href="#糖尿病數據" class="headerlink" title="糖尿病數據"></a>糖尿病數據</h4><h5 id="數據內容-1"><a href="#數據內容-1" class="headerlink" title="數據內容"></a>數據內容</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic8.png" class="" title="pic8">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示所有 columns</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 設定顯示每 row 長度</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">200</span>)</span><br><span class="line"><span class="built_in">print</span>(df.head())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定輸出到第二位小數</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.float_format&#x27;</span>, <span class="string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;輸出數據統計資訊&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.describe())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 檢查是否有缺失值</span></span><br><span class="line"><span class="built_in">print</span>(df.isnull().<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment">#    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFuncti</span></span><br><span class="line"><span class="comment"># 0            6      148             72             35        0  33.6                     0.6</span></span><br><span class="line"><span class="comment"># 1            1       85             66             29        0  26.6                     0.3</span></span><br><span class="line"><span class="comment"># 2            8      183             64              0        0  23.3                     0.6</span></span><br><span class="line"><span class="comment"># 3            1       89             66             23       94  28.1                     0.1</span></span><br><span class="line"><span class="comment"># 4            0      137             40             35      168  43.1                     2.2</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 輸出數據統計資訊</span></span><br><span class="line"><span class="comment">#        Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  DiabetesPedigreeF</span></span><br><span class="line"><span class="comment"># count       768.00   768.00         768.00         768.00   768.00 768.00</span></span><br><span class="line"><span class="comment"># mean          3.85   120.89          69.11          20.54    79.80  31.99</span></span><br><span class="line"><span class="comment"># 50%           3.00   117.00          72.00          23.00    30.50  32.00                      0.37  29.00     0.00</span></span><br><span class="line"><span class="comment"># 75%           6.00   140.25          80.00          32.00   127.25  36.60                      0.63  41.00     1.00</span></span><br><span class="line"><span class="comment"># max          17.00   199.00         122.00          99.00   846.00  67.10                      2.42  81.00     1.00</span></span><br><span class="line"><span class="comment"># Pregnancies                 0</span></span><br><span class="line"><span class="comment"># Glucose                     0</span></span><br><span class="line"><span class="comment"># BloodPressure               0</span></span><br><span class="line"><span class="comment"># SkinThickness               0</span></span><br><span class="line"><span class="comment"># Insulin                     0</span></span><br><span class="line"><span class="comment"># BMI                         0</span></span><br><span class="line"><span class="comment"># DiabetesPedigreeFunction    0</span></span><br><span class="line"><span class="comment"># Age                         0</span></span><br><span class="line"><span class="comment"># Outcome                     0</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure>

<h5 id="處理潛在缺失值-0"><a href="#處理潛在缺失值-0" class="headerlink" title="處理潛在缺失值(0)"></a>處理潛在缺失值(0)</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic12.png" class="" title="pic12">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中位數填補區失值</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可能存在缺失特徵</span></span><br><span class="line">columns_with_potential_missing_values = [<span class="string">&#x27;BloodPressure&#x27;</span>, <span class="string">&#x27;SkinThickness&#x27;</span>, <span class="string">&#x27;Insulin&#x27;</span>, <span class="string">&#x27;BMI&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將0值,替換為中位數</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> columns_with_potential_missing_values:</span><br><span class="line">    median = df[column].median()</span><br><span class="line">    df[column] = df[column].replace(to_replace=<span class="number">0</span>, value=median )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存入新的csv</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;new_diabetes.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h5 id="特徵直方圖"><a href="#特徵直方圖" class="headerlink" title="特徵直方圖"></a>特徵直方圖</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"><span class="comment"># 顯示負號</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;new_diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">titles = [<span class="string">&#x27;懷孕次數&#x27;</span>,<span class="string">&#x27;血糖值&#x27;</span>,<span class="string">&#x27;血壓&#x27;</span>,<span class="string">&#x27;皮膚厚度&#x27;</span>,<span class="string">&#x27;胰島素&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;BMI&#x27;</span>,<span class="string">&#x27;糖尿病家族函數&#x27;</span>,<span class="string">&#x27;年齡&#x27;</span>,<span class="string">&#x27;是否有糖尿病&#x27;</span>]</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(df.columns, <span class="number">1</span>):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">3</span>, <span class="number">3</span>, i)</span><br><span class="line">    df[col].hist(bins=<span class="number">10</span>, ax=ax)</span><br><span class="line">    ax.set_title(titles[i-<span class="number">1</span>], fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.3</span>, hspace=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic9.png" class="" title="pic9">
</div>

<h5 id="特徵箱形圖"><a href="#特徵箱形圖" class="headerlink" title="特徵箱形圖"></a>特徵箱形圖</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"><span class="comment"># 顯示負號</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;new_diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">titles = [<span class="string">&#x27;懷孕次數&#x27;</span>,<span class="string">&#x27;血糖值&#x27;</span>,<span class="string">&#x27;血壓&#x27;</span>,<span class="string">&#x27;皮膚厚度&#x27;</span>,<span class="string">&#x27;胰島素&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;BMI&#x27;</span>,<span class="string">&#x27;糖尿病家族函數&#x27;</span>,<span class="string">&#x27;年齡&#x27;</span>,<span class="string">&#x27;是否有糖尿病&#x27;</span>]</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(df.columns, <span class="number">1</span>):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">3</span>, <span class="number">3</span>, i)</span><br><span class="line">    sns.boxplot(y=df[col], ax=ax)</span><br><span class="line">    ax.set_title(titles[i-<span class="number">1</span>], fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.3</span>, hspace=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic10.png" class="" title="pic10">
</div>

<h5 id="用所有特徵做糖尿病患者預估"><a href="#用所有特徵做糖尿病患者預估" class="headerlink" title="用所有特徵做糖尿病患者預估"></a>用所有特徵做糖尿病患者預估</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, roc_auc_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;new_diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵及目標變數</span></span><br><span class="line">X = df.drop([<span class="string">&quot;Outcome&quot;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&quot;Outcome&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵縮放(標準化)</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立邏輯迴歸模型 + 使用訓練集訓練模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 訓練集進行預測並計算準確率</span></span><br><span class="line"><span class="comment"># train_pred = model.predict(X_train)</span></span><br><span class="line"><span class="comment"># train_accuracy = accuracy_score(y_train, train_pred)</span></span><br><span class="line"><span class="comment"># print(f&quot;訓練集數據準確率 Accuracy: &#123;train_accuracy*100:.2f&#125;%&quot;)</span></span><br><span class="line"><span class="comment"># # 測試集進行預測並計算準確率</span></span><br><span class="line"><span class="comment"># test_pred = model.predict(X_test)</span></span><br><span class="line"><span class="comment"># test_accuracy = accuracy_score(y_test, test_pred)</span></span><br><span class="line"><span class="comment"># print(f&quot;測試集數據準確率 Accuracy: &#123;test_accuracy*100:.2f&#125;%&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試集進行預測並計算準確率</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="comment"># Series 轉成 array</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試真實分類\n<span class="subst">&#123;y_test.to_numpy()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試預測分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列印準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy_score(y_test, y_pred):<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測採集樣本為正類的機率</span></span><br><span class="line"><span class="comment"># AUC-ROC（Area Under the Receiver Operating Characteristic Curve）分數</span></span><br><span class="line"><span class="comment"># 是一種評估二分類模型性能的指標。它表示模型區分正類和負類的能力，範圍從0.0到</span></span><br><span class="line"><span class="comment"># 1.0，1.0表示完美區分，0.5表示隨機猜測。</span></span><br><span class="line"><span class="comment"># model.predict_proba(X_test)[:,0]表為0的機率, model.predict_proba(X_test)[:,1]表為1的機率</span></span><br><span class="line">y_pred_prob = model.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;AOC-ROC: <span class="subst">&#123;roc_auc_score(y_test, y_pred_prob):<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1</span></span><br><span class="line"><span class="comment">#  1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1</span></span><br><span class="line"><span class="comment">#  0 0 1 0 0 0]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試預測分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1</span></span><br><span class="line"><span class="comment">#  1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0</span></span><br><span class="line"><span class="comment">#  0 0 1 0 0 1]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># Accuracy: 0.82468</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[91  9]</span></span><br><span class="line"><span class="comment">#  [18 36]]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># AOC-ROC: 0.87019</span></span><br></pre></td></tr></table></figure>

<h5 id="繪製皮爾遜相關係數熱圖"><a href="#繪製皮爾遜相關係數熱圖" class="headerlink" title="繪製皮爾遜相關係數熱圖"></a>繪製皮爾遜相關係數熱圖</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"><span class="comment"># 顯示負號</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;new_diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">df.columns = [<span class="string">&#x27;懷孕次數&#x27;</span>,<span class="string">&#x27;血糖值&#x27;</span>,<span class="string">&#x27;血壓&#x27;</span>,<span class="string">&#x27;皮膚厚度&#x27;</span>,<span class="string">&#x27;胰島素&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;BMI&#x27;</span>,<span class="string">&#x27;糖尿病家族函數&#x27;</span>,<span class="string">&#x27;年齡&#x27;</span>,<span class="string">&#x27;是否有糖尿病&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line">sns.heatmap(df.corr(), annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span> )</span><br><span class="line">plt.title(<span class="string">&#x27;糖尿病特徵皮爾遜相關係數熱力圖&#x27;</span>)</span><br><span class="line">plt.yticks(rotation=<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic11.png" class="" title="pic11">
</div>

<h5 id="用最相關皮爾遜相關係數做糖尿病預估"><a href="#用最相關皮爾遜相關係數做糖尿病預估" class="headerlink" title="用最相關皮爾遜相關係數做糖尿病預估"></a>用最相關皮爾遜相關係數做糖尿病預估</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, roc_auc_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取糖尿病數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;new_diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以 Outcome 皮爾遜相關係數為基礎,由大到小排列</span></span><br><span class="line">correlation = df.corr()[<span class="string">&#x27;Outcome&#x27;</span>].sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 選擇最相關特徵</span></span><br><span class="line">cor_nums = <span class="number">2</span></span><br><span class="line">features = correlation.index[<span class="number">1</span>:cor_nums+<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;輸出相關係數:<span class="subst">&#123;features&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵及目標變數</span></span><br><span class="line">X = df[features]</span><br><span class="line">y = df[<span class="string">&quot;Outcome&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵縮放(標準化)</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立邏輯迴歸模型 + 使用訓練集訓練模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試集進行預測並計算準確率</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="comment"># Series 轉成 array</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試真實分類\n<span class="subst">&#123;y_test.to_numpy()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試預測分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列印準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy_score(y_test, y_pred):<span class="number">.5</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測採集樣本為正類的機率</span></span><br><span class="line"><span class="comment"># AUC-ROC（Area Under the Receiver Operating Characteristic Curve）分數</span></span><br><span class="line"><span class="comment"># 是一種評估二分類模型性能的指標。它表示模型區分正類和負類的能力，範圍從0.0到</span></span><br><span class="line"><span class="comment"># 1.0，1.0表示完美區分，0.5表示隨機猜測。</span></span><br><span class="line"><span class="comment"># model.predict_proba(X_test)[:,0]表為0的機率, model.predict_proba(X_test)[:,1]表為1的機率</span></span><br><span class="line">y_pred_prob = model.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;AOC-ROC: <span class="subst">&#123;roc_auc_score(y_test, y_pred_prob):<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出相關係數:Index([&#x27;Glucose&#x27;, &#x27;BMI&#x27;], dtype=&#x27;object&#x27;)</span></span><br><span class="line"><span class="comment"># 測試真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1</span></span><br><span class="line"><span class="comment">#  1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1</span></span><br><span class="line"><span class="comment">#  0 0 1 0 0 0]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試預測分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1</span></span><br><span class="line"><span class="comment">#  1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0</span></span><br><span class="line"><span class="comment">#  0 0 1 0 0 1]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># Accuracy: 0.79870%</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[90 10]</span></span><br><span class="line"><span class="comment">#  [21 33]]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># AOC-ROC: 0.85861</span></span><br></pre></td></tr></table></figure>

<h3 id="決策樹-葡萄酒-鐵達尼號-Telco-Retail"><a href="#決策樹-葡萄酒-鐵達尼號-Telco-Retail" class="headerlink" title="決策樹 - 葡萄酒,鐵達尼號,Telco,Retail"></a>決策樹 - 葡萄酒,鐵達尼號,Telco,Retail</h3><h4 id="決策樹觀念"><a href="#決策樹觀念" class="headerlink" title="決策樹觀念"></a>決策樹觀念</h4><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic13.png" class="" title="pic13">
</div>

<h5 id="應用在分類問題"><a href="#應用在分類問題" class="headerlink" title="應用在分類問題"></a>應用在分類問題</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic14.png" class="" title="pic14">
</div>

<h5 id="應用在迴歸問題"><a href="#應用在迴歸問題" class="headerlink" title="應用在迴歸問題"></a>應用在迴歸問題</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic15.png" class="" title="pic15">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic16.png" class="" title="pic16">
</div>

<h4 id="天氣數據應用"><a href="#天氣數據應用" class="headerlink" title="天氣數據應用"></a>天氣數據應用</h4><h5 id="建立決策樹模型"><a href="#建立決策樹模型" class="headerlink" title="建立決策樹模型"></a>建立決策樹模型</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic17.png" class="" title="pic17">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic18.png" class="" title="pic18">
</div>

<h5 id="天氣數據實例"><a href="#天氣數據實例" class="headerlink" title="天氣數據實例"></a>天氣數據實例</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic19.png" class="" title="pic19">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵和目標變數</span></span><br><span class="line">features = [[<span class="string">&#x27;晴&#x27;</span>,<span class="string">&#x27;熱&#x27;</span>,<span class="string">&#x27;弱&#x27;</span>],[<span class="string">&#x27;晴&#x27;</span>,<span class="string">&#x27;熱&#x27;</span>,<span class="string">&#x27;強&#x27;</span>],[<span class="string">&#x27;陰&#x27;</span>,<span class="string">&#x27;熱&#x27;</span>,<span class="string">&#x27;弱&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;雨&#x27;</span>,<span class="string">&#x27;涼&#x27;</span>,<span class="string">&#x27;弱&#x27;</span>],[<span class="string">&#x27;雨&#x27;</span>,<span class="string">&#x27;冷&#x27;</span>,<span class="string">&#x27;弱&#x27;</span>],[<span class="string">&#x27;雨&#x27;</span>,<span class="string">&#x27;冷&#x27;</span>,<span class="string">&#x27;強&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;陰&#x27;</span>,<span class="string">&#x27;冷&#x27;</span>,<span class="string">&#x27;強&#x27;</span>]]</span><br><span class="line">labels = [<span class="string">&#x27;是&#x27;</span>,<span class="string">&#x27;否&#x27;</span>,<span class="string">&#x27;是&#x27;</span>,<span class="string">&#x27;是&#x27;</span>,<span class="string">&#x27;否&#x27;</span>,<span class="string">&#x27;否&#x27;</span>,<span class="string">&#x27;是&#x27;</span>]</span><br><span class="line"></span><br><span class="line">label_encoders = []</span><br><span class="line">features_encoded = []</span><br><span class="line"><span class="comment"># 將特徵變數轉為數字編碼</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(features[<span class="number">0</span>])):</span><br><span class="line">    <span class="comment"># 特徵編碼</span></span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    feature_encoded = le.fit_transform([row[i] <span class="keyword">for</span> row <span class="keyword">in</span> features])</span><br><span class="line">    features_encoded.append(feature_encoded)</span><br><span class="line">    <span class="comment"># 紀錄文字轉數字公式(1)</span></span><br><span class="line">    label_encoders.append(le)</span><br><span class="line"><span class="comment"># 3*7 array 轉成 7*3</span></span><br><span class="line">features_encoded = np.array(features_encoded).T</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;特徵標籤編碼:\n<span class="subst">&#123;features_encoded&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將目標變數轉為數字編碼</span></span><br><span class="line">label_encoder_label = LabelEncoder()</span><br><span class="line">labels_encoded = label_encoder_label.fit_transform(labels)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目標變數編碼:\n<span class="subst">&#123;labels_encoded&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dtc = DecisionTreeClassifier()</span><br><span class="line">dtc.fit(features_encoded, labels_encoded)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用新的觀察值來進行預測</span></span><br><span class="line">test_features = [[<span class="string">&#x27;晴&#x27;</span>,<span class="string">&#x27;涼&#x27;</span>,<span class="string">&#x27;弱&#x27;</span>]]</span><br><span class="line"><span class="comment"># 建立二維 0 矩陣</span></span><br><span class="line">test_features_encoded = np.zeros((<span class="number">1</span>, <span class="built_in">len</span>(test_features[<span class="number">0</span>])))</span><br><span class="line"><span class="comment"># print(test_features_encoded)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_features[<span class="number">0</span>])):</span><br><span class="line">    <span class="comment"># 利用 文字轉數字公式(1) 設定對應值</span></span><br><span class="line">    test_features_encoded[<span class="number">0</span>, i] = label_encoders[i].transform([test_features[<span class="number">0</span>][i]])[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;測試數據編碼\n<span class="subst">&#123;test_features_encoded&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出預測數字標籤</span></span><br><span class="line">pred = dtc.predict(test_features_encoded)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;預測結果 : <span class="subst">&#123;pred&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轉換輸出數字為文字</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;預測結果 : <span class="subst">&#123;label_encoder_label.inverse_transform(pred)[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵標籤編碼:</span></span><br><span class="line"><span class="comment"># [[0 2 0]</span></span><br><span class="line"><span class="comment">#  [0 2 1]</span></span><br><span class="line"><span class="comment">#  [1 2 0]</span></span><br><span class="line"><span class="comment">#  [2 1 0]</span></span><br><span class="line"><span class="comment">#  [2 0 0]</span></span><br><span class="line"><span class="comment">#  [2 0 1]</span></span><br><span class="line"><span class="comment">#  [1 0 1]]</span></span><br><span class="line"><span class="comment"># 目標變數編碼:</span></span><br><span class="line"><span class="comment"># [1 0 1 1 0 0 1]</span></span><br><span class="line"><span class="comment"># 測試數據編碼</span></span><br><span class="line"><span class="comment"># [[0. 1. 0.]]</span></span><br><span class="line"><span class="comment"># 預測結果 : [1]</span></span><br><span class="line"><span class="comment"># 預測結果 : 是</span></span><br></pre></td></tr></table></figure>
<h4 id="葡萄酒數據-分類應用"><a href="#葡萄酒數據-分類應用" class="headerlink" title="葡萄酒數據 - 分類應用"></a>葡萄酒數據 - 分類應用</h4><h5 id="預設條件處理葡萄酒數據"><a href="#預設條件處理葡萄酒數據" class="headerlink" title="預設條件處理葡萄酒數據"></a>預設條件處理葡萄酒數據</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 葡萄酒數據</span></span><br><span class="line">wine = load_wine()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(wine.data, wine.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dtc = DecisionTreeClassifier()</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測結果比較</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試第1個標籤         :<span class="subst">&#123;y_pred[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試第1個標籤各分類機率:<span class="subst">&#123;dtc.predict_proba(X_test[:<span class="number">1</span>])&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列印準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;方法1 測試數據準確率 : <span class="subst">&#123;accuracy_score(y_test, y_pred)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 另一方法準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;方法2 訓練數據準確率 : <span class="subst">&#123;dtc.score(X_train, y_train)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;方法2 測試數據準確率 : <span class="subst">&#123;dtc.score(X_test, y_test)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 1 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 測試第1個標籤         :0</span></span><br><span class="line"><span class="comment"># 測試第1個標籤各分類機率:[[1. 0. 0.]]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 方法1 測試數據準確率 : 0.9722222222222222</span></span><br><span class="line"><span class="comment"># 方法2 訓練數據準確率 : 1.0</span></span><br><span class="line"><span class="comment"># 方法2 測試數據準確率 : 0.9722222222222222</span></span><br></pre></td></tr></table></figure>

<h5 id="使用兩個特徵-更改深度"><a href="#使用兩個特徵-更改深度" class="headerlink" title="使用兩個特徵,更改深度"></a>使用兩個特徵,更改深度</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> dump</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 葡萄酒數據</span></span><br><span class="line">wine = load_wine()</span><br><span class="line"><span class="comment"># 取前兩個特徵</span></span><br><span class="line">X = wine.data[:,:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, wine.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練(max_depth=1)</span></span><br><span class="line">dtc1 = DecisionTreeClassifier(max_depth=<span class="number">1</span>)</span><br><span class="line">dtc1.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc1.predict(X_test)</span><br><span class="line"><span class="comment"># 預測結果比較</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;max_depth=1 測試數據準確率 : <span class="subst">&#123;dtc1.score(X_test, y_test):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練(max_depth=3)</span></span><br><span class="line">dtc3 = DecisionTreeClassifier(max_depth=<span class="number">3</span>)</span><br><span class="line">dtc3.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc3.predict(X_test)</span><br><span class="line"><span class="comment"># 預測結果比較</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;max_depth=1 測試數據準確率 : <span class="subst">&#123;dtc3.score(X_test, y_test):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 儲存公式</span></span><br><span class="line"><span class="comment"># add feature name and class_names</span></span><br><span class="line">feature_names = [<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;malic_acid&#x27;</span>]</span><br><span class="line">class_names = [<span class="string">&#x27;Barolo&#x27;</span>,<span class="string">&#x27;Grignolino&#x27;</span>,<span class="string">&#x27;Barbera&#x27;</span>]</span><br><span class="line">dump((dtc3, feature_names, class_names), <span class="string">&#x27;dtc3.joblib&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 儲存公式</span></span><br><span class="line"><span class="comment"># default feature name, no class name</span></span><br><span class="line"><span class="comment"># dump(dtc3, &#x27;dtc3.joblib&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># max_depth=1 測試數據準確率 : 0.78</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 2 0 0 0 2 1 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># max_depth=1 測試數據準確率 : 0.89</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br></pre></td></tr></table></figure>

<h5 id="繪製決策樹"><a href="#繪製決策樹" class="headerlink" title="繪製決策樹"></a>繪製決策樹</h5><h6 id="安裝"><a href="#安裝" class="headerlink" title="安裝"></a>安裝</h6><ul>
<li>安裝 Graphviz  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install graphviz</span><br></pre></td></tr></table></figure></li>
<li>下載 <a target="_blank" rel="noopener" href="https://graphviz.org/download/">graphviz program</a></li>
<li>解壓縮至 computer</li>
<li>set path<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set from vscode example</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;terminal.integrated.profiles.windows&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;PowerShell&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;source&quot;</span>: <span class="string">&quot;PowerShell&quot;</span>,</span><br><span class="line">      <span class="string">&quot;env&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;PATH&quot;</span>: <span class="string">&quot;<span class="variable">$&#123;env:PATH&#125;</span>;D:\\app\\python_other\\Graphviz-12.0.0-win64\\bin&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;Command Prompt&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;path&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;<span class="variable">$&#123;env:windir&#125;</span>\\System32\\cmd.exe&quot;</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="string">&quot;env&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;PATH&quot;</span>: <span class="string">&quot;<span class="variable">$&#123;env:PATH&#125;</span>;D:\\app\\python_other\\Graphviz-12.0.0-win64\bin&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;terminal.integrated.defaultProfile.windows&quot;</span>: <span class="string">&quot;PowerShell&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h6 id="繪製"><a href="#繪製" class="headerlink" title="繪製"></a>繪製</h6><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 繪製決策樹</span></span><br><span class="line"><span class="comment"># pip install Graphviz</span></span><br><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> load</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> graphviz <span class="keyword">import</span> Source</span><br><span class="line"></span><br><span class="line"><span class="comment"># dtc3.joblib include feature name and class_names</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># default feature name, no class name</span></span><br><span class="line">dtc, feature_names, class_names = load(<span class="string">&#x27;dtc3.joblib&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add feature name and class_names</span></span><br><span class="line"><span class="comment"># feature_names = [&#x27;alcohol&#x27;,&#x27;malic_acid&#x27;]</span></span><br><span class="line"><span class="comment"># class_names = [&#x27;Barolo&#x27;,&#x27;Grignolino&#x27;,&#x27;Barbera&#x27;]</span></span><br><span class="line">grpah = Source(tree.export_graphviz(dtc, out_file=<span class="literal">None</span>, feature_names=feature_names, class_names=class_names, filled=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># default feature name, no class name</span></span><br><span class="line"><span class="comment"># grpah = Source(tree.export_graphviz(dtc, out_file=None))</span></span><br><span class="line">grpah.<span class="built_in">format</span> = <span class="string">&#x27;png&#x27;</span></span><br><span class="line">grpah.render(filename=<span class="string">&#x27;dtc_tree&#x27;</span>, view=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic20.png" class="" title="pic20">
</div>

<ul>
<li>使用 gini 演算法</li>
<li>value 表示各類別包含數量</li>
<li>顏色表示歸類類別</li>
</ul>
<h4 id="鐵達尼號-分類應用"><a href="#鐵達尼號-分類應用" class="headerlink" title="鐵達尼號 - 分類應用"></a>鐵達尼號 - 分類應用</h4><h5 id="鐵達尼數據"><a href="#鐵達尼數據" class="headerlink" title="鐵達尼數據"></a>鐵達尼數據</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic21.png" class="" title="pic21">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示所有 columns</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 設定顯示每 row 長度</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">300</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 數據</span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看數據基本欄位資料</span></span><br><span class="line"><span class="built_in">print</span>(titanic.info())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看數據統計資料</span></span><br><span class="line"><span class="built_in">print</span>(titanic.describe())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示前5筆資料</span></span><br><span class="line"><span class="built_in">print</span>(titanic.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 檢查資料缺失</span></span><br><span class="line"><span class="built_in">print</span>(titanic.isnull().<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="comment"># RangeIndex: 891 entries, 0 to 890</span></span><br><span class="line"><span class="comment"># Data columns (total 15 columns):</span></span><br><span class="line"><span class="comment">#  #   Column       Non-Null Count  Dtype</span></span><br><span class="line"><span class="comment"># ---  ------       --------------  -----</span></span><br><span class="line"><span class="comment">#  0   survived     891 non-null    int64</span></span><br><span class="line"><span class="comment">#  1   pclass       891 non-null    int64</span></span><br><span class="line"><span class="comment">#  2   sex          891 non-null    object</span></span><br><span class="line"><span class="comment">#  3   age          714 non-null    float64</span></span><br><span class="line"><span class="comment">#  4   sibsp        891 non-null    int64</span></span><br><span class="line"><span class="comment">#  5   parch        891 non-null    int64</span></span><br><span class="line"><span class="comment">#  6   fare         891 non-null    float64</span></span><br><span class="line"><span class="comment">#  7   embarked     889 non-null    object</span></span><br><span class="line"><span class="comment">#  8   class        891 non-null    category</span></span><br><span class="line"><span class="comment">#  9   who          891 non-null    object</span></span><br><span class="line"><span class="comment">#  10  adult_male   891 non-null    bool</span></span><br><span class="line"><span class="comment">#  11  deck         203 non-null    category</span></span><br><span class="line"><span class="comment">#  12  embark_town  889 non-null    object</span></span><br><span class="line"><span class="comment">#  13  alive        891 non-null    object</span></span><br><span class="line"><span class="comment">#  14  alone        891 non-null    bool</span></span><br><span class="line"><span class="comment"># dtypes: bool(2), category(2), float64(2), int64(4), object(5)</span></span><br><span class="line"><span class="comment"># memory usage: 80.7+ KB</span></span><br><span class="line"><span class="comment"># None</span></span><br><span class="line"><span class="comment">#          survived      pclass         age       sibsp       parch        fare</span></span><br><span class="line"><span class="comment"># count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000</span></span><br><span class="line"><span class="comment"># mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208</span></span><br><span class="line"><span class="comment"># std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429</span></span><br><span class="line"><span class="comment"># min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000</span></span><br><span class="line"><span class="comment"># 25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400</span></span><br><span class="line"><span class="comment"># 50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200</span></span><br><span class="line"><span class="comment"># 75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000</span></span><br><span class="line"><span class="comment"># max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200</span></span><br><span class="line"><span class="comment">#    survived  pclass     sex   age  sibsp  parch     fare embarked  class    who  adult_male deck  embark_town alive  alone</span></span><br><span class="line"><span class="comment"># 0         0       3    male  22.0      1      0   7.2500        S  Third    man        True  NaN  Southampton    no  False</span></span><br><span class="line"><span class="comment"># 1         1       1  female  38.0      1      0  71.2833        C  First  woman       False    C    Cherbourg   yes  False</span></span><br><span class="line"><span class="comment"># 2         1       3  female  26.0      0      0   7.9250        S  Third  woman       False  NaN  Southampton   yes   True</span></span><br><span class="line"><span class="comment"># 3         1       1  female  35.0      1      0  53.1000        S  First  woman       False    C  Southampton   yes  False</span></span><br><span class="line"><span class="comment"># 4         0       3    male  35.0      0      0   8.0500        S  Third    man        True  NaN  Southampton    no   True</span></span><br><span class="line"><span class="comment"># survived         0</span></span><br><span class="line"><span class="comment"># pclass           0</span></span><br><span class="line"><span class="comment"># sex              0</span></span><br><span class="line"><span class="comment"># age            177</span></span><br><span class="line"><span class="comment"># sibsp            0</span></span><br><span class="line"><span class="comment"># parch            0</span></span><br><span class="line"><span class="comment"># fare             0</span></span><br><span class="line"><span class="comment"># embarked         2</span></span><br><span class="line"><span class="comment"># class            0</span></span><br><span class="line"><span class="comment"># who              0</span></span><br><span class="line"><span class="comment"># adult_male       0</span></span><br><span class="line"><span class="comment"># deck           688</span></span><br><span class="line"><span class="comment"># embark_town      2</span></span><br><span class="line"><span class="comment"># alive            0</span></span><br><span class="line"><span class="comment"># alone            0</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure>

<h5 id="決策樹設計鐵達尼號預測"><a href="#決策樹設計鐵達尼號預測" class="headerlink" title="決策樹設計鐵達尼號預測"></a>決策樹設計鐵達尼號預測</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic22.png" class="" title="pic22">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 數據</span></span><br><span class="line">titanic_data = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"><span class="comment"># 選取有用特徵</span></span><br><span class="line">titanic_data = titanic_data[[<span class="string">&#x27;survived&#x27;</span>,<span class="string">&#x27;pclass&#x27;</span>,<span class="string">&#x27;sex&#x27;</span>,<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;sibsp&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;parch&#x27;</span>,<span class="string">&#x27;fare&#x27;</span>,<span class="string">&#x27;embarked&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(titanic_data)</span></span><br><span class="line"><span class="comment"># print(titanic_data[&#x27;age&#x27;])</span></span><br><span class="line"><span class="comment"># 年齡補上中位數年齡</span></span><br><span class="line">titanic_data[<span class="string">&#x27;age&#x27;</span>] = titanic_data[<span class="string">&#x27;age&#x27;</span>].fillna(titanic_data[<span class="string">&#x27;age&#x27;</span>].median())</span><br><span class="line"><span class="comment"># 登船港口用眾位數取代缺失值</span></span><br><span class="line"><span class="comment"># mode() 傳回的是一個包含眾數的 Series，因此需要取 [0] 來獲取第一個眾數</span></span><br><span class="line">titanic_data[<span class="string">&#x27;embarked&#x27;</span>] = titanic_data[<span class="string">&#x27;embarked&#x27;</span>].fillna(titanic_data[<span class="string">&#x27;embarked&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 對性別,登船港口 執行 on-hot 編碼</span></span><br><span class="line"><span class="comment"># get_dummies 是 Pandas 中的一個函數，用於將分類變數轉換為一個或多個虛擬變數（dummy variables）。</span></span><br><span class="line"><span class="comment"># 這些虛擬變數可以用於機器學習模型，因為大多數模型不能直接處理非數值型資料。</span></span><br><span class="line">titanic_data = pd.get_dummies(titanic_data, columns=[<span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;embarked&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割數據為訓練集及測試集</span></span><br><span class="line">X = titanic_data.drop(<span class="string">&#x27;survived&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = titanic_data[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(titanic_data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dtc = DecisionTreeClassifier(random_state=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測結果比較</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test.to_numpy()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;dtc.score(X_test, y_test):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分類報告(Classification Report)\n<span class="subst">&#123;report&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#    survived  pclass   age  sibsp  parch     fare  sex_female  sex_male  embarked_C  embarked_Q  embarked_S</span></span><br><span class="line"><span class="comment"># 0         0       3  22.0      1      0   7.2500       False      True       False       False        True</span></span><br><span class="line"><span class="comment"># 1         1       1  38.0      1      0  71.2833        True     False        True       False       False</span></span><br><span class="line"><span class="comment"># 2         1       3  26.0      0      0   7.9250        True     False       False       False        True</span></span><br><span class="line"><span class="comment"># 3         1       1  35.0      1      0  53.1000        True     False       False       False        True</span></span><br><span class="line"><span class="comment"># 4         0       3  35.0      0      0   8.0500       False      True       False       False        True</span></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0</span></span><br><span class="line"><span class="comment">#  0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1</span></span><br><span class="line"><span class="comment">#  0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0</span></span><br><span class="line"><span class="comment">#  0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1</span></span><br><span class="line"><span class="comment">#  0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 準確率 : 0.82</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># 111位沒有存活: 98正確 19錯誤</span></span><br><span class="line"><span class="comment"># 62位存活: 19正確 13錯誤</span></span><br><span class="line"><span class="comment"># [[98 13]</span></span><br><span class="line"><span class="comment">#  [19 49]]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.84      0.88      0.86       111</span></span><br><span class="line"><span class="comment">#            1       0.79      0.72      0.75        68</span></span><br><span class="line"><span class="comment">#     accuracy                           0.82       179</span></span><br><span class="line"><span class="comment">#    macro avg       0.81      0.80      0.81       179</span></span><br><span class="line"><span class="comment"># weighted avg       0.82      0.82      0.82       179</span></span><br></pre></td></tr></table></figure>

<h5 id="交叉分析表格介紹"><a href="#交叉分析表格介紹" class="headerlink" title="交叉分析表格介紹"></a>交叉分析表格介紹</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立 DataFrame</span></span><br><span class="line">df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;性別&#x27;</span>:[<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;女&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;喜好&#x27;</span>:[<span class="string">&#x27;籃球&#x27;</span>,<span class="string">&#x27;足球&#x27;</span>,<span class="string">&#x27;籃球&#x27;</span>,<span class="string">&#x27;足球&#x27;</span>,<span class="string">&#x27;籃球&#x27;</span>,<span class="string">&#x27;足球&#x27;</span>,<span class="string">&#x27;籃球&#x27;</span>,<span class="string">&#x27;籃球&#x27;</span>,<span class="string">&#x27;棒球&#x27;</span>,<span class="string">&#x27;棒球&#x27;</span>]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 創建交叉分析表</span></span><br><span class="line">cross_tbl = pd.crosstab(df[<span class="string">&#x27;性別&#x27;</span>], df[<span class="string">&#x27;喜好&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(cross_tbl)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 喜好  棒球  籃球  足球</span></span><br><span class="line"><span class="comment"># 性別</span></span><br><span class="line"><span class="comment"># 女       1     3     1</span></span><br><span class="line"><span class="comment"># 男       1     2     2</span></span><br></pre></td></tr></table></figure>

<h5 id="鐵達尼號交叉分析"><a href="#鐵達尼號交叉分析" class="headerlink" title="鐵達尼號交叉分析"></a>鐵達尼號交叉分析</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> graphviz <span class="keyword">import</span> Source</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 數據</span></span><br><span class="line">titanic_data = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"><span class="comment"># 選取有用特徵</span></span><br><span class="line">titanic_data = titanic_data[[<span class="string">&#x27;survived&#x27;</span>,<span class="string">&#x27;pclass&#x27;</span>,<span class="string">&#x27;sex&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 sex 轉位數字</span></span><br><span class="line">sex_encoder = LabelEncoder()</span><br><span class="line"><span class="comment"># print(titanic_data[&#x27;sex&#x27;])</span></span><br><span class="line">sex_encoded = sex_encoder.fit_transform(titanic_data[<span class="string">&#x27;sex&#x27;</span>])</span><br><span class="line">titanic_data[<span class="string">&#x27;sex&#x27;</span>] = sex_encoded</span><br><span class="line"><span class="comment"># print(titanic_data[&#x27;sex&#x27;])</span></span><br><span class="line"><span class="comment"># male=1 female=0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割數據為訓練集及測試集</span></span><br><span class="line">X = titanic_data.drop(<span class="string">&#x27;survived&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = titanic_data[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dt_classifier = DecisionTreeClassifier()</span><br><span class="line">dt_classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dt_classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測結果比較</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;1表存活&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test.to_numpy()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;dt_classifier.score(X_test, y_test):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測採集樣本為正類的機率</span></span><br><span class="line"><span class="comment"># AUC-ROC（Area Under the Receiver Operating Characteristic Curve）分數</span></span><br><span class="line"><span class="comment"># 是一種評估二分類模型性能的指標。它表示模型區分正類和負類的能力，範圍從0.0到</span></span><br><span class="line"><span class="comment"># 1.0，1.0表示完美區分，0.5表示隨機猜測。</span></span><br><span class="line"><span class="comment"># pre_rate[:,0]表為0的機率, pre_rate[:,0]表為1的機率</span></span><br><span class="line">pre_rate = dt_classifier.predict_proba(X_test)</span><br><span class="line"><span class="comment"># 交叉分析表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;1表female&#x27;</span>)</span><br><span class="line">cross_tbl = pd.crosstab(pre_rate[:,<span class="number">0</span>],</span><br><span class="line">                columns=[X_test[<span class="string">&#x27;pclass&#x27;</span>], X_test[<span class="string">&#x27;sex&#x27;</span>]])</span><br><span class="line"><span class="built_in">print</span>(cross_tbl)</span><br><span class="line"></span><br><span class="line"><span class="comment">#add feature name and class_names</span></span><br><span class="line">feature_names = [<span class="string">&#x27;pclass&#x27;</span>,<span class="string">&#x27;sex&#x27;</span>]</span><br><span class="line">class_names = [<span class="string">&#x27;survived&#x27;</span>,<span class="string">&#x27;dead&#x27;</span>]</span><br><span class="line">grpah = Source(tree.export_graphviz(dt_classifier, out_file=<span class="literal">None</span>, feature_names=feature_names, class_names=class_names, filled=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">grpah.<span class="built_in">format</span> = <span class="string">&#x27;png&#x27;</span></span><br><span class="line">grpah.render(filename=<span class="string">&#x27;dt_classifier_tree&#x27;</span>, view=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1表存活</span></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0</span></span><br><span class="line"><span class="comment">#  0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1</span></span><br><span class="line"><span class="comment">#  0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0</span></span><br><span class="line"><span class="comment">#  1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0</span></span><br><span class="line"><span class="comment">#  0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1</span></span><br><span class="line"><span class="comment">#  0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 準確率 : 0.79</span></span><br><span class="line"><span class="comment"># 1表female</span></span><br><span class="line"><span class="comment"># pclass     1       2       3</span></span><br><span class="line"><span class="comment"># sex        0   1   0   1   0   1</span></span><br><span class="line"><span class="comment"># row_0</span></span><br><span class="line"><span class="comment"># 0.027397  21   0   0   0   0   0</span></span><br><span class="line"><span class="comment"># 0.067797   0   0  17   0   0   0</span></span><br><span class="line"><span class="comment"># 0.495935   0   0   0   0  21   0</span></span><br><span class="line"><span class="comment"># 0.647619   0  17   0   0   0   0</span></span><br><span class="line"><span class="comment"># 0.835443   0   0   0  29   0   0</span></span><br><span class="line"><span class="comment"># 0.868132   0   0   0   0   0  74</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic23.png" class="" title="pic23">
</div>

<h4 id="Telco-電信公司-from-Kaggle-分類應用"><a href="#Telco-電信公司-from-Kaggle-分類應用" class="headerlink" title="Telco 電信公司(from Kaggle) - 分類應用"></a>Telco 電信公司(from Kaggle) - 分類應用</h4><h5 id="數據內容-2"><a href="#數據內容-2" class="headerlink" title="數據內容"></a>數據內容</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic24.png" class="" title="pic24">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic25.png" class="" title="pic25">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove field ID</span></span><br><span class="line">df = df.drop([<span class="string">&#x27;customerID&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 標籤轉成數值</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> df[column].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        le = LabelEncoder()</span><br><span class="line">        df[column] = le.fit_transform(df[column])</span><br><span class="line">        <span class="keyword">if</span> column != <span class="string">&#x27;TotalCharges&#x27;</span>:</span><br><span class="line">            <span class="comment"># 列出原符號和對應的數值</span></span><br><span class="line">            label_mapping = <span class="built_in">dict</span>(<span class="built_in">zip</span>(le.classes_, le.transform(le.classes_)))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;column&#125;</span> <span class="subst">&#123;label_mapping&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># show 數據統計資料及檢查資料缺失</span></span><br><span class="line"><span class="built_in">print</span>(df.isnull().info())</span><br><span class="line"><span class="built_in">print</span>(df.isnull().<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刪除缺失值,處理缺失數據(本例其實不需要)</span></span><br><span class="line">df= df.dropna()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show 數據統計資料及檢查資料缺失</span></span><br><span class="line"><span class="comment"># print(df.isnull().info())</span></span><br><span class="line"><span class="comment"># print(df.isnull().sum())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># show 5 records</span></span><br><span class="line"><span class="built_in">print</span>(df.head())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># gender &#123;&#x27;Female&#x27;: 0, &#x27;Male&#x27;: 1&#125;</span></span><br><span class="line"><span class="comment"># Partner &#123;&#x27;No&#x27;: 0, &#x27;Yes&#x27;: 1&#125;</span></span><br><span class="line"><span class="comment"># Dependents &#123;&#x27;No&#x27;: 0, &#x27;Yes&#x27;: 1&#125;</span></span><br><span class="line"><span class="comment"># PhoneService &#123;&#x27;No&#x27;: 0, &#x27;Yes&#x27;: 1&#125;</span></span><br><span class="line"><span class="comment"># MultipleLines &#123;&#x27;No&#x27;: 0, &#x27;No phone service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># InternetService &#123;&#x27;DSL&#x27;: 0, &#x27;Fiber optic&#x27;: 1, &#x27;No&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># OnlineSecurity &#123;&#x27;No&#x27;: 0, &#x27;No internet service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># OnlineBackup &#123;&#x27;No&#x27;: 0, &#x27;No internet service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># DeviceProtection &#123;&#x27;No&#x27;: 0, &#x27;No internet service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># TechSupport &#123;&#x27;No&#x27;: 0, &#x27;No internet service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># StreamingTV &#123;&#x27;No&#x27;: 0, &#x27;No internet service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># StreamingMovies &#123;&#x27;No&#x27;: 0, &#x27;No internet service&#x27;: 1, &#x27;Yes&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># Contract &#123;&#x27;Month-to-month&#x27;: 0, &#x27;One year&#x27;: 1, &#x27;Two year&#x27;: 2&#125;</span></span><br><span class="line"><span class="comment"># PaperlessBilling &#123;&#x27;No&#x27;: 0, &#x27;Yes&#x27;: 1&#125;</span></span><br><span class="line"><span class="comment"># PaymentMethod &#123;&#x27;Bank transfer (automatic)&#x27;: 0, &#x27;Credit card (automatic)&#x27;: 1, &#x27;Electronic check&#x27;: 2, &#x27;Mailed check&#x27;: 3&#125;</span></span><br><span class="line"><span class="comment"># Churn &#123;&#x27;No&#x27;: 0, &#x27;Yes&#x27;: 1&#125;</span></span><br><span class="line"><span class="comment"># &lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="comment"># RangeIndex: 7043 entries, 0 to 7042</span></span><br><span class="line"><span class="comment"># Data columns (total 20 columns):</span></span><br><span class="line"><span class="comment">#  #   Column            Non-Null Count  Dtype</span></span><br><span class="line"><span class="comment"># ---  ------            --------------  -----</span></span><br><span class="line"><span class="comment">#  0   gender            7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  1   SeniorCitizen     7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  2   Partner           7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  3   Dependents        7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  4   tenure            7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  5   PhoneService      7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  6   MultipleLines     7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  7   InternetService   7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  8   OnlineSecurity    7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  9   OnlineBackup      7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  10  DeviceProtection  7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  11  TechSupport       7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  12  StreamingTV       7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  13  StreamingMovies   7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  14  Contract          7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  15  PaperlessBilling  7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  16  PaymentMethod     7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  17  MonthlyCharges    7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  18  TotalCharges      7043 non-null   bool</span></span><br><span class="line"><span class="comment">#  19  Churn             7043 non-null   bool</span></span><br><span class="line"><span class="comment"># dtypes: bool(20)</span></span><br><span class="line"><span class="comment"># memory usage: 137.7 KB</span></span><br><span class="line"><span class="comment"># None</span></span><br><span class="line"><span class="comment"># gender              0</span></span><br><span class="line"><span class="comment"># SeniorCitizen       0</span></span><br><span class="line"><span class="comment"># Partner             0</span></span><br><span class="line"><span class="comment"># Dependents          0</span></span><br><span class="line"><span class="comment"># tenure              0</span></span><br><span class="line"><span class="comment"># PhoneService        0</span></span><br><span class="line"><span class="comment"># MultipleLines       0</span></span><br><span class="line"><span class="comment"># InternetService     0</span></span><br><span class="line"><span class="comment"># OnlineSecurity      0</span></span><br><span class="line"><span class="comment"># OnlineBackup        0</span></span><br><span class="line"><span class="comment"># DeviceProtection    0</span></span><br><span class="line"><span class="comment"># TechSupport         0</span></span><br><span class="line"><span class="comment"># StreamingTV         0</span></span><br><span class="line"><span class="comment"># StreamingMovies     0</span></span><br><span class="line"><span class="comment"># Contract            0</span></span><br><span class="line"><span class="comment"># PaperlessBilling    0</span></span><br><span class="line"><span class="comment"># PaymentMethod       0</span></span><br><span class="line"><span class="comment"># MonthlyCharges      0</span></span><br><span class="line"><span class="comment"># TotalCharges        0</span></span><br><span class="line"><span class="comment"># Churn               0</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br><span class="line"><span class="comment">#    gender  SeniorCitizen  Partner  Dependents  ...  PaymentMethod  MonthlyCharges  TotalCharges  Churn</span></span><br><span class="line"><span class="comment"># 0       0              0        1           0  ...              2           29.85          2505      0</span></span><br><span class="line"><span class="comment"># 1       1              0        0           0  ...              3           56.95          1466      0</span></span><br><span class="line"><span class="comment"># 2       1              0        0           0  ...              3           53.85           157      1</span></span><br><span class="line"><span class="comment"># 3       1              0        0           0  ...              0           42.30          1400      0</span></span><br><span class="line"><span class="comment"># 4       0              0        0           0  ...              2           70.70           925      1</span></span><br></pre></td></tr></table></figure>

<h5 id="決策樹數據分析"><a href="#決策樹數據分析" class="headerlink" title="決策樹數據分析"></a>決策樹數據分析</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove field ID</span></span><br><span class="line"><span class="comment"># df = df.drop([&#x27;customerID&#x27;], axis=1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 標籤轉成數值</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> df[column].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        le = LabelEncoder()</span><br><span class="line">        df[column] = le.fit_transform(df[column])</span><br><span class="line">        <span class="comment"># if column != &#x27;TotalCharges&#x27;:</span></span><br><span class="line">        <span class="comment">#     # 列出原符號和對應的數值</span></span><br><span class="line">        <span class="comment">#     label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))</span></span><br><span class="line">        <span class="comment">#     print(f&quot;&#123;column&#125; &#123;label_mapping&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">X = df.drop(<span class="string">&#x27;Churn&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&#x27;Churn&#x27;</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line"><span class="comment"># dtc = DecisionTreeClassifier()</span></span><br><span class="line"><span class="comment"># max_depth=5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;max_depth=5&quot;</span>)</span><br><span class="line">dtc = DecisionTreeClassifier(max_depth=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;dtc.score(X_test, y_test)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分類報告(Classification Report)\n<span class="subst">&#123;report&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率 : 0.73</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[1267  277]</span></span><br><span class="line"><span class="comment">#  [ 287  282]]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.82      0.82      0.82      1544 --&gt; 預測顧客未流失精確度 0.82</span></span><br><span class="line"><span class="comment">#            1       0.50      0.50      0.50       569 --&gt; 預測顧客流失精確度   0.5</span></span><br><span class="line"><span class="comment">#     accuracy                           0.73      2113</span></span><br><span class="line"><span class="comment">#    macro avg       0.66      0.66      0.66      2113</span></span><br><span class="line"><span class="comment"># weighted avg       0.73      0.73      0.73      2113</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth=5</span></span><br><span class="line"><span class="comment"># 準確率 : 0.8048261178140526</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[953 108]</span></span><br><span class="line"><span class="comment">#  [167 181]]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.85      0.90      0.87      1061</span></span><br><span class="line"><span class="comment">#            1       0.63      0.52      0.57       348</span></span><br><span class="line"><span class="comment">#     accuracy                           0.80      1409</span></span><br><span class="line"><span class="comment">#    macro avg       0.74      0.71      0.72      1409</span></span><br><span class="line"><span class="comment"># weighted avg       0.80      0.80      0.80      1409</span></span><br></pre></td></tr></table></figure>

<h5 id="了解特徵對模型的重要性"><a href="#了解特徵對模型的重要性" class="headerlink" title="了解特徵對模型的重要性"></a>了解特徵對模型的重要性</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove field ID</span></span><br><span class="line"><span class="comment"># df = df.drop([&#x27;customerID&#x27;], axis=1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 標籤轉成數值</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> df[column].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        le = LabelEncoder()</span><br><span class="line">        df[column] = le.fit_transform(df[column])</span><br><span class="line">        <span class="comment"># if column != &#x27;TotalCharges&#x27;:</span></span><br><span class="line">        <span class="comment">#     # 列出原符號和對應的數值</span></span><br><span class="line">        <span class="comment">#     label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))</span></span><br><span class="line">        <span class="comment">#     print(f&quot;&#123;column&#125; &#123;label_mapping&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">X = df.drop(<span class="string">&#x27;Churn&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&#x27;Churn&#x27;</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line"><span class="comment"># max_depth=5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;max_depth=5&quot;</span>)</span><br><span class="line">dtc = DecisionTreeClassifier(max_depth=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出特徵重要性</span></span><br><span class="line">importances = dtc.feature_importances_</span><br><span class="line"><span class="keyword">for</span> feat, importance <span class="keyword">in</span> <span class="built_in">zip</span>(X.columns, importances):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;特徵 : <span class="subst">&#123;feat:20s&#125;</span> 重要性 : <span class="subst">&#123;importance&#125;</span>&quot;</span> )</span><br><span class="line"></span><br><span class="line">feature_imp = pd.Series(dtc.feature_importances_,</span><br><span class="line">                index=X.columns).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">feature_imp.plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">max_depth=<span class="number">5</span></span><br><span class="line"><span class="comment"># 特徵 : customerID           重要性 : 0.00910320798378901</span></span><br><span class="line"><span class="comment"># 特徵 : gender               重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : SeniorCitizen        重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : Partner              重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : Dependents           重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : tenure               重要性 : 0.1548386776499358</span></span><br><span class="line"><span class="comment"># 特徵 : PhoneService         重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : MultipleLines        重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : InternetService      重要性 : 0.08820670934335376</span></span><br><span class="line"><span class="comment"># 特徵 : OnlineSecurity       重要性 : 0.15018233747881019</span></span><br><span class="line"><span class="comment"># 特徵 : OnlineBackup         重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : DeviceProtection     重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : TechSupport          重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : StreamingTV          重要性 : 0.00531089171150569</span></span><br><span class="line"><span class="comment"># 特徵 : StreamingMovies      重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : Contract             重要性 : 0.5228059535911008</span></span><br><span class="line"><span class="comment"># 特徵 : PaperlessBilling     重要性 : 0.006369190962804586</span></span><br><span class="line"><span class="comment"># 特徵 : PaymentMethod        重要性 : 0.0</span></span><br><span class="line"><span class="comment"># 特徵 : MonthlyCharges       重要性 : 0.05825142168000398</span></span><br><span class="line"><span class="comment"># 特徵 : TotalCharges         重要性 : 0.004931609598696093</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic26.png" class="" title="pic26">
</div>

<h5 id="使用最重要5個特徵做決策樹數據分析"><a href="#使用最重要5個特徵做決策樹數據分析" class="headerlink" title="使用最重要5個特徵做決策樹數據分析"></a>使用最重要5個特徵做決策樹數據分析</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">selected_features = [<span class="string">&#x27;Contract&#x27;</span>,<span class="string">&#x27;tenure&#x27;</span>,<span class="string">&#x27;OnlineSecurity&#x27;</span>,</span><br><span class="line">                     <span class="string">&#x27;InternetService&#x27;</span>,<span class="string">&#x27;MonthlyCharges&#x27;</span>]</span><br><span class="line">target = <span class="string">&#x27;Churn&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 標籤轉成數值</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> selected_features:</span><br><span class="line">    <span class="keyword">if</span> df[column].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        le = LabelEncoder()</span><br><span class="line">        df[column] = le.fit_transform(df[column])</span><br><span class="line"><span class="comment"># 目標變數轉成數值</span></span><br><span class="line">labsel_encoder_target = LabelEncoder()</span><br><span class="line">df[target] = labsel_encoder_target.fit_transform(df[target])</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(df[selected_features], df[target], test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line"><span class="comment"># dtc = DecisionTreeClassifier()</span></span><br><span class="line"><span class="comment"># max_depth=5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;max_depth=5&quot;</span>)</span><br><span class="line">dtc = DecisionTreeClassifier(max_depth=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;dtc.score(X_test, y_test)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分類報告(Classification Report)\n<span class="subst">&#123;report&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth=5</span></span><br><span class="line"><span class="comment"># 準確率 : 0.8090844570617459</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[962  99]</span></span><br><span class="line"><span class="comment">#  [170 178]]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.85      0.91      0.88      1061</span></span><br><span class="line"><span class="comment">#            1       0.64      0.51      0.57       348</span></span><br><span class="line"><span class="comment">#     accuracy                           0.81      1409</span></span><br><span class="line"><span class="comment">#    macro avg       0.75      0.71      0.72      1409</span></span><br><span class="line"><span class="comment"># weighted avg       0.80      0.81      0.80      1409</span></span><br></pre></td></tr></table></figure>

<h5 id="交叉驗證-決策樹最佳深度調整"><a href="#交叉驗證-決策樹最佳深度調整" class="headerlink" title="交叉驗證 - 決策樹最佳深度調整"></a>交叉驗證 - 決策樹最佳深度調整</h5><p>GridSearchCV() 可用於有系統地遍歷多種參數組合</p>
<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic27.png" class="" title="pic27">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score</span><br><span class="line"><span class="comment"># from sklearn.metrics import confusion_matrix</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">selected_features = [<span class="string">&#x27;Contract&#x27;</span>,<span class="string">&#x27;tenure&#x27;</span>,<span class="string">&#x27;OnlineSecurity&#x27;</span>,</span><br><span class="line">                     <span class="string">&#x27;InternetService&#x27;</span>,<span class="string">&#x27;MonthlyCharges&#x27;</span>]</span><br><span class="line">target = <span class="string">&#x27;Churn&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 標籤轉成數值</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> selected_features:</span><br><span class="line">    <span class="keyword">if</span> df[column].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        le = LabelEncoder()</span><br><span class="line">        df[column] = le.fit_transform(df[column])</span><br><span class="line"><span class="comment"># 目標變數轉成數值</span></span><br><span class="line">labsel_encoder_target = LabelEncoder()</span><br><span class="line">df[target] = labsel_encoder_target.fit_transform(df[target])</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(df[selected_features], df[target], test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定調整參數</span></span><br><span class="line">params = &#123;<span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>]&#125;</span><br><span class="line"><span class="comment"># 建立決策樹模型</span></span><br><span class="line">clf = GridSearchCV(DecisionTreeClassifier(), params, cv=<span class="number">5</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 顯示最佳參數</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best parameters:<span class="subst">&#123;clf.best_params_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;accuracy_score(y_test, y_pred)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Best parameters:&#123;&#x27;max_depth&#x27;: 5&#125;</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 準確率 : 0.8090844570617459</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.85      0.91      0.88      1061</span></span><br><span class="line"><span class="comment">#            1       0.64      0.51      0.57       348</span></span><br><span class="line"><span class="comment">#     accuracy                           0.81      1409</span></span><br><span class="line"><span class="comment">#    macro avg       0.75      0.71      0.72      1409</span></span><br><span class="line"><span class="comment"># weighted avg       0.80      0.81      0.80      1409</span></span><br></pre></td></tr></table></figure>

<h4 id="Retail-Data-Analytics-迴歸應用"><a href="#Retail-Data-Analytics-迴歸應用" class="headerlink" title="Retail Data Analytics - 迴歸應用"></a>Retail Data Analytics - 迴歸應用</h4><p>決策樹迴歸,可處理連續值(對比線性迴歸模型,更容易受到極端值的影響,並且可能在訓練數據不足下產生過度擬合)</p>
<h5 id="用簡單數據預估房價"><a href="#用簡單數據預估房價" class="headerlink" title="用簡單數據預估房價"></a>用簡單數據預估房價</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> graphviz <span class="keyword">import</span> Source</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假設X代表房子面積,y代表房價</span></span><br><span class="line">X = np.array([<span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">100</span>, <span class="number">110</span>, <span class="number">120</span>, <span class="number">130</span>, <span class="number">140</span>, <span class="number">150</span>])</span><br><span class="line">y = np.array([<span class="number">150000</span>, <span class="number">180000</span>, <span class="number">200000</span>, <span class="number">230000</span>, <span class="number">260000</span>, <span class="number">280000</span>,</span><br><span class="line">              <span class="number">300000</span>, <span class="number">330000</span>, <span class="number">360000</span>, <span class="number">380000</span>, <span class="number">400000</span> ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># X 改為二維</span></span><br><span class="line">X = X.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹回歸模型</span></span><br><span class="line">tree_reg = DecisionTreeRegressor(max_depth=<span class="number">3</span>, random_state=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 擬合模型</span></span><br><span class="line">tree_reg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = tree_reg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># R平方係數</span></span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出預測結果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R平方係數:<span class="subst">&#123;r2&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;實際房價: <span class="subst">&#123;y_test&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;預測房價: <span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grpah = Source(tree.export_graphviz(tree_reg, out_file=<span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line">grpah.<span class="built_in">format</span> = <span class="string">&#x27;png&#x27;</span></span><br><span class="line">grpah.render(filename=<span class="string">&#x27;tree_reg&#x27;</span>, view=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># R平方係數:0.8671875</span></span><br><span class="line"><span class="comment"># 實際房價: [280000 360000 200000]</span></span><br><span class="line"><span class="comment"># 預測房價: [260000. 330000. 180000.]</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic28.png" class="" title="pic28">
</div>

<h5 id="Retail-Data-Analytics"><a href="#Retail-Data-Analytics" class="headerlink" title="Retail Data Analytics"></a>Retail Data Analytics</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic29.png" class="" title="pic29">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic30.png" class="" title="pic30">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示所有 columns</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 設定顯示每 row 長度</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">300</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">sales_df = pd.read_csv(<span class="string">&#x27;sales.csv&#x27;</span>)</span><br><span class="line">features_df = pd.read_csv(<span class="string">&#x27;features.csv&#x27;</span>)</span><br><span class="line">stores_pd = pd.read_csv(<span class="string">&#x27;stores.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合併 features_df, sales_df, link key = &#x27;Store&#x27; + &#x27;Date&#x27;</span></span><br><span class="line">merged_df = pd.merge(sales_df, features_df, on=[<span class="string">&#x27;Store&#x27;</span>, <span class="string">&#x27;Date&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"><span class="comment"># 合併 stores_pd, link key = &#x27;Store&#x27;</span></span><br><span class="line">final_df = pd.merge(merged_df, stores_pd, on=[<span class="string">&#x27;Store&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Date 轉為日期型數據</span></span><br><span class="line">final_df[<span class="string">&#x27;Date&#x27;</span>] = pd.to_datetime(final_df[<span class="string">&#x27;Date&#x27;</span>], <span class="built_in">format</span>=<span class="string">&#x27;%d/%m/%Y&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提出年份及月份</span></span><br><span class="line">final_df[<span class="string">&#x27;Year&#x27;</span>] = final_df[<span class="string">&#x27;Date&#x27;</span>].dt.year</span><br><span class="line">final_df[<span class="string">&#x27;Month&#x27;</span>] = final_df[<span class="string">&#x27;Date&#x27;</span>].dt.month</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 Type 轉成類型數據</span></span><br><span class="line"><span class="comment"># 將 Type 列的資料類型轉換為 category 類型</span></span><br><span class="line"><span class="comment"># .cat.codes：將類別型資料轉換為對應的數字編碼。每個類別將被分配一個整數編碼（從0開始）</span></span><br><span class="line">final_df[<span class="string">&#x27;Type&#x27;</span>] = final_df[<span class="string">&#x27;Type&#x27;</span>].astype(<span class="string">&#x27;category&#x27;</span>).cat.codes</span><br><span class="line"></span><br><span class="line"><span class="comment"># print 區失值統計</span></span><br><span class="line"><span class="comment"># print(final_df.head())</span></span><br><span class="line"><span class="comment"># print(final_df.isnull().sum())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 處理區失值</span></span><br><span class="line">final_df.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 刪除 IsHoliday_y, 將 IsHoliday_x 改為 IsHoliday</span></span><br><span class="line">final_df = final_df.drop(<span class="string">&#x27;IsHoliday_y&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">final_df = final_df.rename(columns=&#123;<span class="string">&#x27;IsHoliday_x&#x27;</span>: <span class="string">&#x27;IsHoliday&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將結果存為 RetailDataAnalytics.csv</span></span><br><span class="line">final_df.to_csv(<span class="string">&#x27;RetailDataAnalytics.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定義特徵變量和目標變量</span></span><br><span class="line">X = final_df.drop([<span class="string">&#x27;Weekly_Sales&#x27;</span>, <span class="string">&#x27;Date&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = final_df[<span class="string">&#x27;Weekly_Sales&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 劃分訓練集和測試集</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹回歸模型</span></span><br><span class="line">model = DecisionTreeRegressor(random_state=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 擬合模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;y_test=<span class="subst">&#123;y_test.to_numpy()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;y_pred=<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># R平方係數</span></span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R平方係數:<span class="subst">&#123;r2:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y_test=[21376.88  2020.91  4372.62 ... 16527.55 37469.44   107.32]</span></span><br><span class="line"><span class="comment"># y_pred=[1.680736e+04 1.787640e+03 4.751260e+03 ... 1.441381e+04 3.348333e+04</span></span><br><span class="line"><span class="comment">#  2.557000e+01]</span></span><br><span class="line"><span class="comment"># R平方係數:0.945</span></span><br></pre></td></tr></table></figure>

<h3 id="隨機森林樹-波士頓房價-鐵達尼號-Telco-收入分析"><a href="#隨機森林樹-波士頓房價-鐵達尼號-Telco-收入分析" class="headerlink" title="隨機森林樹-波士頓房價,鐵達尼號,Telco,收入分析"></a>隨機森林樹-波士頓房價,鐵達尼號,Telco,收入分析</h3><p>決策樹簡單易懂,但資料若有變動常有不準的形況,隨機森林樹(Random Forest)是將一堆決策樹組織起來這樣可以獲得比較好的結果</p>
<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic31.png" class="" title="pic31">
</div>

<h4 id="波士頓房價-迴歸應用"><a href="#波士頓房價-迴歸應用" class="headerlink" title="波士頓房價 - 迴歸應用"></a>波士頓房價 - 迴歸應用</h4><h5 id="簡單數據執行森林樹的應用"><a href="#簡單數據執行森林樹的應用" class="headerlink" title="簡單數據執行森林樹的應用"></a>簡單數據執行森林樹的應用</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 簡單數據執行隨機森林(迴歸應用)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立一個小型數據集</span></span><br><span class="line">X = np.array([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>], [<span class="number">4</span>], [<span class="number">5</span>], [<span class="number">6</span>], [<span class="number">7</span>], [<span class="number">8</span>], [<span class="number">9</span>], [<span class="number">10</span>]])</span><br><span class="line">y = np.array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">18</span>, <span class="number">20</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立森林隨機模型</span></span><br><span class="line"><span class="comment"># n_estimators 設計隨機森林有機棵樹,更多的樹可能會有更好的性能</span></span><br><span class="line"><span class="comment">#              但也同時增加訓練時間及模型的大小(default 100)</span></span><br><span class="line">estimators = <span class="number">100</span></span><br><span class="line">rt = RandomForestRegressor(n_estimators=estimators, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練模型</span></span><br><span class="line">rt.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#進行預測</span></span><br><span class="line">X_new = np.array([[<span class="number">5.5</span>], [<span class="number">6.5</span>], [<span class="number">7.5</span>]])</span><br><span class="line">predictions = rt.predict(X_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;estimators = <span class="subst">&#123;estimators&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;預測結果:<span class="subst">&#123;predictions&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># estimators = 100</span></span><br><span class="line"><span class="comment"># 預測結果:[10.46 12.56 14.4 ]</span></span><br><span class="line"><span class="comment"># estimators = 1000</span></span><br><span class="line"><span class="comment"># 預測結果:[10.414 12.45  14.404]</span></span><br></pre></td></tr></table></figure>

<h5 id="波士頓房價森林樹的應用"><a href="#波士頓房價森林樹的應用" class="headerlink" title="波士頓房價森林樹的應用"></a>波士頓房價森林樹的應用</h5><p>得到比線性迴歸更好的R平方判定係數</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># boston data url : http://lib.stat.cmu.edu/datasets/boston</span></span><br><span class="line">boston = pd.read_csv(<span class="string">&quot;boston.csv&quot;</span>, sep=<span class="string">&#x27;\s+&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X = boston.drop(<span class="string">&#x27;MEDV&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = boston[<span class="string">&#x27;MEDV&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割測試數據與測試數據</span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立森林隨機模型</span></span><br><span class="line"><span class="comment"># n_estimators 設計隨機森林有機棵樹,更多的樹可能會有更好的性能</span></span><br><span class="line"><span class="comment">#              但也同時增加訓練時間及模型的大小(default 100)</span></span><br><span class="line">rt = RandomForestRegressor(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練模型</span></span><br><span class="line">rt.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#進行預測</span></span><br><span class="line">y_pred = rt.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算評估指標</span></span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R-squared : <span class="subst">&#123;r2:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error : <span class="subst">&#123;mse:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># R-squared : 0.914</span></span><br><span class="line"><span class="comment"># Mean Squared Error : 8.523</span></span><br></pre></td></tr></table></figure>

<h4 id="鐵達尼號-分類應用-1"><a href="#鐵達尼號-分類應用-1" class="headerlink" title="鐵達尼號 - 分類應用"></a>鐵達尼號 - 分類應用</h4><p>得到和決策樹相同的準確率</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 數據</span></span><br><span class="line">titanic_data = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"><span class="comment"># 選取有用特徵</span></span><br><span class="line">titanic_data = titanic_data[[<span class="string">&#x27;survived&#x27;</span>,<span class="string">&#x27;pclass&#x27;</span>,<span class="string">&#x27;sex&#x27;</span>,<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;sibsp&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;parch&#x27;</span>,<span class="string">&#x27;fare&#x27;</span>,<span class="string">&#x27;embarked&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(titanic_data)</span></span><br><span class="line"><span class="comment"># print(titanic_data[&#x27;age&#x27;])</span></span><br><span class="line"><span class="comment"># 年齡補上中位數年齡</span></span><br><span class="line">titanic_data[<span class="string">&#x27;age&#x27;</span>] = titanic_data[<span class="string">&#x27;age&#x27;</span>].fillna(titanic_data[<span class="string">&#x27;age&#x27;</span>].median())</span><br><span class="line"><span class="comment"># 登船港口用眾位數取代缺失值</span></span><br><span class="line"><span class="comment"># mode() 傳回的是一個包含眾數的 Series，因此需要取 [0] 來獲取第一個眾數</span></span><br><span class="line">titanic_data[<span class="string">&#x27;embarked&#x27;</span>] = titanic_data[<span class="string">&#x27;embarked&#x27;</span>].fillna(titanic_data[<span class="string">&#x27;embarked&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 對性別,登船港口 執行 on-hot 編碼</span></span><br><span class="line"><span class="comment"># get_dummies 是 Pandas 中的一個函數，用於將分類變數轉換為一個或多個虛擬變數（dummy variables）。</span></span><br><span class="line"><span class="comment"># 這些虛擬變數可以用於機器學習模型，因為大多數模型不能直接處理非數值型資料。</span></span><br><span class="line">titanic_data = pd.get_dummies(titanic_data, columns=[<span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;embarked&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割數據為訓練集及測試集</span></span><br><span class="line">X = titanic_data.drop(<span class="string">&#x27;survived&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = titanic_data[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">rf_classifier = RandomForestClassifier(random_state=<span class="number">5</span>)</span><br><span class="line">rf_classifier.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = rf_classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(titanic_data.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 建立決策樹模型並進行訓練</span></span><br><span class="line"><span class="comment"># dtc = DecisionTreeClassifier(random_state=5)</span></span><br><span class="line"><span class="comment"># dtc.fit(X_train, y_train)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 進行預測</span></span><br><span class="line"><span class="comment"># y_pred = dtc.predict(X_test)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測結果比較</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的真實分類\n<span class="subst">&#123;y_test.to_numpy()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;測試的目標分類\n<span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;accuracy_score(y_test, y_pred):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 計算混淆矩陣並輸出</span></span><br><span class="line"><span class="comment"># 測試準確對照表</span></span><br><span class="line">conf_mat = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;混淆矩陣(Confusion Matix):\n<span class="subst">&#123;conf_mat&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分類報告(Classification Report)\n<span class="subst">&#123;report&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 測試的真實分類</span></span><br><span class="line"><span class="comment"># [0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0</span></span><br><span class="line"><span class="comment">#  1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0</span></span><br><span class="line"><span class="comment">#  0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1</span></span><br><span class="line"><span class="comment">#  0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 測試的目標分類</span></span><br><span class="line"><span class="comment"># [0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0</span></span><br><span class="line"><span class="comment">#  0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0</span></span><br><span class="line"><span class="comment">#  1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0</span></span><br><span class="line"><span class="comment">#  0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1</span></span><br><span class="line"><span class="comment">#  0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># 準確率 : 0.82</span></span><br><span class="line"><span class="comment"># 混淆矩陣(Confusion Matix):</span></span><br><span class="line"><span class="comment"># [[97 14]</span></span><br><span class="line"><span class="comment">#  [18 50]]</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.84      0.87      0.86       111</span></span><br><span class="line"><span class="comment">#            1       0.78      0.74      0.76        68</span></span><br><span class="line"><span class="comment">#     accuracy                           0.82       179</span></span><br><span class="line"><span class="comment">#    macro avg       0.81      0.80      0.81       179</span></span><br><span class="line"><span class="comment"># weighted avg       0.82      0.82      0.82       179</span></span><br></pre></td></tr></table></figure>

<h4 id="Telco-客戶流失-分類應用"><a href="#Telco-客戶流失-分類應用" class="headerlink" title="Telco 客戶流失 - 分類應用"></a>Telco 客戶流失 - 分類應用</h4><p>準確率差一點點</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="comment"># from sklearn.tree import DecisionTreeClassifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 選擇特及目標變數</span></span><br><span class="line">selected_features = [<span class="string">&#x27;Contract&#x27;</span>,<span class="string">&#x27;tenure&#x27;</span>,<span class="string">&#x27;OnlineSecurity&#x27;</span>,</span><br><span class="line">                     <span class="string">&#x27;InternetService&#x27;</span>,<span class="string">&#x27;MonthlyCharges&#x27;</span>]</span><br><span class="line">target = <span class="string">&#x27;Churn&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 標籤轉成數值</span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> selected_features:</span><br><span class="line">    <span class="keyword">if</span> df[column].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line">        le = LabelEncoder()</span><br><span class="line">        df[column] = le.fit_transform(df[column])</span><br><span class="line"><span class="comment"># 目標變數轉成數值</span></span><br><span class="line">labsel_encoder_target = LabelEncoder()</span><br><span class="line">df[target] = labsel_encoder_target.fit_transform(df[target])</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(df[selected_features], df[target], test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line"><span class="comment"># n_estimators 設計隨機森林有機棵樹,更多的樹可能會有更好的性能</span></span><br><span class="line"><span class="comment">#              但也同時增加訓練時間及模型的大小(default 100)</span></span><br><span class="line"><span class="comment"># max_depth=5</span></span><br><span class="line">dtc = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">5</span>, random_state=<span class="number">1</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;dtc.score(X_test, y_test)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分類報告</span></span><br><span class="line"><span class="comment"># 測試報告</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分類報告(Classification Report)\n<span class="subst">&#123;report&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率 : 0.8062455642299503</span></span><br><span class="line"><span class="comment"># 分類報告(Classification Report)</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"><span class="comment">#            0       0.85      0.91      0.88      1061</span></span><br><span class="line"><span class="comment">#            1       0.64      0.49      0.56       348</span></span><br><span class="line"><span class="comment">#     accuracy                           0.81      1409</span></span><br><span class="line"><span class="comment">#    macro avg       0.74      0.70      0.72      1409</span></span><br><span class="line"><span class="comment"># weighted avg       0.79      0.81      0.80      1409</span></span><br></pre></td></tr></table></figure>

<h4 id="美國成年人收入分析-kaggle-分類應用"><a href="#美國成年人收入分析-kaggle-分類應用" class="headerlink" title="美國成年人收入分析(kaggle) - 分類應用"></a>美國成年人收入分析(kaggle) - 分類應用</h4><h5 id="adult-csv-數據"><a href="#adult-csv-數據" class="headerlink" title="adult.csv 數據"></a>adult.csv 數據</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic32.png" class="" title="pic32">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic33.png" class="" title="pic33">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取 csv</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示所有 columns</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 設定顯示每 row 長度</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">300</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 ? 轉成 np.nan</span></span><br><span class="line">data = data.replace(<span class="string">&#x27;?&#x27;</span>, np.nan)</span><br><span class="line"><span class="comment"># show 檢查資料缺失</span></span><br><span class="line"><span class="comment"># size 48842,max nan 2809</span></span><br><span class="line"><span class="comment"># print(data.info())</span></span><br><span class="line"><span class="comment"># print(data.isnull().sum())</span></span><br><span class="line"><span class="comment"># 刪除包含缺失</span></span><br><span class="line">data = data.dropna()</span><br><span class="line"><span class="comment"># show 檢查資料缺失</span></span><br><span class="line"><span class="comment"># size 45222</span></span><br><span class="line"><span class="comment"># print(data.info())</span></span><br><span class="line"><span class="comment"># print(data.isnull().sum())</span></span><br><span class="line"><span class="comment"># 列出前五筆</span></span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">180</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將類別轉成數字</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">categorical_features = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data.dtypes[i]==<span class="string">&#x27;object&#x27;</span> ]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_features:</span><br><span class="line">    data[col] = le.fit_transform(data[col])</span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment">#    age  workclass  fnlwgt     education  educational-num      marital-status         occupation   relationship   race gender  capital-gain  capital-loss  hours-per-week native-country income</span></span><br><span class="line"><span class="comment"># 0   25    Private  226802          11th                7       Never-married  Machine-op-inspct      Own-child  Black   Male             0             0              40  United-States  &lt;=50K</span></span><br><span class="line"><span class="comment"># 1   38    Private   89814       HS-grad                9  Married-civ-spouse    Farming-fishing        Husband  White   Male             0             0              50  United-States  &lt;=50K</span></span><br><span class="line"><span class="comment"># 2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse    Protective-serv        Husband  White   Male             0             0              40  United-States   &gt;50K</span></span><br><span class="line"><span class="comment"># 3   44    Private  160323  Some-college               10  Married-civ-spouse  Machine-op-inspct        Husband  Black   Male          7688             0              40  United-States   &gt;50K</span></span><br><span class="line"><span class="comment"># 5   34    Private  198693          10th                6       Never-married      Other-service  Not-in-family  White   Male             0             0              30  United-States  &lt;=50K</span></span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">#    age  workclass  fnlwgt  education  educational-num  marital-status  occupation  relationship  race  gender  capital-gain  capital-loss  hours-per-week  native-country  income</span></span><br><span class="line"><span class="comment"># 0   25          2  226802          1                7               4           6             3     2       1             0             0              40              38       0</span></span><br><span class="line"><span class="comment"># 1   38          2   89814         11                9               2           4             0     4       1             0             0              50              38       0</span></span><br><span class="line"><span class="comment"># 2   28          1  336951          7               12               2          10             0     4       1             0             0              40              38       1</span></span><br><span class="line"><span class="comment"># 3   44          2  160323         15               10               2           6             0     2       1          7688             0              40              38       1</span></span><br><span class="line"><span class="comment"># 5   34          2  198693          0                6               4           7             1     4       1             0             0              30              38       0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="使用決策樹處理年收入預估"><a href="#使用決策樹處理年收入預估" class="headerlink" title="使用決策樹處理年收入預估"></a>使用決策樹處理年收入預估</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取 csv</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 ? 轉成 np.nan</span></span><br><span class="line">data = data.replace(<span class="string">&#x27;?&#x27;</span>, np.nan)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將類別轉成數字</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">categorical_features = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data.dtypes[i]==<span class="string">&#x27;object&#x27;</span> ]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_features:</span><br><span class="line">    data[col] = le.fit_transform(data[col])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵值及目標值</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;income&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;income&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dtc = DecisionTreeClassifier(random_state=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;accuracy_score(y_test, y_pred):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率 : 0.809</span></span><br></pre></td></tr></table></figure>

<h5 id="特徵之重要性"><a href="#特徵之重要性" class="headerlink" title="特徵之重要性"></a>特徵之重要性</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特徵之重要性</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取 csv</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 ? 轉成 np.nan</span></span><br><span class="line">data = data.replace(<span class="string">&#x27;?&#x27;</span>, np.nan)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將類別轉成數字</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">categorical_features = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data.dtypes[i]==<span class="string">&#x27;object&#x27;</span> ]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_features:</span><br><span class="line">    data[col] = le.fit_transform(data[col])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵值及目標值</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;income&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;income&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dtc = DecisionTreeClassifier(random_state=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出特徵重要性</span></span><br><span class="line">importances = dtc.feature_importances_</span><br><span class="line"><span class="keyword">for</span> feat, importance <span class="keyword">in</span> <span class="built_in">zip</span>(X.columns, importances):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;特徵 : <span class="subst">&#123;feat:20s&#125;</span> 重要性 : <span class="subst">&#123;importance&#125;</span>&quot;</span> )</span><br><span class="line"></span><br><span class="line">feature_imp = pd.Series(dtc.feature_importances_,</span><br><span class="line">                index=X.columns).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">feature_imp.plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵 : age                  重要性 : 0.11978703368273183</span></span><br><span class="line"><span class="comment"># 特徵 : workclass            重要性 : 0.032764901917090215</span></span><br><span class="line"><span class="comment"># 特徵 : fnlwgt               重要性 : 0.2056924305712409</span></span><br><span class="line"><span class="comment"># 特徵 : education            重要性 : 0.0129702048255056</span></span><br><span class="line"><span class="comment"># 特徵 : educational-num      重要性 : 0.11355184888333343</span></span><br><span class="line"><span class="comment"># 特徵 : marital-status       重要性 : 0.006535999243215993</span></span><br><span class="line"><span class="comment"># 特徵 : occupation           重要性 : 0.0539721412011748</span></span><br><span class="line"><span class="comment"># 特徵 : relationship         重要性 : 0.1987225583756099</span></span><br><span class="line"><span class="comment"># 特徵 : race                 重要性 : 0.013271473606213178</span></span><br><span class="line"><span class="comment"># 特徵 : gender               重要性 : 0.0021772976656923393</span></span><br><span class="line"><span class="comment"># 特徵 : capital-gain         重要性 : 0.11284501812585948</span></span><br><span class="line"><span class="comment"># 特徵 : capital-loss         重要性 : 0.04032376245073732</span></span><br><span class="line"><span class="comment"># 特徵 : hours-per-week       重要性 : 0.07132449271050804</span></span><br><span class="line"><span class="comment"># 特徵 : native-country       重要性 : 0.0160608367410867</span></span><br><span class="line"><span class="comment"># 特徵 : native-country       重要性 : 0.018187854563646542</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic34.png" class="" title="pic34">
</div>

<h5 id="使用7個最重要特徵做決策樹處理年收入預估-並沒有比較好"><a href="#使用7個最重要特徵做決策樹處理年收入預估-並沒有比較好" class="headerlink" title="使用7個最重要特徵做決策樹處理年收入預估 - 並沒有比較好"></a>使用7個最重要特徵做決策樹處理年收入預估 - 並沒有比較好</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取 csv</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 ? 轉成 np.nan</span></span><br><span class="line">data = data.replace(<span class="string">&#x27;?&#x27;</span>, np.nan)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將類別轉成數字</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">categorical_features = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data.dtypes[i]==<span class="string">&#x27;object&#x27;</span> ]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_features:</span><br><span class="line">    data[col] = le.fit_transform(data[col])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵值及目標值</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;income&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;income&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用所有特徵訓練決策樹並計算特徵重要性</span></span><br><span class="line">dtc = DecisionTreeClassifier(random_state=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X, y)</span><br><span class="line">importances = dtc.feature_importances_</span><br><span class="line">features = X.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 獲得最重要7個特徵</span></span><br><span class="line"><span class="comment"># p.argsort 取出由小到大 array&#x27;s index</span></span><br><span class="line">indices = np.argsort(importances)[-<span class="number">7</span>:]</span><br><span class="line"><span class="comment"># top 7 features&#x27; name</span></span><br><span class="line">top_features = [features[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices]</span><br><span class="line"></span><br><span class="line">X = data[top_features]</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立決策樹模型並進行訓練</span></span><br><span class="line">dtc = DecisionTreeClassifier(random_state=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;accuracy_score(y_test, y_pred):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率 : 0.803</span></span><br></pre></td></tr></table></figure>

<h5 id="使用隨機森林處理收入預估-得到較準確結果"><a href="#使用隨機森林處理收入預估-得到較準確結果" class="headerlink" title="使用隨機森林處理收入預估 - 得到較準確結果"></a>使用隨機森林處理收入預估 - 得到較準確結果</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取 csv</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 ? 轉成 np.nan</span></span><br><span class="line">data = data.replace(<span class="string">&#x27;?&#x27;</span>, np.nan)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將類別轉成數字</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">categorical_features = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data.dtypes[i]==<span class="string">&#x27;object&#x27;</span> ]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_features:</span><br><span class="line">    data[col] = le.fit_transform(data[col])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵值及目標值</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;income&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;income&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line"><span class="comment"># n_estimators 設計隨機森林有機棵樹,更多的樹可能會有更好的性能</span></span><br><span class="line"><span class="comment">#              但也同時增加訓練時間及模型的大小(default 100)</span></span><br><span class="line"><span class="comment"># max_depth=5  深度設定</span></span><br><span class="line">dtc = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">5</span>)</span><br><span class="line">dtc.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 進行預測</span></span><br><span class="line">y_pred = dtc.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;accuracy_score(y_test, y_pred):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率 : 0.854</span></span><br></pre></td></tr></table></figure>

<h3 id="KNN-演算法-鳶尾花-小行星撞地球"><a href="#KNN-演算法-鳶尾花-小行星撞地球" class="headerlink" title="KNN 演算法 - 鳶尾花,小行星撞地球"></a>KNN 演算法 - 鳶尾花,小行星撞地球</h3><h4 id="KNN-K-Nearest-Neighbors-K-最近鄰-演算法基礎觀念"><a href="#KNN-K-Nearest-Neighbors-K-最近鄰-演算法基礎觀念" class="headerlink" title="KNN(K-Nearest Neighbors K-最近鄰) 演算法基礎觀念"></a>KNN(K-Nearest Neighbors K-最近鄰) 演算法基礎觀念</h4><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic35.png" class="" title="pic35">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic36.png" class="" title="pic36">
</div>

<h4 id="電影推薦-足球射門-分類應用"><a href="#電影推薦-足球射門-分類應用" class="headerlink" title="電影推薦,足球射門 - 分類應用"></a>電影推薦,足球射門 - 分類應用</h4><h5 id="簡單例子"><a href="#簡單例子" class="headerlink" title="簡單例子"></a>簡單例子</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 簡單例子</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">X = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line"><span class="comment"># n_neighbors=3 取最近 3 點</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">x = <span class="number">1.1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;x=<span class="subst">&#123;x&#125;</span> 分類是  :<span class="subst">&#123;knn.predict([[x]])&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;x=<span class="subst">&#123;x&#125;</span> 分類機率:<span class="subst">&#123;knn.predict_proba([[x]])&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = <span class="number">1.6</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;x=<span class="subst">&#123;x&#125;</span> 分類是  :<span class="subst">&#123;knn.predict([[x]])&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;x=<span class="subst">&#123;x&#125;</span> 分類機率:<span class="subst">&#123;knn.predict_proba([[x]])&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x=1.1 分類是  :[0]</span></span><br><span class="line"><span class="comment"># x=1.1 分類機率:[[0.66666667 0.33333333]] - 0 的機率 0.66, 1 的機率 0.33</span></span><br><span class="line"><span class="comment"># x=1.6 分類是  :[1]</span></span><br><span class="line"><span class="comment"># x=1.6 分類機率:[[0.33333333 0.66666667]] - 3 的機率 0.33, 1 的機率 0.66</span></span><br></pre></td></tr></table></figure>

<h5 id="電影推薦"><a href="#電影推薦" class="headerlink" title="電影推薦"></a>電影推薦</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 喜好電影預測</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 電影數據(韓兩個特徵)</span></span><br><span class="line">movies = np.array([</span><br><span class="line">    [<span class="number">8</span>, <span class="number">7</span>],     <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">9</span>, <span class="number">8</span>],     <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">10</span>, <span class="number">9</span>],    <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">7</span>, <span class="number">6</span>],     <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>],     <span class="comment"># 喜劇片</span></span><br><span class="line">    [<span class="number">2</span>, <span class="number">1</span>],     <span class="comment"># 喜劇片</span></span><br><span class="line">    [<span class="number">3</span>, <span class="number">4</span>]     <span class="comment"># 喜劇片</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 電影類型(0:動作片,1:喜劇片)</span></span><br><span class="line">lables = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line"><span class="comment"># n_neighbors=3 取最近 3 點</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(movies, lables)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Kwei 喜好電影類型-特徵 [6, 7]</span></span><br><span class="line">kwei_movie = np.array([<span class="number">6</span>, <span class="number">7</span>]).reshape(<span class="number">1</span>,-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測 Kwei 電影類型</span></span><br><span class="line">prediction = knn.predict(kwei_movie)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> prediction == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;推薦 Kwei 動作片&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;推薦 Kwei 喜劇片&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推薦 Kwei 動作片</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 喜好電影預測</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 電影數據(韓兩個特徵)</span></span><br><span class="line">movies = np.array([</span><br><span class="line">    [<span class="number">8</span>, <span class="number">7</span>],     <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">9</span>, <span class="number">8</span>],     <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">10</span>, <span class="number">9</span>],    <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">7</span>, <span class="number">6</span>],     <span class="comment"># 動作片</span></span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>],     <span class="comment"># 喜劇片</span></span><br><span class="line">    [<span class="number">2</span>, <span class="number">1</span>],     <span class="comment"># 喜劇片</span></span><br><span class="line">    [<span class="number">3</span>, <span class="number">4</span>]     <span class="comment"># 喜劇片</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 電影類型(0:動作片,1:喜劇片)</span></span><br><span class="line">lables = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 電影名稱</span></span><br><span class="line">movie_names = np.array([</span><br><span class="line">    <span class="string">&quot;Mission Impossible&quot;</span>,</span><br><span class="line">    <span class="string">&quot;搶救雷恩大兵&quot;</span>,</span><br><span class="line">    <span class="string">&quot;玩命關頭&quot;</span>,</span><br><span class="line">    <span class="string">&quot;雷神索爾&quot;</span>,</span><br><span class="line">    <span class="string">&quot;真善美&quot;</span>,</span><br><span class="line">    <span class="string">&quot;愛情停損點&quot;</span>,</span><br><span class="line">    <span class="string">&quot;雙手的溫柔&quot;</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line"><span class="comment"># n_neighbors=3 取最近 3 點</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(movies, lables)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Kwei 喜好電影類型-特徵 [8, 7]</span></span><br><span class="line">kwei_movie = np.array([<span class="number">8</span>, <span class="number">7</span>]).reshape(<span class="number">1</span>,-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找出與 Kwei 電影喜好,最接近3部電影</span></span><br><span class="line">distences, indices = knn.kneighbors(kwei_movie)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最接近喜好的距離: <span class="subst">&#123;distences&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最接近喜好的索引: <span class="subst">&#123;indices&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多維陣列轉成list</span></span><br><span class="line">index = indices.flatten()</span><br><span class="line"><span class="built_in">print</span>(index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出 Kwel 喜好最接近3部電影</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;列出 Kwel 喜好最接近3部電影&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;movie_names[i]&#125;</span> <span class="subst">&#123;movies[i]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最接近喜好的距離: [[0.         1.41421356 1.41421356]]</span></span><br><span class="line"><span class="comment"># 最接近喜好的索引: [[0 1 3]]</span></span><br><span class="line"><span class="comment"># ======================================================================</span></span><br><span class="line"><span class="comment"># [0 1 3]</span></span><br><span class="line"><span class="comment"># 列出 Kwel 喜好最接近3部電影</span></span><br><span class="line"><span class="comment"># Mission Impossible [8 7]</span></span><br><span class="line"><span class="comment"># 搶救雷恩大兵 [9 8]</span></span><br><span class="line"><span class="comment"># 雷神索爾 [7 6]</span></span><br></pre></td></tr></table></figure>

<h5 id="足球進球分析"><a href="#足球進球分析" class="headerlink" title="足球進球分析"></a>足球進球分析</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 足球進球分析</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># distance 距離, angle 角度, goal 1=進球</span></span><br><span class="line">distance = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>, <span class="number">30</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">20</span>, <span class="number">15</span>]</span><br><span class="line">angle = [<span class="number">30</span>, <span class="number">45</span>, <span class="number">60</span>, <span class="number">30</span>, <span class="number">60</span>, <span class="number">75</span>, <span class="number">45</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">90</span>]</span><br><span class="line">goal = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整理數據</span></span><br><span class="line"><span class="comment"># 1D array 合成 2D array</span></span><br><span class="line">X = np.column_stack((distance, angle))</span><br><span class="line">y = np.array(goal)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line"><span class="comment"># n_neighbors=3 取最近 3 點</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸入球員數據</span></span><br><span class="line">new_distance = <span class="built_in">float</span>(<span class="built_in">input</span>(<span class="string">&quot;輸入射門距離(公尺):&quot;</span>))</span><br><span class="line">new_angle = <span class="built_in">float</span>(<span class="built_in">input</span>(<span class="string">&quot;輸入射門角度:&quot;</span>))</span><br><span class="line">new_player = np.array([[new_distance, new_angle]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測是否能進球</span></span><br><span class="line">prediction = knn.predict(new_player)</span><br><span class="line">prediction_proba = knn.predict_proba(new_player)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出結果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;是否進球(0沒進,1進球):<span class="subst">&#123;prediction&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;不進球機率: <span class="subst">&#123;prediction_proba[<span class="number">0</span>][<span class="number">0</span>]:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;進球  機率: <span class="subst">&#123;prediction_proba[<span class="number">0</span>][<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸入射門距離(公尺):36</span></span><br><span class="line"><span class="comment"># 輸入射門角度:63</span></span><br><span class="line"><span class="comment"># 是否進球(0沒進,1進球):[0]</span></span><br><span class="line"><span class="comment"># 不進球機率: 1.000</span></span><br><span class="line"><span class="comment"># 進球  機率: 0.000</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 輸入射門距離(公尺):35</span></span><br><span class="line"><span class="comment"># 輸入射門角度:48</span></span><br><span class="line"><span class="comment"># 是否進球(0沒進,1進球):[1]</span></span><br><span class="line"><span class="comment"># 不進球機率: 0.333</span></span><br><span class="line"><span class="comment"># 進球  機率: 0.667</span></span><br></pre></td></tr></table></figure>

<h5 id="繪製分類決策邊界-ecision-Boundary"><a href="#繪製分類決策邊界-ecision-Boundary" class="headerlink" title="繪製分類決策邊界(ecision Boundary)"></a>繪製分類決策邊界(ecision Boundary)</h5><h6 id="線性回歸數據集-繪製散點圖"><a href="#線性回歸數據集-繪製散點圖" class="headerlink" title="線性回歸數據集-繪製散點圖"></a>線性回歸數據集-繪製散點圖</h6><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># make_blobs 是 Scikit-learn 庫中用於生成合成數據集的函數</span></span><br><span class="line"><span class="comment"># 這個函數主要用於創建聚類算法的測試數據集</span></span><br><span class="line"><span class="comment"># 主要參數和返回值</span></span><br><span class="line"><span class="comment">#   n_samples: 要生成的樣本數。</span></span><br><span class="line"><span class="comment">#   centers: 簇的中心數量或具體坐標。如果是整數，則隨機生成指定數量的簇中心；如果是數組，則使用提供的坐標作為簇中心。</span></span><br><span class="line"><span class="comment">#   n_features: 每個樣本的特徵數。即每個數據點的維度。</span></span><br><span class="line"><span class="comment">#   cluster_std: 每個簇的標準差。可設置單一值或數組，數組時可為每個簇指定不同的標準差。</span></span><br><span class="line"><span class="comment">#   random_state: 用於確保生成的數據集的一致性，方便重現結果。</span></span><br><span class="line"><span class="comment"># 返回值</span></span><br><span class="line"><span class="comment">#   X: 包含數據點的數組，每行是一個數據點。</span></span><br><span class="line"><span class="comment">#   y: 每個數據點所屬簇的標籤數組。</span></span><br><span class="line"><span class="comment"># 生成數據</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">200</span>, centers=<span class="number">2</span>, random_state=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(f&quot;X=&#123;X&#125;&quot;)</span></span><br><span class="line"><span class="comment"># print(f&quot;y=&#123;y&#125;&quot;)</span></span><br><span class="line"><span class="comment"># 顯示散點圖</span></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolor=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic37.png" class="" title="pic37">
</div>

<h6 id="繪製分類邊界"><a href="#繪製分類邊界" class="headerlink" title="繪製分類邊界"></a>繪製分類邊界</h6><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成數據</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">200</span>, centers=<span class="number">2</span>, random_state=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line"><span class="comment"># n_neighbors=3 取最近 3 點</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors = k)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定繪圖區域</span></span><br><span class="line">x_min, x_max = X[:,<span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = X[:,<span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 產生所有平面座標(這些陣列是二維的)</span></span><br><span class="line"><span class="comment"># xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),</span></span><br><span class="line"><span class="comment">#                      np.arange(y_min, y_max, 0.01))</span></span><br><span class="line"><span class="comment"># more quickly</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;xx = <span class="subst">&#123;xx&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;yy = <span class="subst">&#123;yy&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ravel() 方法將二維陣列壓平成一維陣列</span></span><br><span class="line"><span class="comment"># np.c_ 按列合併多個一維陣列，生成一個新的二維陣</span></span><br><span class="line">Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;np.c_[] = <span class="subst">&#123;np.c_[xx.ravel(), yy.ravel()]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Z = <span class="subst">&#123;Z&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Z 的 shape same as xx</span></span><br><span class="line">Z = Z.reshape(xx.shape)</span><br><span class="line"><span class="built_in">print</span>(xx.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Z(reshape) = <span class="subst">&#123;Z&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 繪製等高線圖（Filled Contour Plot）</span></span><br><span class="line"><span class="comment"># plt.contourf 會填充等高線之間的區域，形成帶有顏色的圖像，這些顏色對應於不同的數值範圍。</span></span><br><span class="line"><span class="comment"># 使用方法</span></span><br><span class="line"><span class="comment"># plt.contourf 的基本用法是將網格點的座標和對應的數值數據傳遞給它，然後它會繪製出填充的等高線。</span></span><br><span class="line"><span class="comment"># 參數</span></span><br><span class="line"><span class="comment"># X, Y:</span></span><br><span class="line"><span class="comment">#   這些是網格的橫坐標和縱坐標數組。通常由 np.meshgrid 生成。</span></span><br><span class="line"><span class="comment"># Z:</span></span><br><span class="line"><span class="comment">#   這是對應於網格點的數值數據，用於確定等高線的位置。Z 的形狀應該與 X 和 Y 的形狀相同。</span></span><br><span class="line"><span class="comment"># levels（可選）:</span></span><br><span class="line"><span class="comment">#   指定等高線的數量或其具體值。若未指定，Matplotlib 會自動選擇適當的等高線數量和間距。</span></span><br><span class="line"><span class="comment"># cmap（可選）:</span></span><br><span class="line"><span class="comment">#   這個參數指定色彩地圖（colormap），決定不同數值範圍對應的顏色。預設情況下會使用 Matplotlib 的預設色彩地圖。</span></span><br><span class="line"><span class="comment"># alpha（可選）:</span></span><br><span class="line"><span class="comment">#   透明度，數值範圍為 0 到 1。alpha=0.3 代表圖形有 30% 的透明度。</span></span><br><span class="line">plt.contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.contour 繪製等高線但不填充</span></span><br><span class="line"><span class="comment"># plt.contour(xx, yy, Z, alpha=0.3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示散點圖</span></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolor=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># xx = [[ 3.33366829  3.43366829  3.53366829 ... 10.73366829 10.83366829</span></span><br><span class="line"><span class="comment">#   10.93366829]</span></span><br><span class="line"><span class="comment">#  [ 3.33366829  3.43366829  3.53366829 ... 10.73366829 10.83366829</span></span><br><span class="line"><span class="comment">#   10.93366829]</span></span><br><span class="line"><span class="comment">#  [ 3.33366829  3.43366829  3.53366829 ... 10.73366829 10.83366829</span></span><br><span class="line"><span class="comment">#   10.93366829]</span></span><br><span class="line"><span class="comment">#  ...</span></span><br><span class="line"><span class="comment">#  [ 3.33366829  3.43366829  3.53366829 ... 10.73366829 10.83366829</span></span><br><span class="line"><span class="comment">#   10.93366829]</span></span><br><span class="line"><span class="comment">#  [ 3.33366829  3.43366829  3.53366829 ... 10.73366829 10.83366829</span></span><br><span class="line"><span class="comment">#   10.93366829]</span></span><br><span class="line"><span class="comment">#  [ 3.33366829  3.43366829  3.53366829 ... 10.73366829 10.83366829</span></span><br><span class="line"><span class="comment">#   10.93366829]]</span></span><br><span class="line"><span class="comment"># yy = [[-2.89105765 -2.89105765 -2.89105765 ... -2.89105765 -2.89105765</span></span><br><span class="line"><span class="comment">#   -2.89105765]</span></span><br><span class="line"><span class="comment">#  [-2.79105765 -2.79105765 -2.79105765 ... -2.79105765 -2.79105765</span></span><br><span class="line"><span class="comment">#   -2.79105765]</span></span><br><span class="line"><span class="comment">#  [-2.69105765 -2.69105765 -2.69105765 ... -2.69105765 -2.69105765</span></span><br><span class="line"><span class="comment">#   -2.69105765]</span></span><br><span class="line"><span class="comment">#  ...</span></span><br><span class="line"><span class="comment">#  [12.80894235 12.80894235 12.80894235 ... 12.80894235 12.80894235</span></span><br><span class="line"><span class="comment">#   12.80894235]</span></span><br><span class="line"><span class="comment">#  [12.90894235 12.90894235 12.90894235 ... 12.90894235 12.90894235</span></span><br><span class="line"><span class="comment">#   12.90894235]</span></span><br><span class="line"><span class="comment">#  [13.00894235 13.00894235 13.00894235 ... 13.00894235 13.00894235</span></span><br><span class="line"><span class="comment">#   13.00894235]]</span></span><br><span class="line"><span class="comment"># np.c_[] = [[ 3.33366829 -2.89105765]</span></span><br><span class="line"><span class="comment">#  [ 3.43366829 -2.89105765]</span></span><br><span class="line"><span class="comment">#  [ 3.53366829 -2.89105765]</span></span><br><span class="line"><span class="comment">#  ...</span></span><br><span class="line"><span class="comment">#  [10.73366829 13.00894235]</span></span><br><span class="line"><span class="comment">#  [10.83366829 13.00894235]</span></span><br><span class="line"><span class="comment">#  [10.93366829 13.00894235]]</span></span><br><span class="line"><span class="comment"># Z = [1 1 1 ... 0 0 0]</span></span><br><span class="line"><span class="comment"># (160, 77)</span></span><br><span class="line"><span class="comment"># Z(reshape) = [[1 1 1 ... 1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1 ... 1 1 1]</span></span><br><span class="line"><span class="comment">#  [1 1 1 ... 1 1 1]</span></span><br><span class="line"><span class="comment">#  ...</span></span><br><span class="line"><span class="comment">#  [0 0 0 ... 0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 0 0 ... 0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 0 0 ... 0 0 0]]</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic38.png" class="" title="pic38">
</div>

<h6 id="繪製分類邊界-調整隨機種子及k值"><a href="#繪製分類邊界-調整隨機種子及k值" class="headerlink" title="繪製分類邊界 - 調整隨機種子及k值"></a>繪製分類邊界 - 調整隨機種子及k值</h6><ul>
<li>k&#x3D;1 會造成決策邊界對於異常值,錯誤標記值非常敏感</li>
<li>k值放到很大時,會有欠擬合的問題</li>
<li>KNN 演算法關鍵點就是找到k值,可以獲得最好的分類</li>
<li>欠擬合<ul>
<li>低測試準確率</li>
<li>改進:調整 K 值,增加特徵,減少噪音(對數據進行清理和預處理),使用更複雜的模型</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成數據</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">200</span>, centers=<span class="number">2</span>, random_state=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定繪圖區域</span></span><br><span class="line">x_min, x_max = X[:,<span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = X[:,<span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 產生所有平面座標(這些陣列是二維的)</span></span><br><span class="line"><span class="comment"># xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),</span></span><br><span class="line"><span class="comment">#                      np.arange(y_min, y_max, 0.01))</span></span><br><span class="line"><span class="comment"># more quickly</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">k_values = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立四個子圖</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, ax <span class="keyword">in</span> <span class="built_in">zip</span>(k_values, axs.ravel()):</span><br><span class="line">    <span class="comment"># 建立模型,進行訓練</span></span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors = k)</span><br><span class="line">    knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ravel() 方法將二維陣列壓平成一維陣列</span></span><br><span class="line">    <span class="comment"># np.c_ 按列合併多個一維陣列，生成一個新的二維陣</span></span><br><span class="line">    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    <span class="comment"># Z 的 shape same as xx</span></span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 繪製等高線圖</span></span><br><span class="line">    ax.contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 顯示散點圖</span></span><br><span class="line">    ax.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolor=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    ax.set_title(<span class="string">f&quot;KNN, random_state=30, k=<span class="subst">&#123;k&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">k_values = [<span class="number">5</span>, <span class="number">7</span>, <span class="number">29</span>, <span class="number">49</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立四個子圖</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, ax <span class="keyword">in</span> <span class="built_in">zip</span>(k_values, axs.ravel()):</span><br><span class="line">    <span class="comment"># 建立模型,進行訓練</span></span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors = k)</span><br><span class="line">    knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ravel() 方法將二維陣列壓平成一維陣列</span></span><br><span class="line">    <span class="comment"># np.c_ 按列合併多個一維陣列，生成一個新的二維陣</span></span><br><span class="line">    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    <span class="comment"># Z 的 shape same as xx</span></span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 繪製等高線圖</span></span><br><span class="line">    ax.contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 顯示散點圖</span></span><br><span class="line">    ax.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolor=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    ax.set_title(<span class="string">f&quot;KNN, random_state=30, k=<span class="subst">&#123;k&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 調整子圖距離</span></span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.2</span>, hspace=<span class="number">0.4</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic39.png" class="" title="pic39">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic40.png" class="" title="pic40">
</div>

<h6 id="多類分析"><a href="#多類分析" class="headerlink" title="多類分析"></a>多類分析</h6><p>錯誤原因應該是資料重疊,分成4類應較為適當</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成數據</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">5</span>, random_state=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line"><span class="comment"># n_neighbors=3 取最近 3 點</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors = k)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定繪圖區域</span></span><br><span class="line">x_min, x_max = X[:,<span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = X[:,<span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 產生所有平面座標(這些陣列是二維的)</span></span><br><span class="line"><span class="comment"># xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),</span></span><br><span class="line"><span class="comment">#                      np.arange(y_min, y_max, 0.01))</span></span><br><span class="line"><span class="comment"># more quickly</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ravel() 方法將二維陣列壓平成一維陣列</span></span><br><span class="line"><span class="comment"># np.c_ 按列合併多個一維陣列，生成一個新的二維陣</span></span><br><span class="line">Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line"><span class="comment"># Z 的 shape same as xx</span></span><br><span class="line">Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 繪製等高線圖（Filled Contour Plot）</span></span><br><span class="line">plt.contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示散點圖</span></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolor=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示準確度</span></span><br><span class="line">y_pred = knn.predict(X)</span><br><span class="line">accuracy = accuracy_score(y, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;準確率 : <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準確率 : 0.952</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic41.png" class="" title="pic41">
</div>

<h4 id="房價計算-選舉準備香腸-迴歸應用"><a href="#房價計算-選舉準備香腸-迴歸應用" class="headerlink" title="房價計算,選舉準備香腸 - 迴歸應用"></a>房價計算,選舉準備香腸 - 迴歸應用</h4><h5 id="KNN迴歸應用-簡單實例"><a href="#KNN迴歸應用-簡單實例" class="headerlink" title="KNN迴歸應用 - 簡單實例"></a>KNN迴歸應用 - 簡單實例</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNN迴歸應用 - 簡單實例</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">X = [[<span class="number">0</span>] ,[<span class="number">1</span>] ,[<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=<span class="number">2</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">x = <span class="number">1.5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x = <span class="subst">&#123;x&#125;</span> --&gt; <span class="subst">&#123;knn.predict([[x]])&#125;</span>&#x27;</span>)</span><br><span class="line">x = <span class="number">2.5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x = <span class="subst">&#123;x&#125;</span> --&gt; <span class="subst">&#123;knn.predict([[x]])&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x = 1.5 --&gt; [0.5]</span></span><br><span class="line"><span class="comment"># x = 2.5 --&gt; [1.5]</span></span><br></pre></td></tr></table></figure>

<h5 id="KNN迴歸應用-房價預估"><a href="#KNN迴歸應用-房價預估" class="headerlink" title="KNN迴歸應用 - 房價預估"></a>KNN迴歸應用 - 房價預估</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNN迴歸應用 - 房價預估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練數據(坪)</span></span><br><span class="line">X_train = np.array([<span class="number">50</span>, <span class="number">80</span>, <span class="number">120</span>, <span class="number">150</span>, <span class="number">200</span>, <span class="number">250</span>, <span class="number">300</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 目標數值(價格萬元)</span></span><br><span class="line">y_train = np.array([<span class="number">180</span>, <span class="number">280</span>, <span class="number">360</span>, <span class="number">420</span>, <span class="number">580</span>, <span class="number">720</span>, <span class="number">850</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型 k=3, 擬合模型</span></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測新的房子價格</span></span><br><span class="line">X_new = np.array([<span class="number">110</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y_pred = knn.predict(X_new)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出結果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;X_new[<span class="number">0</span>,<span class="number">0</span>]&#125;</span>坪的房子預估價格為 <span class="subst">&#123;y_pred[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span> 萬元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 110坪的房子預估價格為 353.33 萬元</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNN迴歸應用 - 房價預估2</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練數據(坪)</span></span><br><span class="line">X_train = np.array([[<span class="number">50</span>,<span class="number">15</span>], [<span class="number">80</span>,<span class="number">10</span>], [<span class="number">120</span>,<span class="number">5</span>], [<span class="number">150</span>,<span class="number">3</span>],</span><br><span class="line">                    [<span class="number">200</span>,<span class="number">2</span>], [<span class="number">250</span>,<span class="number">1</span>], [<span class="number">300</span>,<span class="number">0.5</span>]])</span><br><span class="line"><span class="comment"># 目標數值(價格萬元)</span></span><br><span class="line">y_train = np.array([<span class="number">180</span>, <span class="number">280</span>, <span class="number">360</span>, <span class="number">420</span>, <span class="number">580</span>, <span class="number">720</span>, <span class="number">850</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型 k=3, 擬合模型</span></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測新的房子價格</span></span><br><span class="line">X_new = np.array([[<span class="number">180</span>, <span class="number">7</span>]])</span><br><span class="line">y_pred = knn.predict(X_new)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出結果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;X_new[<span class="number">0</span>,<span class="number">0</span>]&#125;</span>坪 <span class="subst">&#123;X_new[<span class="number">0</span>,<span class="number">1</span>]&#125;</span>年的房子預估價格為 <span class="subst">&#123;y_pred[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span> 萬元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 180坪 7年的房子預估價格為 453.33 萬元</span></span><br></pre></td></tr></table></figure>

<h5 id="選舉造勢與準備烤香腸數量"><a href="#選舉造勢與準備烤香腸數量" class="headerlink" title="選舉造勢與準備烤香腸數量"></a>選舉造勢與準備烤香腸數量</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic42.png" class="" title="pic42">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 造勢烤香腸預估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練數據</span></span><br><span class="line">X_train = np.array([[<span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>],</span><br><span class="line">                    [<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">5</span>, <span class="number">4</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>],</span><br><span class="line">                    [<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="comment"># 目標數值</span></span><br><span class="line">y_train = np.array([<span class="number">100</span>, <span class="number">250</span>, <span class="number">350</span>, <span class="number">180</span>, <span class="number">170</span>, <span class="number">300</span>, <span class="number">50</span>,</span><br><span class="line">                    <span class="number">275</span>, <span class="number">230</span>, <span class="number">165</span>, <span class="number">320</span>, <span class="number">210</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型 k=5, 擬合模型</span></span><br><span class="line">knn = KNeighborsRegressor(n_neighbors=<span class="number">5</span>)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測準備香腸數</span></span><br><span class="line">X_new = np.array([[<span class="number">1</span>, <span class="number">5</span>, <span class="number">2</span>]])</span><br><span class="line">y_pred = knn.predict(X_new)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出結果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;應該準備 <span class="subst">&#123;<span class="built_in">int</span>(y_pred[<span class="number">0</span>])&#125;</span> 條香腸&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 應該準備 243 條香腸</span></span><br></pre></td></tr></table></figure>

<h5 id="KKK-模型回歸線分析"><a href="#KKK-模型回歸線分析" class="headerlink" title="KKK 模型回歸線分析"></a>KKK 模型回歸線分析</h5><h6 id="繪製散點圖"><a href="#繪製散點圖" class="headerlink" title="繪製散點圖"></a>繪製散點圖</h6><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成線性數據</span></span><br><span class="line"><span class="comment"># make_regression 用於生成合成線性回歸數據集的函數</span></span><br><span class="line"><span class="comment"># 主要參數</span></span><br><span class="line"><span class="comment">#   n_samples（樣本數量）：指定要生成的數據點數量。默認值為 100。</span></span><br><span class="line"><span class="comment">#   n_features（特徵數量）：每個數據點的特徵數量。在回歸問題中，這表示自變量的個數。</span></span><br><span class="line"><span class="comment">#   n_informative（有用特徵數量）：對於回歸任務有實際影響的特徵數量。默認值是 n_features。</span></span><br><span class="line"><span class="comment">#   noise（噪聲）：目標變量中添加的高斯噪聲的標準差。這個參數用來模擬數據中的隨機誤差或不確定性。</span></span><br><span class="line"><span class="comment">#   random_state（隨機種子）：用於控制生成數據集的隨機性。設置這個值可以保證每次生成相同的數據集，方便結果重現。</span></span><br><span class="line"><span class="comment"># 返回值</span></span><br><span class="line"><span class="comment">#   X：生成的特徵數據集，是一個形狀為 (n_samples, n_features) 的二維數組。</span></span><br><span class="line"><span class="comment">#   y：對應的目標變量，是一個形狀為 (n_samples,) 的一維數組。</span></span><br><span class="line">X, y = make_regression(n_features=<span class="number">1</span>, noise=<span class="number">20</span>, random_state=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X, y, c=<span class="string">&#x27;y&#x27;</span>, edgecolors=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic43.png" class="" title="pic43">
</div>

<h6 id="繪製KNN迴歸曲線"><a href="#繪製KNN迴歸曲線" class="headerlink" title="繪製KNN迴歸曲線"></a>繪製KNN迴歸曲線</h6><p>設定k值 2,3,4,5 同時計算 R平方判定係數,得到最好模型的k值</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"><span class="comment"># 顯示負號</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成線性數據</span></span><br><span class="line">X, y = make_regression(n_features=<span class="number">1</span>, noise=<span class="number">20</span>, random_state=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立 X 區間含 300 點</span></span><br><span class="line">xx = np.linspace(X.<span class="built_in">min</span>(), X.<span class="built_in">max</span>(), <span class="number">300</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">k_values = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, ax <span class="keyword">in</span> <span class="built_in">zip</span>(k_values, axs.ravel()):</span><br><span class="line">    <span class="comment"># 建立模型, 擬合模型</span></span><br><span class="line">    knn = KNeighborsRegressor(n_neighbors=k)</span><br><span class="line">    knn.fit(X, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 計算平方係數</span></span><br><span class="line">    r2 = knn.score(X, y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;k = <span class="subst">&#123;k&#125;</span>, R平方係數: <span class="subst">&#123;r2:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 繪製迴歸線</span></span><br><span class="line">    yy = knn.predict(xx)</span><br><span class="line">    ax.plot(xx, yy)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 繪製散點圖</span></span><br><span class="line">    ax.scatter(X, y, c=<span class="string">&#x27;y&#x27;</span>, edgecolors=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    ax.set_title(<span class="string">f&quot;KNN-Regression k=<span class="subst">&#123;k&#125;</span> R 平方係數=<span class="subst">&#123;r2:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 調整子圖間距</span></span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.2</span>, hspace=<span class="number">0.2</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># k = 2, R平方係數: 0.871(最好模型)</span></span><br><span class="line"><span class="comment"># k = 3, R平方係數: 0.838</span></span><br><span class="line"><span class="comment"># k = 4, R平方係數: 0.800</span></span><br><span class="line"><span class="comment"># k = 5, R平方係數: 0.788</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic44.png" class="" title="pic44">
</div>

<h4 id="鳶尾花數據-分類應用"><a href="#鳶尾花數據-分類應用" class="headerlink" title="鳶尾花數據-分類應用"></a>鳶尾花數據-分類應用</h4><h5 id="鳶尾花數據內容"><a href="#鳶尾花數據內容" class="headerlink" title="鳶尾花數據內容"></a>鳶尾花數據內容</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic45.png" class="" title="pic45">
</div>

<h5 id="輸出數據集"><a href="#輸出數據集" class="headerlink" title="輸出數據集"></a>輸出數據集</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic46.png" class="" title="pic46">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;自變數  樣本外形 : <span class="subst">&#123;iris.data.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目標變數樣本外形 : <span class="subst">&#123;iris.target.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特徵名稱</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;特徵名稱\n <span class="subst">&#123;iris.feature_names&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 描述特徵名稱</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;描述特徵名稱\n <span class="subst">&#123;iris.DESCR&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自變數  樣本外形 : (150, 4)</span></span><br><span class="line"><span class="comment"># 目標變數樣本外形 : (150,)</span></span><br><span class="line"><span class="comment"># 特徵名稱</span></span><br><span class="line"><span class="comment">#  [&#x27;sepal length (cm)&#x27;, &#x27;sepal width (cm)&#x27;, &#x27;petal length (cm)&#x27;, &#x27;petal width (cm)&#x27;]</span></span><br><span class="line"><span class="comment"># 描述特徵名稱</span></span><br><span class="line"><span class="comment">#  .. _iris_dataset:</span></span><br></pre></td></tr></table></figure>

<h5 id="用-Pandas-顯示鳶尾花數據"><a href="#用-Pandas-顯示鳶尾花數據" class="headerlink" title="用 Pandas 顯示鳶尾花數據"></a>用 Pandas 顯示鳶尾花數據</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pandas 顯示鳶尾花數據</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示所有 columns</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 設定顯示每 row 長度</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;species&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轉鳶尾花數據為標籤</span></span><br><span class="line">df[<span class="string">&#x27;species&#x27;</span>] = df[<span class="string">&#x27;species&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="number">0</span>:<span class="string">&#x27;setosa&#x27;</span>, <span class="number">1</span>:<span class="string">&#x27;versicolor&#x27;</span>, <span class="number">2</span>:<span class="string">&#x27;virginica&#x27;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(df.head())</span><br><span class="line"><span class="built_in">print</span>(df.groupby(<span class="string">&#x27;species&#x27;</span>).size())</span><br><span class="line"></span><br><span class="line"><span class="comment">#    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  species</span></span><br><span class="line"><span class="comment"># 0                5.1               3.5                1.4               0.2        0</span></span><br><span class="line"><span class="comment"># 1                4.9               3.0                1.4               0.2        0</span></span><br><span class="line"><span class="comment"># 2                4.7               3.2                1.3               0.2        0</span></span><br><span class="line"><span class="comment"># 3                4.6               3.1                1.5               0.2        0</span></span><br><span class="line"><span class="comment"># 4                5.0               3.6                1.4               0.2        0</span></span><br><span class="line"><span class="comment">#    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm) species</span></span><br><span class="line"><span class="comment"># 0                5.1               3.5                1.4               0.2  setosa</span></span><br><span class="line"><span class="comment"># 1                4.9               3.0                1.4               0.2  setosa</span></span><br><span class="line"><span class="comment"># 2                4.7               3.2                1.3               0.2  setosa</span></span><br><span class="line"><span class="comment"># 3                4.6               3.1                1.5               0.2  setosa</span></span><br><span class="line"><span class="comment"># 4                5.0               3.6                1.4               0.2  setosa</span></span><br><span class="line"><span class="comment"># species</span></span><br><span class="line"><span class="comment"># setosa        50</span></span><br><span class="line"><span class="comment"># versicolor    50</span></span><br><span class="line"><span class="comment"># virginica     50</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure>

<h5 id="繪製特徵散點圖"><a href="#繪製特徵散點圖" class="headerlink" title="繪製特徵散點圖"></a>繪製特徵散點圖</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將數據轉成 DataFrame format</span></span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;species&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轉鳶尾花數據為標籤</span></span><br><span class="line">df[<span class="string">&#x27;species&#x27;</span>] = df[<span class="string">&#x27;species&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="number">0</span>:<span class="string">&#x27;setosa&#x27;</span>, <span class="number">1</span>:<span class="string">&#x27;versicolor&#x27;</span>, <span class="number">2</span>:<span class="string">&#x27;virginica&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seaborn 是一個基於 matplotlib 的 Python 資料視覺化庫，旨在提供更高層次的界面來繪製統計圖表。</span></span><br><span class="line"><span class="comment"># sns.scatterplot() 特別用於繪製散點圖，其主要目的是展示兩個變量之間的關係或分佈情況。每個數據點在圖上對應於資料集中一組特定的 x 和 y 座標值。</span></span><br><span class="line"><span class="comment"># 主要參數說明</span></span><br><span class="line"><span class="comment">#     x 和 y: 定義散點圖的 X 軸和 Y 軸資料。這些資料可以是資料框（DataFrame）中的列名，指定要繪製的變量。</span></span><br><span class="line"><span class="comment">#     data: 資料來源，通常是一個 pandas 資料框（DataFrame）。這個參數指定了要繪製圖表的數據集合。</span></span><br><span class="line"><span class="comment">#     hue: 用於根據某一類別變量的值對數據點進行著色，以便在圖中視覺上區分不同的組別。</span></span><br><span class="line"><span class="comment">#     style: 根據某一類別變量的值改變數據點的形狀，以區分不同的類別。</span></span><br><span class="line"><span class="comment">#     size: 根據某一數值變量的大小改變數據點的大小。</span></span><br><span class="line"><span class="comment">#     palette: 定義數據點顏色的調色板，可以是內置的顏色列表或自定義顏色列表。</span></span><br><span class="line"><span class="comment">#     markers: 設置不同組別的數據點標記樣式，可以指定具體的標記形狀。</span></span><br><span class="line"><span class="comment">#     alpha: 控制數據點的透明度，取值範圍為 0 到 1，0 為完全透明，1 為完全不透明。</span></span><br><span class="line"><span class="comment"># 傘點圖</span></span><br><span class="line">sns.scatterplot(data=df, x=<span class="string">&#x27;sepal length (cm)&#x27;</span>, y = <span class="string">&#x27;sepal width (cm)&#x27;</span>, style=<span class="string">&#x27;species&#x27;</span>, hue=<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;花萼長度(sepal length) vs 花萼寬度(sepal width)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic47.png" class="" title="pic47">
</div>

<h5 id="繪製成對數據特徵散點圖"><a href="#繪製成對數據特徵散點圖" class="headerlink" title="繪製成對數據特徵散點圖"></a>繪製成對數據特徵散點圖</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 設計機器學習模型,繪製所有變數的散點圖,也是認識數據特徵的好方法</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將數據轉成 DataFrame format</span></span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;species&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轉鳶尾花數據為標籤</span></span><br><span class="line">df[<span class="string">&#x27;species&#x27;</span>] = df[<span class="string">&#x27;species&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="number">0</span>:<span class="string">&#x27;setosa&#x27;</span>, <span class="number">1</span>:<span class="string">&#x27;versicolor&#x27;</span>, <span class="number">2</span>:<span class="string">&#x27;virginica&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sns.pairplot() 主要用於資料探索（exploratory data analysis, EDA），</span></span><br><span class="line"><span class="comment"># 可以幫助分析師快速了解數據中的變量之間的關係、數據的分佈情況和潛在的相關性。</span></span><br><span class="line"><span class="comment"># 主要參數說明</span></span><br><span class="line"><span class="comment">#   data: 指定要繪製的資料框（DataFrame），這是必須提供的參數。</span></span><br><span class="line"><span class="comment">#   hue: 用於設置根據某個類別變量對數據點進行顏色區分。例如，可以使用顏色來區分不同的類別標籤。</span></span><br><span class="line"><span class="comment">#   vars: 指定要包括在圖中的變量列表。如果未指定，將使用資料框中的所有數值變量。</span></span><br><span class="line"><span class="comment">#   kind: 指定對角線上的圖形類型，可以是 &quot;scatter&quot;（散點圖）、&quot;kde&quot;（核密度估計）或 &quot;hist&quot;（直方圖）。默認為 &quot;scatter&quot;。</span></span><br><span class="line"><span class="comment">#   diag_kind: 指定對角線上的圖形類型，可以是 &quot;auto&quot;、&quot;hist&quot;（直方圖）或 &quot;kde&quot;（核密度估計）。默認為 &quot;auto&quot;，</span></span><br><span class="line"><span class="comment">#               這意味著 hue 變量是類別變量時顯示直方圖，否則顯示核密度估計。</span></span><br><span class="line"><span class="comment">#   palette: 設定調色盤，用於設置不同類別的顏色。</span></span><br><span class="line"><span class="comment">#   markers: 用於指定不同類別的數據點標記樣式。</span></span><br><span class="line"><span class="comment">#   plot_kws: 提供其他繪圖參數，這些參數會傳遞給底層的 seaborn 繪圖函數。</span></span><br><span class="line"><span class="comment"># 使用 pairplot 繪製 sepal length(花萼長度) 和 petal length(花瓣長度) 兩個特徵的圖形</span></span><br><span class="line"><span class="comment"># 繪兩個特徵</span></span><br><span class="line">sns.pairplot(df, <span class="built_in">vars</span>=[<span class="string">&#x27;sepal length (cm)&#x27;</span>, <span class="string">&#x27;petal length (cm)&#x27;</span>], hue=<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"><span class="comment"># 繪所有個特徵</span></span><br><span class="line">sns.pairplot(df, hue=<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic48.png" class="" title="pic48">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic49.png" class="" title="pic49">
</div>

<h5 id="繪製鳶尾花決策邊界"><a href="#繪製鳶尾花決策邊界" class="headerlink" title="繪製鳶尾花決策邊界"></a>繪製鳶尾花決策邊界</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#  windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line">X = iris.data[: , :<span class="number">2</span>]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定繪圖區域</span></span><br><span class="line">x_min, x_max = X[:,<span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = X[:,<span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 產生所有平面座標</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 xx, yy 先扁平化再組成二維陣列,然後預估分類</span></span><br><span class="line">Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">Z = Z.reshape(xx.shape)</span><br><span class="line">plt.contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 顯示散點圖</span></span><br><span class="line">scatter = plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolors=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加圖例</span></span><br><span class="line">handle, labels = scatter.legend_elements()</span><br><span class="line">plt.legend(handle, iris.target_names, title=<span class="string">&#x27;鳶尾花品種&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;KNN for 鳶尾花Iris, k=1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花萼長度sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花萼寬度sepal width&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic50.png" class="" title="pic50">
</div>

<h5 id="繪製鳶尾花決策邊界-不同k值"><a href="#繪製鳶尾花決策邊界-不同k值" class="headerlink" title="繪製鳶尾花決策邊界(不同k值)"></a>繪製鳶尾花決策邊界(不同k值)</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#  windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data[: , :<span class="number">2</span>]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型,進行訓練</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">knn.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定繪圖區域</span></span><br><span class="line">x_min, x_max = X[:,<span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = X[:,<span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:,<span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 產生所有平面座標</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.01</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.01</span>))</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">k_values = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">19</span>, <span class="number">49</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, ax <span class="keyword">in</span> <span class="built_in">zip</span>(k_values, axs.ravel()):</span><br><span class="line">    <span class="comment"># 將 xx, yy 先扁平化再組成二維陣列,然後預估分類</span></span><br><span class="line">    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    ax.contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 顯示散點圖</span></span><br><span class="line">    scatter = ax.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=y, edgecolors=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 增加圖例</span></span><br><span class="line">    handle, labels = scatter.legend_elements()</span><br><span class="line">    ax.legend(handle, iris.target_names, title=<span class="string">&#x27;鳶尾花品種&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    ax.set_title(<span class="string">f&#x27;KNN for 鳶尾花Iris, k=<span class="subst">&#123;k&#125;</span>&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;花萼長度sepal length&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;花萼寬度sepal width&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.2</span>, hspace=<span class="number">0.2</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic51.png" class="" title="pic51">
</div>

<h5 id="計算最優k值"><a href="#計算最優k值" class="headerlink" title="計算最優k值"></a>計算最優k值</h5><p>k&lt;43 有較好的準確度</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 計算最優k值 (k&lt;43 有較好的準確度)</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="comment"># import pandas as pd</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># import seaborn as sns</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#  windows 使用 微軟正黑體</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>] = [<span class="string">&quot;Microsoft JhengHei&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># load 鳶尾花數據</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割訓練集和測試集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y,</span><br><span class="line">                                    test_size=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 設定所有準確度列表</span></span><br><span class="line">accuracy_scores = []</span><br><span class="line"></span><br><span class="line">k_values = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">100</span>, <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_values:</span><br><span class="line">    <span class="comment"># 建立模型,進行訓練</span></span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    y_pred = knn.predict(X_test)</span><br><span class="line">    <span class="comment"># 計算準確度</span></span><br><span class="line">    accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line">    accuracy_scores.append(accuracy)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;k=<span class="subst">&#123;k&#125;</span>, 準確度: <span class="subst">&#123;accuracy:<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 繪製圖表</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(k_values, accuracy_scores, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;鳶尾花預估準確值 vs k值&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;k 值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;準確度&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># k=1, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=3, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=5, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=7, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=9, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=11, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=13, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=15, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=17, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=19, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=21, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=23, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=25, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=27, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=29, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=31, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=33, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=35, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=37, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=39, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=41, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=43, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=45, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=47, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=49, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=51, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=53, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=55, 準確度: 1.000</span></span><br><span class="line"><span class="comment"># k=57, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=59, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=61, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=63, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=65, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=67, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=69, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=71, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=73, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=75, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=77, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=79, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=81, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=83, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=85, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=87, 準確度: 0.933</span></span><br><span class="line"><span class="comment"># k=89, 準確度: 0.733</span></span><br><span class="line"><span class="comment"># k=91, 準確度: 0.733</span></span><br><span class="line"><span class="comment"># k=93, 準確度: 0.733</span></span><br><span class="line"><span class="comment"># k=95, 準確度: 0.733</span></span><br><span class="line"><span class="comment"># k=97, 準確度: 0.733</span></span><br><span class="line"><span class="comment"># k=99, 準確度: 0.733</span></span><br></pre></td></tr></table></figure>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic52.png" class="" title="pic52">
</div>

<h4 id="小行星撞地球-分類應用"><a href="#小行星撞地球-分類應用" class="headerlink" title="小行星撞地球-分類應用"></a>小行星撞地球-分類應用</h4><h5 id="Kaggle-NANA-ASteroids-Classification-數據"><a href="#Kaggle-NANA-ASteroids-Classification-數據" class="headerlink" title="Kaggle NANA ASteroids Classification 數據"></a>Kaggle NANA ASteroids Classification 數據</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic53.png" class="" title="pic53">
</div>

<div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic54.png" class="" title="pic54">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;nasa.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出5筆</span></span><br><span class="line"><span class="built_in">print</span>(df.head)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;bound method NDFrame.head of       Neo Reference ID     Name  Absolute Magnitude  ...  Mean Motion  Equinox  Hazardous</span></span><br><span class="line"><span class="comment"># 0              3703080  3703080              21.600  ...     0.590551    J2000       True</span></span><br><span class="line"><span class="comment"># 1              3723955  3723955              21.300  ...     0.845330    J2000      False</span></span><br><span class="line"><span class="comment"># 2              2446862  2446862              20.300  ...     0.559371    J2000       True</span></span><br><span class="line"><span class="comment"># 3              3092506  3092506              27.400  ...     0.700277    J2000      False</span></span><br><span class="line"><span class="comment"># 4              3514799  3514799              21.600  ...     0.726395    J2000       True</span></span><br><span class="line"><span class="comment"># ...                ...      ...                 ...  ...          ...      ...        ...</span></span><br><span class="line"><span class="comment"># 4682           3759007  3759007              23.900  ...     0.787436    J2000      False</span></span><br><span class="line"><span class="comment"># 4683           3759295  3759295              28.200  ...     0.884117    J2000      False</span></span><br><span class="line"><span class="comment"># 4684           3759714  3759714              22.700  ...     0.521698    J2000      False</span></span><br><span class="line"><span class="comment"># 4685           3759720  3759720              21.800  ...     0.543767    J2000      False</span></span><br><span class="line"><span class="comment"># 4686           3772978  3772978              19.109  ...     0.550729    J2000      False</span></span><br></pre></td></tr></table></figure>

<h5 id="預處理資料"><a href="#預處理資料" class="headerlink" title="預處理資料"></a>預處理資料</h5><div style="max-width:500px">
  <img src="/2024/06/27/python-33/pic55.png" class="" title="pic55">
</div>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;nasa.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刪除資料</span></span><br><span class="line">df = df.drop([<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Neo Reference ID&#x27;</span>, <span class="string">&#x27;Est Dia in M(min)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Est Dia in M(max)&#x27;</span>, <span class="string">&#x27;Est Dia in Miles(min)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Est Dia in Miles(max)&#x27;</span>, <span class="string">&#x27;Est Dia in Feet(min)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Est Dia in Feet(max)&#x27;</span>, <span class="string">&#x27;Epoch Date Close Approach&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Relative Velocity km per hr&#x27;</span>, <span class="string">&#x27;Miles per hour&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Miss Dist.(Astronomical)&#x27;</span>, <span class="string">&#x27;Miss Dist.(lunar)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Miss Dist.(miles)&#x27;</span>, <span class="string">&#x27;Equinox&#x27;</span>],</span><br><span class="line">             axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 &#x27;Hazardous&#x27; True/False 轉為 1/0</span></span><br><span class="line">df[<span class="string">&#x27;Hazardous&#x27;</span>] = df[<span class="string">&#x27;Hazardous&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="literal">True</span>:<span class="number">1</span>, <span class="literal">False</span>:<span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 &#x27;Close Approach Date&#x27; 和 &#x27;Orbit Determination Date&#x27;</span></span><br><span class="line"><span class="comment"># 轉為日期時間物件,再轉為時間戳記</span></span><br><span class="line"><span class="comment"># test format</span></span><br><span class="line"><span class="comment"># df[&#x27;Close Approach Date&#x27;] = pd.to_datetime(df[&#x27;Close Approach Date&#x27;])</span></span><br><span class="line"><span class="comment"># df[&#x27;Orbit Determination Date&#x27;] = pd.to_datetime(df[&#x27;Orbit Determination Date&#x27;])</span></span><br><span class="line">df[<span class="string">&#x27;Close Approach Date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;Close Approach Date&#x27;</span>]).astype(<span class="string">&#x27;int64&#x27;</span>) // <span class="number">10</span>**<span class="number">9</span></span><br><span class="line">df[<span class="string">&#x27;Orbit Determination Date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;Orbit Determination Date&#x27;</span>]).astype(<span class="string">&#x27;int64&#x27;</span>) // <span class="number">10</span>**<span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出5筆</span></span><br><span class="line"><span class="built_in">print</span>(df.head)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;bound method NDFrame.head of       Absolute Magnitude  Est Dia in KM(min)  Est Dia in KM(max)  Close Approach Date  Relative Velocity km per sec  Miss Dist.(kilometers)  ... Perihelion Arg  Aphelion Dist  Perihelion Time  Mean Anomaly  Mean Motion  Hazardous</span></span><br><span class="line"><span class="comment"># 0                 21.600            0.127220            0.284472            788918400                      6.115834            6.275369e+07  ...      57.257470       2.005764     2.458162e+06    264.837533     0.590551          1</span></span><br><span class="line"><span class="comment"># 1                 21.300            0.146068            0.326618            788918400                     18.113985            5.729815e+07  ...     313.091975       1.497352     2.457795e+06    173.741112     0.845330          0</span></span><br><span class="line"><span class="comment"># 2                 20.300            0.231502            0.517654            789523200                      7.590711            7.622912e+06  ...     248.415038       1.966857     2.458120e+06    292.893654     0.559371          1</span></span><br><span class="line"><span class="comment"># 3                 27.400            0.008801            0.019681            790128000                     11.173874            4.268362e+07  ...      18.707701       1.527904     2.457902e+06     68.741007     0.700277          0</span></span><br><span class="line"><span class="comment"># 4                 21.600            0.127220            0.284472            790128000                      9.840831            6.101082e+07  ...     158.263596       1.483543     2.457814e+06    135.142133     0.726395          1</span></span><br><span class="line"><span class="comment"># ...                  ...                 ...                 ...                  ...                           ...                     ...  ...            ...            ...              ...           ...          ...        ...</span></span><br><span class="line"><span class="comment"># 4682              23.900            0.044112            0.098637           1473292800                     22.154265            6.187511e+06  ...     276.395697       1.581299     2.457708e+06    304.306025     0.787436          0</span></span><br><span class="line"><span class="comment"># 4683              28.200            0.006089            0.013616           1473292800                      3.225150            9.677324e+05  ...      42.111064       1.153835     2.458088e+06    282.978786     0.884117          0</span></span><br><span class="line"><span class="comment"># 4684              22.700            0.076658            0.171412           1473292800                      7.191642            9.126775e+06  ...     274.692712       2.090708     2.458300e+06    203.501147     0.521698          0</span></span><br><span class="line"><span class="comment"># 4685              21.800            0.116026            0.259442           1473292800                     11.352090            3.900908e+07  ...     180.346090       1.787733     2.458288e+06    203.524965     0.543767          0</span></span><br><span class="line"><span class="comment"># 4686              19.109            0.400641            0.895860           1473292800                     35.946852            6.916986e+07  ...     222.436688       2.071980     2.458319e+06    184.820424     0.550729          0</span></span><br></pre></td></tr></table></figure>

<h5 id="預測小行星撞地球準確率"><a href="#預測小行星撞地球準確率" class="headerlink" title="預測小行星撞地球準確率"></a>預測小行星撞地球準確率</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 讀取數據</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;nasa.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刪除資料</span></span><br><span class="line">df = df.drop([<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Neo Reference ID&#x27;</span>, <span class="string">&#x27;Est Dia in M(min)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Est Dia in M(max)&#x27;</span>, <span class="string">&#x27;Est Dia in Miles(min)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Est Dia in Miles(max)&#x27;</span>, <span class="string">&#x27;Est Dia in Feet(min)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Est Dia in Feet(max)&#x27;</span>, <span class="string">&#x27;Epoch Date Close Approach&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Relative Velocity km per hr&#x27;</span>, <span class="string">&#x27;Miles per hour&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Miss Dist.(Astronomical)&#x27;</span>, <span class="string">&#x27;Miss Dist.(lunar)&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Miss Dist.(miles)&#x27;</span>, <span class="string">&#x27;Equinox&#x27;</span>],</span><br><span class="line">             axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 &#x27;Hazardous&#x27; True/False 轉為 1/0</span></span><br><span class="line">df[<span class="string">&#x27;Hazardous&#x27;</span>] = df[<span class="string">&#x27;Hazardous&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="literal">True</span>:<span class="number">1</span>, <span class="literal">False</span>:<span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 將 &#x27;Close Approach Date&#x27; 和 &#x27;Orbit Determination Date&#x27;</span></span><br><span class="line"><span class="comment"># 轉為日期時間物件,再轉為時間戳記</span></span><br><span class="line">df[<span class="string">&#x27;Close Approach Date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;Close Approach Date&#x27;</span>]).astype(<span class="string">&#x27;int64&#x27;</span>) // <span class="number">10</span>**<span class="number">9</span></span><br><span class="line">df[<span class="string">&#x27;Orbit Determination Date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;Orbit Determination Date&#x27;</span>]).astype(<span class="string">&#x27;int64&#x27;</span>) // <span class="number">10</span>**<span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 檢查並處理缺失值</span></span><br><span class="line"><span class="keyword">if</span> df.isnull().values.<span class="built_in">any</span>():</span><br><span class="line">    <span class="comment"># 可選擇填補缺失值或丟棄(填補中位數)</span></span><br><span class="line">    df.fillna(df.mefian(), implace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 執行 one-hot 編碼df</span></span><br><span class="line">df = pd.get_dummies(df, columns=[<span class="string">&#x27;Orbiting Body&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割數據集為特徵及目標</span></span><br><span class="line">X = df.drop(<span class="string">&#x27;Hazardous&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&#x27;Hazardous&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割訓練集和測試集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y,</span><br><span class="line">                                    test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 標準化數據</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用KNN演算法進行訓練</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 預測並計算準確度</span></span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy : <span class="subst">&#123;accuracy_score(y_test, y_pred)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出混淆矩陣</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Confusion Matrix:&#x27;</span> )</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 輸出分類報告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Classification Report:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy : 0.8923240938166311</span></span><br><span class="line"><span class="comment"># Confusion Matrix:</span></span><br><span class="line"><span class="comment"># [[760  31]</span></span><br><span class="line"><span class="comment">#  [ 70  77]]</span></span><br><span class="line"><span class="comment"># Classification Report:</span></span><br><span class="line"><span class="comment">#               precision    recall  f1-score   support</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#            0       0.92      0.96      0.94       791</span></span><br><span class="line"><span class="comment">#            1       0.71      0.52      0.60       147</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     accuracy                           0.89       938</span></span><br><span class="line"><span class="comment">#    macro avg       0.81      0.74      0.77       938</span></span><br><span class="line"><span class="comment"># weighted avg       0.88      0.89      0.89       938</span></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/book/" rel="tag"># book</a>
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/06/13/python-32/" rel="prev" title="scikit-learn">
                  <i class="fa fa-chevron-left"></i> scikit-learn
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/08/05/python-34/" rel="next" title="(3) 機器學習最強入門:基礎數學/機率/統計邁向AI真實數據">
                  (3) 機器學習最強入門:基礎數學/機率/統計邁向AI真實數據 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Robert Kao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="總字數">2.7m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="所需總閱讀時間">40:58</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://hot5656-blog.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://hot5656.github.io/2024/06/27/python-33/";
    this.page.identifier = "2024/06/27/python-33/";
    this.page.title = "(2) 機器學習最強入門:基礎數學/機率/統計邁向AI真實數據";
    };
  NexT.utils.loadComments('#disqus_thread', () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://hot5656-blog.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
